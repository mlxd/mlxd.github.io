<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math on Lost in Computation</title>
    <link>https://mlxd.github.io/tags/math/</link>
    <description>Recent content in Math on Lost in Computation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Lee James O&#39;Riordan (mlxd)</copyright>
    <lastBuildDate>Mon, 04 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mlxd.github.io/tags/math/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Permutations of n-D data</title>
      <link>https://mlxd.github.io/post/2017-09-04-nd-data/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-09-04-nd-data/</guid>
      <description>Something I have been (occasionally) thinking about for quite a long time is the means to manipulate high-dimensional data-sets (dense grids, specifically), and do so efficiently. Namely, I wish to make the data along any specific orthgonal basis direction to become adjacent in memory by strides of the length of samples along that axis.
The reason for this? To allow for optimal vectorisation and caching of data when performing computations. Take for example a GPU: if we put data on GPU memory we want to access and manipulate it in chunks given by the chosen thread-size.</description>
    </item>
    
  </channel>
</rss>