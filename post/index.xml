<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Lost in Computation</title>
    <link>https://mlxd.github.io/post/</link>
    <description>Recent content in Posts on Lost in Computation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Lee James O&#39;Riordan (mlxd)</copyright>
    <lastBuildDate>Sun, 14 Jan 2018 13:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates: Background</title>
      <link>https://mlxd.github.io/post/thesis_background/</link>
      <pubDate>Sun, 14 Jan 2018 13:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/thesis_background/</guid>
      <description>

&lt;p&gt;&lt;code&gt;NOTE: The following format was generated by converting the LaTeX format to mMarkdown with pandoc. The referencing has not converted, images are not present, and errors may exist.&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;ultracold-atoms&#34;&gt;Ultracold atoms&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;cooling-of-atomic-gases&#34;&gt;Cooling of atomic gases&lt;/h3&gt;

&lt;p&gt;One of the major advances in experimental physics towards creating matter in extreme situations has been the cooling of trapped atoms to temperatures near absolute zero. This feat resulted from the pioneering work of C. Cohen-Tannoudji, S. Chu and W. Phillips, and earned them the Nobel Prize in Physics, 1997 . It relies on the use of counter-propagating detuned laser fields which act upon a trapped cloud of atoms. Due to Doppler shifting of the frequencies, atoms moving towards the respective beams see resonant photons, absorb them and slow down due to the momentum absorbed. This is followed by a spontaneous emission in a random direction, for which the recoil kicks average out to zero; hence, the atoms become cooler. This technique is known as “Doppler cooling”. As a result, the atoms eventually reach a velocity below that which no photons can be absorbed from the lasers due to the change in resonance frequency and the limit imposed by the resonance width of the atomic levels, leaving a narrower velocity distribution with a peak at a lower value. Although Doppler cooling allowed temperatures to reach micro-Kelvin regimes, additional techniques, such as evaporative cooling, must be used to obtain atoms deep in the nano-Kelvin temperature range. A further discussion of these cooling methods is presented in . These cooling techniques allow for the creation of Bose–Einstein condensates in dilute atomic gases.&lt;/p&gt;

&lt;h3 id=&#34;introduction-to-bose-einstein-condensation&#34;&gt;Introduction to Bose–Einstein condensation&lt;/h3&gt;

&lt;p&gt;Upon learning of a work by S. N. Bose on the statistical behaviour of photons, A. Einstein translated and arranged for publication of his work, and generalised it to also describe systems of ideal bosons with mass . This led to the Bose–Einstein distribution, which in the framework of the grand canonical ensemble and following the description given by Pitaevskii and Stringari , can be written as
$$\bar{n}_i = \frac{1}{e^{\beta(\epsilon_i - \mu)} -1},$$
 where $\bar{n}_i$ is the average occupation number of the $i$-th energy state, $β = (k_BT)^{−1}$ with $k_B$ being the Boltzmann constant and $T$ the temperature, $ϵ_i$ is the $i$-th energy eigenvalue, and $μ$ is the chemical potential giving the energy required to add an atom to the system for a fixed volume and entropy. The total number of particles in the system, can be evaluated by summing over the individual occupation numbers, as
$$N=\displaystyle\sum_i \bar{n}_i.$$
 This work predicted that non-interacting, indistinguishable bosonic particles would undergo a phase transition below a critical temperature into a new phase in which all particles would occupy the same lowest lying energy state of the system. The number of atoms occupying this lowest lying state, $N_0$, at a given temperature is provided by
$$N_0 \equiv \bar{n}_0 = \frac{1}{e^{\beta(\epsilon_0 - \mu)} - 1},$$
 with $ϵ_0$ representing the lowest energy eigenvalue. Since negative occupation numbers would be a nonphysical result, the chemical potential is limited to values of $μ &amp;lt; ϵ_0$. As $μ$ tends to $ϵ_0$, the occupation of the lowest energy state grows large. Separating the total number of atoms into the lowest lying (condensed), $N_0$, and higher lying (thermal), $N_T$, states as
$$N = N_0 + N_T = N_0 + \displaystyle\sum_{i\neq 0}\bar{n}_i(T,\mu),$$
 allows for a relation for the onset of Bose–Einstein condensation to be given. For a finite temperature system ($T$ &amp;gt; 0) this will happen when the temperature drops below a critical value, $T$&lt;sub&gt;c&lt;/sub&gt;, where $μ$ will approach $ϵ$&lt;sub&gt;0&lt;/sub&gt;. This results in the macroscopic occupation of the lowest lying state, yielding a Bose–Einstein condensate (BEC).&lt;/p&gt;

&lt;p&gt;Given a cloud of identical bosons at temperatures higher than $T_c$, the particles behave classically and exhibit hard-core scattering interactions. As they are cooled, their thermal de Broglie wavelength increases as
$$\lambda_{\textrm{dB}} = \sqrt{\frac{\hbar^2}{2\pi mk_{B}T}},$$
 where $m$ is the atom mass, and the wave-nature of the atoms becomes more prominent. The de Broglie waves start to overlap when $λ_{dB}$≈ inter-particle separation. The quantity $χ = ρλ_{\textrm{dB}}^3$, where $ρ$ is the density of the gas, is known as the &lt;em&gt;phase-space density&lt;/em&gt;. Physically this denotes the number of particles present in a box with sides of $λ_{dB}$ length. The phase transition to the condensate sets in at $χ = ζ(3 / 2) ≈ 2.612$, where $\zeta(s) = \displaystyle\sum\limits_{n=1}^{\infty}\frac{1}{n^s}$ is the Riemann-Zeta function.  The value of $T_c$ for this to occur in a uniform gas is given by
    $ k_{\textrm{B}}T_{\textrm{c}} = \frac{2\pi}{\zeta\left( 3 / 2 \right)^{2 / 3}}\frac{\hbar^2\rho^{ 2 / 3 }}{m}.$
 It is worth noting that the above derivation assumes an ideal gas, in which there are no interactions between particles. As this is not the case for most physical systems, one must consider systems where interactions are weak. Fritz London, in 1938, following on from the body of work derived by Einstein and Bose drew the connection between superfluidity in liquid $^4\textrm{He}$ and Bose–Einstein condensation. However, due to the strongly interacting nature of liquid $^4\textrm{He}$ at low temperatures only approximately 10% of the atoms condense into a BEC. In order to achieve the large occupation of the lowest energy state the system must be prepared so that the inter-particle interaction strength does not degrade the coherence, as is the case for liquid $^4\textrm{He}$.&lt;/p&gt;

&lt;p&gt;Due to their weak interactions, dilute atomic gases are closer to the ideal case discussed by Bose and Einstein. One negative impact, though, were the diluteness requirements and higher masses of most atoms compared to $^4\textrm{He}$, which required reaching much lower transition temperatures. As such, the use of lighter elements was considered. Spin-polarised hydrogen was one of the first systems to be investigated to create a BEC in the 1970’s. Using trapping and cooling techniques available at the time, this type of system came close, but did not quite reach the required temperatures and phase-space densities for Bose–Einstein condensation to occur until over twenty years later. With the advent of laser cooling in the 1980’s, the use of alkali atoms was considered partly due to the ease of accessibility of their optical transition frequencies. It was not until 1995 that the first BECs were experimentally realised.&lt;/p&gt;

&lt;p&gt;For a finite number of atoms in a realistic experimental scenario, one can consider the case of a BEC trapped in a harmonic oscillator potential. For this finite-sized sample and inhomogeneous density profile, the transition temperature is given by 
$ k_{\textrm{B}}T_{\textrm{c}} = \frac{\hbar\bar{\omega}N^{ 1 / 3 }}{\zeta(3)^{ 1 / 3}},$
 where $\bar{\omega}=(\omega_x\omega_y\omega_z)^{ 1 / 3 }$ is the geometric mean of the harmonic oscillator frequencies, and interactions between the particles have been neglected. Critical temperatures for harmonically trapped dilute gases are on the order of nano-Kelvin for experimentally realistic systems.&lt;/p&gt;

&lt;h3 id=&#34;theoretical-description-of-becs-gross-pitaevskii-equation&#34;&gt;Theoretical description of BECs: Gross–Pitaevskii equation&lt;/h3&gt;

&lt;p&gt;We will, in the following section, outline the derivation of the mean-field Gross–Pitaevskii equation, which is widely used to study the behaviour of condensates in many works cited in this review. Following the &lt;em&gt;Les Houches 2013 Lecture Course&lt;/em&gt; by J. Walraven the second quantized form of the many-body Hamiltonian for interacting particles in an external potential is given by
$$\label{eqn:ham2ndq}
\hat{\mathcal{H}} = \hat{H_1} + \hat{H_2} = \int \hat{\Psi}^{\dagger}(\mathbf{r}) H_0\left(\textbf{r},\textbf{p} \right)  \hat{\Psi}(\mathbf{r}) \; d\textbf{r}  + \frac{1}{2} \iint\hat{\Psi}^{\dagger}(\mathbf{r}^\prime)\hat{\Psi}^{\dagger}(\mathbf{r})V_{\textrm{int}}(\textbf{r}^\prime,\textbf{r})\hat{\Psi}(\mathbf{r})\hat{\Psi}(\mathbf{r}^\prime) \; d\textbf{r}^\prime d\textbf{r},$$
 with $H_0(\textbf{r},\textbf{p}) = \textbf{p}^2 / (2m) + V_{\textrm{ext}}(\textbf{r}) = −( ℏ / (2m))∇^2 + V_\textrm{ext}(\textbf{r})$, and $\textbf{r} = (x, y, z)$. The external potential, $V_\textrm{ext}(\textbf{r})$ is taken as harmonic, of the form
$$V_{\text{ext}}(\mathbf{r}) = \frac{m}{2}\displaystyle\sum_{i}{\left(\omega_i r_i \right)^2},$$
 where $ω_i$ represents the trapping frequency in the $i$-th spatial dimension. The interaction potential, $V_\textrm{int}$ is assumed to be point-like as
$V_\textrm{int}(\textbf{r},\textbf{r}^′) = gδ(\textbf{r}−\textbf{r}^′)$,
 where $δ$ is the Dirac delta function and the mean-field interaction, $g$, is given by
$$g = \frac{4\pi\hbar^2 a_s}{m},$$
 with $a_s$ being the &lt;em&gt;s&lt;/em&gt;-wave scattering length. Inserting the contact potential Eq. into the second quantised interaction Hamiltonian $\hat{H}_2$ from Eq. above yields the relations&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
\hat{H}_2 &amp;amp;= \frac{g}{2} \int \hat{\Psi}^{\dagger}(\mathbf{r})\hat{\Psi}^{\dagger}(\mathbf{r}^{\prime}) \delta\left(\textbf{r} - \textbf{r}^{\prime}\right)\hat{\Psi}(\mathbf{r}^{\prime})\hat{\Psi}(\textbf{r})d\textbf{r}d\textbf{r}^{\prime} \newline
 &amp;amp; = \frac{g}{2}\int \hat{\Psi}^{\dagger}(\textbf{r})\hat{\Psi}^{\dagger}(\mathbf{r}) \hat{\Psi}(\mathbf{r})\hat{\Psi}(\mathbf{r})d\mathbf{r}d\mathbf{r} \newline
 &amp;amp; = \frac{g}{2}\int \hat{\Psi}^{\dagger}\left(\mathbf{r}\right)\hat{n}\left(\mathbf{\mathbf{r}}\right)\hat{\Psi}(\mathbf{r})d\textbf{r}.\end{aligned}$$&lt;/p&gt;

&lt;p&gt;In the Heisenberg picture, the evolution of the system is governed by the equation
$$\label{eqn:heisenberg}
\textrm{i}\hbar \frac{d}{d t}\hat{\Psi}_H\left(\mathbf{r}, t\right) = \left[\hat{\Psi}_{H}\left(\mathbf{r}, t\right), \hat{\mathcal{H}}  \right],$$
 where the Heisenberg field annihilation operator, $\hat{\Psi}_H\left(\textbf{r}, t\right)$, is given by
$$\label{eqn:psi_heisenberg}
\hat{\Psi}_H\left(\mathbf{r}, {t} \right) = e^{{\textrm{i}\hat{\mathcal{H}}t / \hbar}}\hat{\Psi}\left(\mathbf{r}\right) e^{{-\textrm{i}\hat{\mathcal{H}}t / \hbar}}.$$
 The operator, $\hat{\Psi}_H$, can be interpreted as the one removing an atom from a given state of the system. Therefore, if all &lt;em&gt;N&lt;/em&gt; atoms in the system are in the ground state, $|0_N\rangle$, as would be the case in an ideal condensate, the following relationship holds&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
\hat{\Psi}_{H}(\mathbf{r},t)\vert 0_N \rangle &amp;amp;= e^{\frac{\textrm{i}E_0(N-1)t}{\hbar}}\hat{\Psi}(\mathbf{r})e^{\frac{-\textrm{i}E_0(N)t}{\hbar}}\vert 0_N \rangle \newline
&amp;amp;= \hat{\Psi}(\mathbf{r})e^{\frac{\textrm{i}[E_0(N-1) - E_0(N)]t}{\hbar}} \vert 0_N \rangle \newline
&amp;amp;= \hat{\Psi}(\mathbf{r})e^{\frac{-\textrm{i}\mu t}{\hbar}} \vert 0_N \rangle,\end{aligned}\label{eqn:psi_dagger_time}
$$&lt;/p&gt;

&lt;p&gt;where the chemical potential is defined as $μ = E_0(N)−E_0(N − 1)$. Using the bosonic commutation relations
$$\begin{aligned}
\left[\hat{\Psi}(\mathbf{r}&amp;lsquo;), \hat{\Psi}^{\dagger}(\mathbf{r})\right] &amp;amp;=&amp;amp; \delta(\mathbf{r}&amp;rsquo; - \mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}&amp;lsquo;), \hat{\Psi}(\mathbf{r})\right] &amp;amp;=&amp;amp; \left[\hat{\Psi}^{\dagger}(\mathbf{r}&amp;lsquo;), \hat{\Psi}^{\dagger}(\mathbf{r})\right] = 0,\end{aligned}$$
 and noting the following relations
$$\begin{aligned}
\left[\hat{\Psi}(\mathbf{r}),\hat{H}_1 \right] &amp;amp; = \hat{H}_0(\mathbf{r},\mathbf{p})\hat{\Psi}(\mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}),\hat{H}_2 \right] &amp;amp; = g\hat{n}(\textbf{r})\hat{\Psi}(\mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}),\hat{N} \right] &amp;amp; = \hat{\Psi}(\textbf{r}) ,\end{aligned}$$
 upon substitution of Eq.  into Eq. , it can be rewritten as
$$\label{eqn:almost_gpe}
    \textrm{i} \hbar \frac{d}{d t} \left( \hat{\Psi}(\mathbf{r}) e^{-{\textrm{i}\mu t / \hbar}} \right) = H \hat{\Psi}(\mathbf{r}) e^{-{\textrm{i}\mu t / \hbar}}$$
 with
$$\label{eqn:h_many}
H =  -\frac{\hbar^2}{2m}\nabla^2  + V(\mathbf{r}) + g\hat{n}(\mathbf{r}).$$
 Due to the macroscopic occupation of the lowest lying single-particle state, $\hat{\Psi}$ can be treated as the sum of a condensed term and a quantum fluctuation (uncondensed) term, as
$$\label{eqn:gpe_fluc}
    \hat{\Psi} = \Psi + \delta\hat{\Psi},$$
 where $\Psi = \langle \hat{\Psi} \rangle$ is known as the condensate wavefunction. &lt;em&gt;Ψ&lt;/em&gt; takes the form of a classical field, and can be used to model the behaviour of the condensate, provided the number of atoms is sufficiently large ($N &amp;gt; 10^3$ for most experimental set-ups) and the correlations are not too strong i.e. the gas is sufficiently dilute that only two-body interactions occur. By substituting Eq.  into , and assuming a condensate at $T = 0 ~\textrm{K}$, the number of uncondensed atoms will be essentially zero, and thus we can safely ignore all terms in $\delta\hat{\Psi}$ and $\delta\hat{\Psi}^{\dagger}$. The above procedure gives the time dependent mean-field Gross–Pitaevskii equation (GPE) as
$$\label{eqn:gpe}
\textrm{i}\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = H_{\textrm{GP}} \Psi(\textbf{r},t),$$
 with the nonlinear GPE Hamiltonian,
$$\label{eqn:h_gp}
H_{\textrm{GP}} = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\textbf{r}) + g\vert\Psi(\mathbf{r},t)\vert^2 \right],$$
 where $Ψ(\mathbf{r}, t)=Ψ(\mathbf{r})e^{−\textrm{i}μt / ℏ}$. The time independent form can be found by evaluating the left-hand side derivative in and dividing across by $e^{−\textrm{i}μt / ℏ}$, yielding
$$\mu\Psi(\mathbf{r}) = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}) + g\vert\Psi(\mathbf{r})\vert^2 \right]\Psi(\mathbf{r}),$$
 where the wavefunction is normalised to the particle number, &lt;em&gt;N&lt;/em&gt;, as follows
$$\label{eqn:norm}
\displaystyle\int\limits_{-\infty}^{\infty}d\mathbf{r} \left\vert \Psi\left(\mathbf{r},t\right) \right\vert^2 = N.$$&lt;/p&gt;

&lt;p&gt;Assuming a large number of bosons in the condensate $N ≫ 1$, the interaction term dominates over the kinetic term of the Hamiltonian which can therefore be neglected. This approximation turns finding the ground state of the system into a solvable, algebraic problem, and is known as the Thomas–Fermi approximation . The Hamiltonian can thus be reduced to a combination of the trapping potential and the mean-field interaction, where the ground state wavefunction, $Ψ_\textrm{TF}$, can be determined from the time independent GPE as
$$\Psi_{\textrm{TF}}(\mathbf{r}) = \sqrt{ g^{-1}[\mu - V(\textbf{r})] \Theta(\mu - V(\textbf{r}))},$$
 where &lt;em&gt;μ&lt;/em&gt; is the chemical potential, and $Θ$ is the Heaviside step function, which ensures that the condensate density does not become negative. The boundary of the cloud is determined by the surface at which the density becomes zero, and corresponds to the point where the trapping potential and chemical potential are equal. This gives the Thomas–Fermi radius along the $i$-th direction of the cloud as
$${R}_i = a_{\textrm{}}\left(\frac{15Na_s}{a_{\textrm{}}}\right)^{ 1 / 5 }\frac{\bar{\omega}_{\textrm{}}}{\omega_i},$$
 where the characteristic length of the harmonic oscillator is given by ${a} = \sqrt{{\hbar}/{m\bar{\omega}}}$, and
$$\bar{\omega} = \left(\displaystyle\prod\limits_j \omega_j\right)^{ 1 / 3 },$$
 is the geometric mean of the harmonic oscillator trapping frequencies. This approximation holds valid for stationary condensate solutions.&lt;/p&gt;

&lt;p&gt;To investigate condensate dynamics, it is convenient to consider rotation of the condensate about an axis. For such a rotating condensate, an additional term appears in the GPE Hamiltonian, $−\mathbf{Ω} ⋅ \mathbf{L}$, where $\mathbf{Ω}$ is the angular rotation frequency, and $\mathbf{L}$ is the angular momentum operator. Assuming rotation about a single axis, the longitudinal direction $z$, $\mathbf{L}$ can be replaced with $L_z$, giving the form of the GPE in the co-rotating frame as
$$\label{eqn:gpe_rotation}
\textrm{i}\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}) + g\vert\Psi(\textbf{r},t)\vert^2 - \Omega L_z  \right]\Psi(\mathbf{r},t).$$
 Within the Thomas-Fermi approximation, it is possible to determine analytical results for the profile of the BEC, and compare with exact results from numerically integrating the full GPE. However, in the case of a rotating condensate to solve the above form of the Gross–Pitaevskii equation will require numerical integration as the kinetic energy term can no longer be neglected.&lt;/p&gt;

&lt;h3 id=&#34;bogoliubov-de-gennes-equations&#34;&gt;Bogoliubov-de Gennes equations&lt;/h3&gt;

&lt;p&gt;While the Gross–Pitaevskii equation captures the rich array of dynamics exhibited by a condensate system, it is often necessary to examine the stability of its solutions. The previously neglected small quantum fluctuations (see Eq. ) can be included by writing them as a combination of counterpropagating waves as
$$\delta\hat{\Psi} = e^{{-\textrm{i}\mu t/\hbar}}[u(\mathbf{r})e^{-\textrm{i}t\omega} + v^{*}(\mathbf{r})e^{it\omega}].$$
 From this expression, the wavefunction can be written as
$Ψ(\textbf{r}, t)=e^{−\textrm{i}μt / ℏ }[Ψ_0(\textbf{r})+u(\textbf{r})e^{−\textrm{i}tω} + v^*(\textbf{r})e^{\textrm{i}tω}],$
 where $Ψ_0&amp;gt;(\textbf{r})$ is the stationary state solution. Firstly, we calculate the time-derivative of Eq. , which after simplification becomes
$$\label{eqn:bogo_lhs}
    \textrm{i}\hbar\partial_t \Psi(t) = e^{\frac{-\textrm{i}\mu t}{\hbar}}\left[\mu\Psi_0 + (\mu+\hbar\omega)ue^{-\textrm{i}t\omega} + (\mu-\hbar\omega)v^{*}e^{\textrm{i}t\omega} \right],$$
 where the dependence on &lt;strong&gt;r&lt;/strong&gt; is dropped for notational simplicity. Next, the nonlinear interaction term is given as&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned} \label{eqn:bogo_nonlin}
    g|\Psi|^2\Psi &amp;amp;= g\Psi^{*}\Psi\Psi \newline
    &amp;amp;= g e^{\frac{-\textrm{i}\mu t}{\hbar}}(\Psi_0^{*} + u^{*}e^{\textrm{i}t\omega} + ve^{-\textrm{i}t\omega}) \times (\Psi_0 + u e^{-\textrm{i}t\omega} + v^{*} e^{\textrm{i}t\omega})^2, \nonumber \newline
    &amp;amp; \approx g e^{\frac{-\textrm{i}\mu t}{\hbar}}[|\Psi_0|^2(\Psi_0 + 2(u e^{-\textrm{i}t\omega} + v^{*} e^{\textrm{i}t\omega} )) + \Psi_0^2( u^{*} e^{\textrm{i}t\omega} + v e^{-\textrm{i}t\omega})]. \nonumber
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;with the resulting equations linearised in terms of $u$ and $v$. Plugging these terms into the GPE yields the Bogoliubov-de Gennes (BdG) equations,&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \mu \Psi_0 &amp;amp;= (H_0 - \Omega L_z + g |\Psi_0|^2)\Psi_0,\newline
    (\mu +\hbar\omega)u &amp;amp;= (H_0 - \Omega L_z + 2g|\Psi_0|^2)u + g\Psi_0^2 v,\newline
    (\mu -\hbar\omega)v^{*} &amp;amp;= (H_0 - \Omega L_z + 2g|\Psi_0|^2)v^{*} + g\Psi_0^2 u^{*},\end{aligned}$$&lt;/p&gt;

&lt;p&gt;where
$$\label{eqn:bogo_h0}
H_0 = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}).$$
 This can be written in matrix form as
$$\begin{pmatrix}
        H_0 + 2g|\Psi_0|^2- \mu -\Omega L_z &amp;amp; g\Psi_0^2 \newline
        -g\Psi_0^{*2} &amp;amp; -H_0 - 2g|\Psi_0|^2 + \mu +\Omega L_z
    \end{pmatrix}
    \begin{pmatrix}
        u \newline
        v
    \end{pmatrix}
    = \hbar\omega
    \begin{pmatrix}
        u \newline
        v
    \end{pmatrix},$$
 where the eigenvalues of these modes can be used to determine the stability of the system. The norm of these functions is given by $N_\textrm{BdG} = ∫d\textbf{r}(|u|^2 − |v|^2)$. If the norm is positive, with positive eigenvalues, the system is energetically stable. If the norm is positive with negative eigenvalues, the system will have an energetic instability, which will cause the system to move towards the lowest energy state only in the presence of dissipation. If, however, the norm is 0 with imaginary eigenvalues, the modes of the fluctuations are dynamically unstable. Due to the complex eigenvalues these modes will dominate exponentially over time and destroy the initial state of the condensate.&lt;/p&gt;

&lt;h3 id=&#34;lower-dimensional-condensates&#34;&gt;Lower dimensional condensates&lt;/h3&gt;

&lt;p&gt;Whilst the full three dimensional GPE describes the dynamics of a condensed cloud of cold atoms, often the physics of lower dimensional systems can also be quite interesting. For a BEC tightly confined along one axis, the system can be described as a pancake shaped condensate, or cigar shaped for tight confinement along two axes. These tightly confined systems allow for the examination of both two and one dimensional physics. For a BEC harmonically confined in a trap with a transverse frequency, $ω_⊥$, and tightly confined along $z$ with frequency $ω_z ≫ ω_⊥$, all dynamics can be frozen out along $z$, leaving the system in the ground state of the oscillator along $z$. This assumes that the energy to excite the system along $z$, $ℏω_z$ is significantly greater than that to excite along the transverse plane $ℏω_⊥$, and also the chemical potential $μ$. This assumption allows for the wavefunction to be written as $Ψ(\textbf{r}, t)=Ψ(x, y, t)ϕ(z)$ where $Ψ(x, y, t)$ is the transverse wavefunction, and $ϕ(z)=(mω_z / (πℏ))exp(−z^2 m ω_z / (2ℏ))$ is the ground state along $z$. Substituting this separable wavefunction into the GPE and integrating over &lt;em&gt;z&lt;/em&gt; modifies the nonlinear interaction strength as 
$$\label{eqn:g2d_efint}
    g_{\textrm{2D}} = g\sqrt{\frac{m\omega_z}{2\pi\hbar}}.$$
 Though still technically a 3D system, this separation and integration allows one to consider a quasi-2D model, which can be modelled in two-dimensions and which reproduces the main aspects of the same vortex dynamics as a tightly confined three dimensional model. This is advantageous for numerical simulations, but also ensures that only the physics of interest, i.e. in this case the vortex-vortex interactions, play a role. Three dimensional effects, such as the possibility of excitations along the vortex line are removed. The above assumptions have been observed in many experimental systems , and therefore all work and models discussed later will be within the quasi-2D condensate regime, unless otherwise specified.&lt;/p&gt;

&lt;h2 id=&#34;superfluidity&#34;&gt;Superfluidity&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;introduction-to-superfluidity&#34;&gt;Introduction to superfluidity&lt;/h3&gt;

&lt;p&gt;Superfluidity is a macroscopic quantum effect that is closely related to Bose–Einstein condensation. Liquid helium has been known for many years to exhibit superfluid behaviour . One interesting property of superfluids is that they have quantized circulation which can lead to the appearance of quantum vortices under rotation. Traditionally, such excitations have been created in liquid $^4\textrm{He}$ by a “rotating bucket” type of experiment, where the container holding the superfluid is rotated about a single axis. When the fluid is initially above the $λ$-critical point, the temperature at which $^4\textrm{He}$ moves from a classical fluid to a superfluid, the atoms will undergo classical rotation with the container. On cooling the atoms below the $λ$-critical point, liquid $^4\textrm{He}$ will undergo a transition to the superfluid state. If the velocity is above a critical rotation frequency, $Ω_c$, vortices are nucleated in the rotating superfluid helium system. Due to the strongly interacting nature of liquid helium, the nucleated vortices are difficult to visualise as the healing length, $ξ$, of liquid $^4\textrm{He}$ is only on the order of Ångströms.&lt;/p&gt;

&lt;p&gt;In order to visualise these vortices experimentally it was necessary to use an indirect means of visualisation in the form of tracer particles . Limited success was had with this technique using solid hydrogen, and later plastic microspheres, as they tended to join together due to static charges. An improved technique, using charged particles, showed much greater success . Ions, or electrons, were trapped inside the vortex lines, and an electric field along the direction of the lines allowed for acceleration of the charges towards a luminescent screen where they could be observed. Current experimental work in vortex visualisation with liquid $^4\textrm{He}$ has advanced significantly, yet fine control over the behaviour of the liquid and the vortex dynamics remains difficult.&lt;/p&gt;

&lt;p&gt;Superfluid behaviour is observed in liquid helium due partly to a portion of the atoms condensing into the ground state. Given that BECs show superfluidity, the use of a dilute gas where the majority of atoms are in the condensate state provides a more controlled means to investigate superfluidity and quantised vortices . In contrast with liquid $^4\textrm{He}$, which has a healing length of the order of Ångströms, the healing length of a dilute gas of alkali atoms is on the order of microns. This places condensates in a much more accessible regime for visualising vortices compared with liquid $^4\textrm{He}$ experiments. For many condensates visualisation of the vortices is provided by absorption imaging, following a time-of-flight expansion of the cloud which allows the vortex cores to expand and become more easily visible. One drawback of this method is that it is destructive, and requires multiple experimental realisations to acquire any dynamical information. To examine the dynamics of the vortices, successive imaging techniques are required. Single-shot experiments have been demonstrated, where a small percentage of the condensate is repeatedly transferred to an untrapped atomic state. This allows for the untrapped atoms to expand, and vortices have been imaged this way. With this method the precession of the vortices in a trapped condensate can be directly observed, in a single-shot experiment. More recently, &lt;em&gt;in-situ&lt;/em&gt; imaging of a condensate with a vortex lattice was demonstrated and allowed resolution of the cores without time-of-flight expansion with a minimally destructive optical refraction technique.&lt;/p&gt;

&lt;p&gt;To fully understand the behaviour of these systems, it is necessary to have a framework for modeling the condensate, in the absence and the presence of vortices. As described above, a dilute gas of condensed atoms close to absolute zero temperature can be readily modelled by the Gross–Pitaevskii equation, offering a direct means to examine condensate behaviour. It is, however, useful to obtain a hydrodynamic description for the condensate, performed by treating its wave-function as
$$\label{eqn:madelung}
\Psi(\textbf{r},t) = \sqrt{\rho(\mathbf{r},t)} e^{\textrm{i}\theta(\textbf{r},t)},$$
 with
$ρ(\textbf{r}, t)=Ψ^{*}(\textbf{r},t)Ψ(\textbf{r}, t)=|Ψ(\textbf{r}, t)|^2$.
 where $θ(\textbf{r},t)$ is the condensate phase . Multiplying Eq.  by $Ψ^{*}(\textbf{r}, t)$ then subtracting the complex conjugate of that expression allows one to obtain the continuity equation as 
$$\label{eqn:continuity}
\frac{\partial}{\partial t}\rho(\textbf{r},t)  + \nabla\cdot \textbf{j}(\textbf{r},t) = 0,$$
 where the current density of the condensate is
$$\label{eqn:current_density}
\textbf{j}(\textbf{r},t) = \frac{-\textrm{i}\hbar}{2m}\left[\Psi^*(\textbf{r},t)\nabla\Psi(\textbf{r},t) - \Psi(\textbf{r},t)\nabla\Psi^*(\textbf{r},t)\right].$$
 Using ansatz and substituting it into Eq. then gives the form for the current density,
$$\textbf{j}(\textbf{r},t) = \vert\Psi(\textbf{r},t)\vert ^2\frac{\hbar}{m}\nabla\theta(\textbf{r},t).$$
 The velocity of the superfluid, $\textbf{v}(\textbf{r},t)$, is defined as the ratio of the current density to the density, which is then given by
$$\label{eqn:velocity}
\textbf{v}(\textbf{r},t)\equiv \frac{\textbf{j}(\textbf{r},t)}{\rho(\textbf{r},t)} = \frac{\hbar}{m}\nabla\theta(\textbf{r},t).$$
 The gradient of the phase therefore determines the velocity of the condensate atoms; this indicates that the superfluid behaviour in a condensate is irrotational $(∇ × (∇θ)=0)$. Assuming a closed loop integral about a central point in the condensate, and recalling the single-valued nature of the wavefunction, yields the relationship
$$\label{eqn:circulation}
\oint \textbf{v}\cdot d\textbf{l} = \frac{\hbar}{m}2\pi l.$$
 This shows the quantised nature of circulation in a superfluid, with &lt;em&gt;l&lt;/em&gt; representing the integer charge of the circulation. The phase winding around the central region is given by multiples of $2π$, with the centre of the phase becoming ill-defined. To circumvent this problem the density at this point drops to zero, signalling the presence of a vortex in the condensate. This drop happens over the scale of the healing length, which, for repulsive interactions, is given by
$$\xi = \frac{1}{\sqrt{8\pi \rho_b a_s}},$$
 where $ρ_b$ is the bulk density of the condensate, and $a_s$ is the &lt;em&gt;s&lt;/em&gt;-wave scattering length. For a cylindrically symmetric rotating condensate carrying a single vortex in its centre the wavefunction can be written as
$Ψ = |Ψ|e^{\textrm{i}lθ}$,
 where $l$ is the vortex charge. The velocity profile at a distance $r_v$ away from the core can then be given as
$$\label{eqn:1_over_r}
    v =\frac{\hbar l}{m r_v}.$$&lt;/p&gt;

&lt;p&gt;To sustain a vortex the condensate must have sufficient angular momentum, which is imparted via the angular rotation frequency times the angular momentum operator $−ΩL_z$ in the Hamiltonian given by Eq. . The rotation frequency, $Ω$, of the condensate has an upper-bound stability limit equivalent to the transverse trapping frequency, $ω_⊥$, of the harmonically trapped condensate.&lt;/p&gt;

&lt;h3 id=&#34;vortices-in-bose-einstein-condensates&#34;&gt;Vortices in Bose–Einstein condensates&lt;/h3&gt;

&lt;p&gt;Given that the circulation of a vortex in a superfluid is quantised, one may assume that for faster rotation rates the circulation increases in integer multiples of $ h / m$, beyond critical rotation thresholds to excite each higher multiple. To understand the effect of vortex charge on the condensate, it is necessary to examine the energy functional, as given by
$E[Ψ]=∫Ψ^{*}(H_E)Ψd\textbf{r}$,
 where $H_E = (−ℏ^2 /(2m)) ∇^2 + V + g|Ψ|^2 / 2 − ΩL_z$. By substituting into Eq.  the energy functional is given as
$$\label{eqn:functional_full}
    E[\Psi] = \int \frac{\hbar^2}{2m} \left(|\nabla\Psi|^2  + \frac{|\Psi|^2 l^2 m \mathbf{v}^2}{2}  \right) + V|\Psi|^2 + \frac{g}{2}|\Psi|^4 + \Omega \Psi^{*} L_z \Psi,$$
 where &lt;strong&gt;v&lt;/strong&gt; is the superfluid velocity, as given by Eq. . The $l^2$ term shows that the energy scales quadratically with an increase in charge. This energy growth dependence indicates that it will be more favourable to allow for two singly charged vortices, than a single doubly charged vortex, which will decay due to the presence of complex eigenmodes . For rates of rotation $Ω_c &amp;lt; Ω &amp;lt; ω_⊥$, where $Ω_c$, is the threshold rotation rate to create a vortex, the condensate will favour many singly quantised vortices, rather than one or several multiply charged ones. For a superfluid condensate in the rotating frame $Ω_c = E_v / L = E_v /(Nℏ)$, where $E_v$ is the energy of the vortex, and $L$ is the angular momentum component of the superfluid along $z$.&lt;/p&gt;

&lt;p&gt;The stability of vortex states in a condensate is also a widely discussed topic , as non-rotating traps show an instability for small displacements of the vortex from the trap centre. Since the “rotating bucket” technique used to generate vortices in $^4\textrm{He}$ cannot be used for gaseous BECs, many other techniques have been developed . For the work presented in this thesis, the method proposed by Dobrek &lt;em&gt;et al&lt;/em&gt;. , is of particular interest, as it allows one to optically generate vortices by the use of what they term a “phase-imprinting” method. The authors describe a scheme where the phase of the condensate is directly controlled in such a way that the required topological charge to induce a vortex during evolution is provided by external lasers. Through use of an absorption plate whose absorption coefficient depends on the axis angle, the condensate can be imprinted with the required phase pattern. This method will form the basis of one work carried out in this thesis, and will be discussed in detail later in Sec. [sec:phase].&lt;/p&gt;

&lt;h3 id=&#34;vortex-lattices&#34;&gt;Vortex lattices&lt;/h3&gt;

&lt;p&gt;Although a large number of works exist which investigate systems with low numbers of vortices , such systems do not necessarily form periodic vortex lattices. We will therefore concentrate primarily on studies of systems containing many vortices, assuming large values of $Ω ≲ ω_⊥$. For such systems, the vortices are arranged in a periodic triangular Abrikosov lattice, reminiscent of that which appears in type-II superconductors with magnetic flux lines. This triangular lattice configuration is the most energetically favourable and stable arrangement. Experimental setups have demonstrated upwards of over 130 vortices in a well ordered triangular formation. The resulting lattices are shown to be highly stable and are ideal setups for investigations of periodic systems.&lt;/p&gt;

&lt;p&gt;The Thomas–Fermi limit discussed earlier describes the case where the kinetic energy term of the Hamiltonian may be neglected in comparison to the interaction energy, as it offers little contribution to the condensate behaviour. This remains true for low rotation rates, however kinetic energy becomes important in the limit of fast rotation. In this case $Ω / ω_⊥ ≈ 1$, and the centrifugal force term, $mΩ^2r$, almost balances with the trapping force term, $−mω^2r$. The condensate behaviour then closely resembles that of the two-dimensional quantum Hall regime, where the system is residing in the lowest Landau level, (LLL) $(n = 0)$ . As the rotation of the cloud approaches the trapping frequency, the system tends to the LLL, wherein the nonlinear interaction term becomes relatively weak due to the centrifugal forces on the atomic cloud. In this regime the Thomas–Fermi approximation becomes invalid, as the interaction term no longer dominates over the kinetic energy. The interaction energy is then much smaller than the gap between energy levels for single particle Landau levels. While there have been studies using harmonic-plus-quartic potentials to allow condensates to remain trapped beyond the harmonic trapping frequency limit , we will in this thesis consider only systems in a harmonic confinement.&lt;/p&gt;

&lt;p&gt;At high rotation rates very close to the trap frequency $(Ω / ω_⊥≈1)$ the system enters a fractional quantum Hall (FQH) state , and will require treatment beyond that of mean-field methods. This state will require the use of a discrete boson model, which becomes next to impossible to simulate for a realistic number of atoms in a condensate. However, for rotation rates just below this limit a mean-field approach can be used in the so-called “mean-field quantum Hall” (MFQH) regime . The differences between these two regimes are characterised purely by the ratio of the kinetic energy to the interaction energy of the system, and in the MFQH regime we can assume that the LLL has been achieved . To identify these different regimes one may use the the “filling factor”, $ν = N / N_v$ , which examines the ratio of atoms, $N$, to vortices in the system, $N_v$. This becomes an important characteristic at high rotation rates, and in the case where $1000 &amp;gt; ν &amp;gt; 10$, the system may be accurately described to be in the MFQH regime. For values $ν ≤ 10$ the system is said to be strongly correlated , and the system enters the FQH regime. For an almost perfectly regular vortex lattice, the rotation rate must be sufficiently large so that the condensate width extends to large distances and a large number of vortices are generated, without entering the FQH regime . To ensure the applicability of mean-field theory choosing rotational frequencies that guarantee this is important.&lt;/p&gt;

&lt;p&gt;The distribution of the vortices in the MFQH regime forms a triangular lattice pattern that is almost regular . As discussed earlier, the condensate has an irrotational flow profile due to velocity being defined as Eq. . This relation holds true provided that $θ$ is well defined, which is not the case at the centre of a vortex. As the phase at the vortex core is ill-defined, this singular region creates a non-zero curl. A generalisation of the irrotational flow condition (i.e. $∇ × \textbf{v}=0$) to account for this can be given as as 
$$\nabla\times \mathbf{v}=\frac{2\pi l\hbar}{m}\delta^{(2)}(\mathbf{r}_\perp) \hat{z},$$
 where $δ^2$ is a two-dimensional Dirac delta function, $\hat{z}$ is the unit vector along $z$ and $\textbf{r}_⊥=(x, y)$. For large rotation frequencies this value becomes very similar to that of a solid-body rotation, as given by $∇ × \textbf{v} = 2Ω_z$. This result arises for a large regular vortex lattice, where the areal density of vortices can be specified by the Feynman relation 
$$\label{eqn:feynman}
n_{v} = \frac{m\Omega}{\pi\hbar}.$$
 In the case of realistic condensates systems, where the densities are not uniform due to harmonic trapping, deviations exist from this value which have been calculated theoretically and observed experimentally . However, for the values chosen in all later discussed simulations these deviations tend to be small, and can in most cases be neglected.&lt;/p&gt;

&lt;p&gt;Some key details for the classification of the regime of the condensate are :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mean-field theory and experiment agree well for large atom numbers $(N &amp;gt; 10^3)$ and rotational frequencies reaching approximately $0.995ω_⊥$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The density profile of slowly rotating condensates differs very little from that of non-rotating condensates, except for the inclusion of the vortex cores.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Thomas–Fermi regime holds true for frequencies of $0.75 ≤ Ω / ω_⊥ ≤ 0.99$, where kinetic energy remains negligible compared to flow velocity.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The MFQH regime description, holding for $0.99 ≤ Ω / ω_⊥ ≤ 0.999$, sees the vortex cores expanding and forming a densely packed lattice.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given the above criteria, the rapidly rotating condensate system in our work can be described using mean-field Gross–Pitaevskii theory at a rotation rate of $Ω = 0.995ω_⊥$, assuming $N ≈ 10^6$ atoms, as used in typical experimental setups.&lt;/p&gt;

&lt;h2 id=&#34;recent-progress-and-outlook&#34;&gt;Recent progress and outlook&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;Recently there have been many advances in the control of atomic BEC systems. A notable example is the work of Gauthier &lt;em&gt;et&lt;/em&gt; al. , wherein they demonstrate arbitrary optical potential generation for Bose–Einstein condensates through use of digital micromirror devices (DMD). The authors demonstrate high resolution control and patterning of the condensate, and show near perfect control of the condensate atomic distribution. Given the current state of the art high performance imaging and control techniques available, these experimental systems can allow for high precision control and manipulations of the atoms, and therefore also vortices.&lt;/p&gt;

&lt;p&gt;Another recent experimental work of note is that of Wigley &lt;em&gt;et&lt;/em&gt; al. , with a completely automated approach to BEC generation and control. Such automation can allow for much higher throughput of experimental data collection, and allow for a much wider breadth of physics to be explored in condensate systems.&lt;/p&gt;

&lt;p&gt;The current state of the art experimental systems can offer a very high degree of control of condensates, and their ensuing dynamics. In fact, all further methods discussed can be built using currently available state of the art systems, and hence are experimentally realisable.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates: Introduction</title>
      <link>https://mlxd.github.io/post/thesis_intro/</link>
      <pubDate>Sun, 14 Jan 2018 12:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/thesis_intro/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;The purpose of this work is to understand the dynamics of rapidly rotating Bose–Einstein condensates subjected to perturbations, and to develop techniques to control and engineer specific non-equilibrium states. While it is possible to derive some analytical solutions for rapidly rotating condensates (e.g. lowest Landau level approach), such solutions are rare. This thesis concentrates on the numerical solutions of the Gross–Pitaevskii equation, and the resulting dynamics within this framework. It focuses on gaining an understanding of the dynamical behaviour of quantum vortices in an Abrikosov geometry following a perturbation. This body of work was carried out during my time as a Ph.D student at Okinawa Institute of Science and Technology Graduate University (OIST), and grew out of work and ideas I started to pursue at University College Cork (UCC), Ireland.&lt;/p&gt;

&lt;p&gt;Understanding ultracold Abrikosov vortex systems can help with engineering quantum states for future technologies. Ideally, these systems can be used for long-term memory storage in computing applications as individual vortices are topologically protected and, therefore, very robust. They also allow the study of quantum mechanical effects on mesoscopic scales, and the inherent periodicity makes them a promising tool for simulating condensed matter physics. Furthermore, perturbed vortex lattices can be used to investigate turbulent, and possibly chaotic, quantum behaviour. While turbulent classical systems are notoriously hard to understand and control, quantum turbulence is thought to offer a more controllable route to understanding the nature of turbulence, due to the quantisation condition of the circulation. It is therefore of large interest to develop new tools for manipulating and engineering specific states of rotating condensates. In the following work I concentrate on two types of perturbations to the equilibrium state of a rotating condensate: i) the modification of the phonon spectrum of the condensate which does not influence the angular momentum, in particular through the use of a kicked optical potential; ii) the direct control of the topological excitations, and hence the angular momentum, which is performed with direct phase engineering of the condensate wavefunction. I examine both in the above order, and investigate their usefulness in controlling and manipulating condensate dynamics.&lt;/p&gt;

&lt;p&gt;For investigating these perturbances I assume a system of a rapidly rotating BEC having a large number of vortices, arranged in a triangular Abrikosov lattice pattern. This requires the solution of a two-dimensional partial differential equation at high grid resolution with a variety of different initial conditions and controllable perturbations. The solution of the proposed system is a non-trivial numerical problem, and requires the use of advanced numerical computing techniques to allow for results in a reasonable time. For this I make use of graphics processing unit (GPU) computing, and I will discuss the development of such tools, my numerical contributions, and compare them against conventional simulation techniques.&lt;/p&gt;

&lt;p&gt;The thesis is organised as follows:&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;I will first give a brief introduction to the field of cold-atomic gases, and discuss the theoretical framework to describe Bose–Einstein condensation. Emphasis will be placed on material and works relevant to the studies I have performed in this thesis. I will present a derivation of the Gross–Pitaevskii equation, used to model Bose–Einstein condensates, as well as a discussion of the Bogoliubov-de Gennes equations. I will then discuss the hydrodynamic description of the condensate, and give the hydrodynamic form of the Gross–Pitaevskii equation. Here I introduce superfluidity, and the nature of quantised vortices in these systems. I will conclude with an outlook on the cutting edge work in the field in the context of condensate trapping and control.&lt;/p&gt;

&lt;h2 id=&#34;numerical-methods&#34;&gt;Numerical methods&lt;/h2&gt;

&lt;p&gt;In this chapter I will discuss methods for numerically solving the Gross–Pitaevskii equation for simulating the dynamics of Bose–Einstein condensates. The Fourier split-operator method will be introduced, as well as the need for imaginary time evolution, and considerations required to effectively simulate the condensate. Graphics processing unit (GPU) computing will be introduced here, with the implementation of the Gross–Pitaevskii equation discussed. To demonstrate the power of GPU computing we will present and solve a difficult numerical problem, namely the solution of an experimentally realistic situation for a single, ultracold atom on an atomchip, for which the treatment of the fully three-dimensional Schrödinger equation is required. The use of GPU computing makes this problem tractable in realistic times. The work focuses on the area of adiabatic control techniques, and demonstrates the use of GPU computing to describe the long-time dynamics of a system for observing matter-wave spatial adiabatic passage. This work has been published in Phys. Rev. A &lt;strong&gt;88&lt;/strong&gt;, 053618 (2013) .&lt;/p&gt;

&lt;h2 id=&#34;bose-einstein-condensate-dynamics&#34;&gt;Bose–Einstein condensate dynamics&lt;/h2&gt;

&lt;p&gt;In this chapter I will examine the dynamics of Bose–Einstein condensates under rotation, and discuss the methods used for perturbing the condensate system. I begin by introducing the dynamical behaviour of the condensate in the presence of vortices, and introduce a model system used for further discussions. I present the velocity profiles and discuss some of the dynamics a condensate with many vortices is expected to follow. This will be followed by an introduction to the two main perturbation methods for the condensate that I will later use: optical kicking, and phase imprinting. I will also discuss the techniques that I use to analyse the vortex dynamics, concentrating primarily on the kinetic energy spectrum, Delaunay triangulation and Voronoi tessellation.&lt;/p&gt;

&lt;h2 id=&#34;moiré-superlattice-structures&#34;&gt;Moiré superlattice structures&lt;/h2&gt;

&lt;p&gt;Here I investigate effects stemming from the optical kicking of a condensate carrying a vortex lattice. The dynamics of the condensate after a kick with an optical potential of the same geometry as the vortex lattice is demonstrated, and shows little to no deviation of ideal vortex positions. However, the resulting condensate density shows the appearance of a superlattice pattern. I analyse this system, and demonstrate that the resulting superlattice pattern stems from interference between the optical kicking potential and the present vortex lattice in reciprocal space. Moiré interference theory accurately predicts the observed behaviour, and is backed up by examining the kinetic energy spectrum of the condensate. To conclude, I discuss applications of this optical kicking technique and the resulting moiré interference. The results presented in this chapter have been published in Phys. Rev. A &lt;strong&gt;93&lt;/strong&gt;, 023609 (2016) .&lt;/p&gt;

&lt;h2 id=&#34;defect-engineering-of-the-vortex-lattice&#34;&gt;Defect engineering of the vortex lattice&lt;/h2&gt;

&lt;p&gt;To investigate the robustness of a vortex lattice in a rapidly rotating BEC, I will in this chapter discuss the effect of perturbations induced by adding or removing angular momentum through phase imprinting. This technique creates lattice imperfections, with stable topological lattice defects appearing during time evolution. The behaviour of these resulting defects is investigated over long times. I show that the vortex lattice demonstrates highly robust behaviour, even in the presence of such defects. I discuss the use of this method for creating varying degrees of disorder in the lattice, and propose it as a system for investigating transitions from ordered to disordered lattice geometries. The results presented in this chapter have been published in Phys. Rev. A &lt;strong&gt;94&lt;/strong&gt;, 053603 (2016) .&lt;/p&gt;

&lt;h2 id=&#34;conclusions-and-outlook&#34;&gt;Conclusions and outlook&lt;/h2&gt;

&lt;p&gt;In this chapter I conclude the work discussed in the thesis, and discuss extensions, and future ideas for the field.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates: Abstract</title>
      <link>https://mlxd.github.io/post/thesis_abstract/</link>
      <pubDate>Sun, 14 Jan 2018 11:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/thesis_abstract/</guid>
      <description>

&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;span-non-equilibrium-vortex-dynamics-in-rapidly-rotating-bose-einstein-condensates-span&#34;&gt;&lt;span&gt;Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates&lt;/span&gt;&lt;/h3&gt;

&lt;p&gt;This body of work examines the non-equilibrium dynamics of vortex lattice carrying Bose–Einstein condensates. We solve the mean-field Gross–Pitaevskii equation for a two-dimensional pancake geometry, in the co-rotating frame within the limit of high rotation frequencies. The condensate responds to this by creating a large periodic lattice of vortices with 6-fold triangular symmetry. By applying two distinct perturbations to this lattice, we examine the resulting effects on the vortices during time evolution. The first perturbation involves applying an optical potential with matching geometry to the vortex lattice. We observe the appearance of interference fringes, and we show that these can be described by moiré interference theory. This is backed up by a decomposition of the kinetic energy spectra of the condensate. The applied perturbation only modifies the condensate density, with the vortex positions largely unaffected. From this we conclude that the vortex lattice is very stable and robust against phononic disturbances.&lt;/p&gt;

&lt;p&gt;Next, by removing vortices at predefined positions in the lattice using phase imprinting techniques, we examine the resulting order of the lattice. By performing this we generate stable topological defects in the crystal structure. The resulting lattice remains highly ordered in the presence of low numbers of these defects, where crystal structure and order of the lattice shows to be highly robust. By varying the type of imprinted phases we can create controllable degrees of disorder in the lattice. This disorder is analysed using orientational correlations, Delaunay triangulation, and Voronoi diagrams of the vortex lattice, and demonstrates a method for examining order and generating disorder in vortex lattices in Bose–Einstein condensates.&lt;/p&gt;

&lt;p&gt;All work described makes extensive use of GPU computing techniques, and allows for the simulation of these systems to be realised in short times. The implementation of the calculations using GPU computing are also discussed, where the software is shown to be the fastest of its kind out of the independently tested software suites.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 1</title>
      <link>https://mlxd.github.io/post/2015-09-18-quantums/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-18-quantums/</guid>
      <description>

&lt;h1 id=&#34;bose-einstein-condensation&#34;&gt;Bose$-$Einstein condensation&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;This will be a hand-waiving introduction to Bose-Einstein condensate theory. I&amp;rsquo;ll begin by introducing what is a Bose-Einstein condensate, followed by how we model it (hint: we use the Gross-Pitaevskii equation). For more detailed derivations, see Pethick and Smith [ISBN: 978-0521846516] or Pitaevskii and Stringari [ISBN: 978-0198507192].&lt;/p&gt;

&lt;p&gt;Again, this is another work in progress, so expect me to continually dump my thoughts here and on subsequent posts.&lt;/p&gt;

&lt;h2 id=&#34;schrödinger-equation&#34;&gt;Schrödinger equation&lt;/h2&gt;

&lt;p&gt;To understand how we simulate a Bose$-$Einstein condensate, first we must examine the behaviour of the Schrödinger equation. I will assume that you are already familiar with the Schrödinger equation, but if not, I will recommend the usual material:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Principles of Quantum Mechanics, Shankar [ISBN: 978-0306447907]&lt;/li&gt;
&lt;li&gt;Introduction to Quantum Mechanics, Griffiths [ISBN: 978-9332542891]&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;single-particle&#34;&gt;Single particle&lt;/h3&gt;

&lt;p&gt;The single particle Schrödinger equation describes the behaviour of a non-relativistic (i.e. much slower than the speed of light, and/or massless) quantum particle. Firstly, we define our Hamiltonian as&lt;/p&gt;

&lt;p&gt;$$
\hat{H}_0 = -\frac{\hbar^2}{2m} \hat{\nabla}^2 ,
$$&lt;/p&gt;

&lt;p&gt;where $~\hat{H}_0$ corresponds with the momentum-space operator for a free particle. Assuming the particle is trapped by an external potential energy, we can give the following Hamiltonian instead,&lt;/p&gt;

&lt;p&gt;$$
\hat{H}_1 = \hat{H}_0 + \hat{V}_{\textrm{ext}}(\mathbf{r},t).
$$&lt;/p&gt;

&lt;p&gt;Now we have a potential and kinetic term for our system. In cold atomic systems, we nearly always have trapped atoms, by use of an external trapping potential [usually with optical or magnetic fields]. To simulate the dynamics of a single particle in a trapping potential, we use the time dependent Schrödinger equation,&lt;/p&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}{\Psi}(\mathbf{r},t) =  \hat{H}_1 {\Psi}(\mathbf{r},t).
$$&lt;/p&gt;

&lt;h3 id=&#34;many-particle&#34;&gt;Many particle&lt;/h3&gt;

&lt;p&gt;$$
 H_N = \displaystyle\sum\limits_{i=1}^{N} \left(-\frac{\hbar^2}{2m_i} \nabla_i^2 + V_\textrm{ext}(\mathbf{r}_i,t) + \displaystyle\sum_{j\neq i}^{N-1}U(\mathbf{r}_i,\mathbf{r}_j) \right)
$$
Solving this for the ground state is hard, even numerically. The memory requirements grow exponentially as we increase the particle count, as every particle must interact in some way with all the others nearby. Therefore, in order to find the lowest energy state we must &lt;a href=&#34;http://arxiv.org/pdf/1301.2073v1.pdf&#34;&gt;simplify things&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s assume that particles don&amp;rsquo;t interact over long, or even short ranges. What if they can only interact when they occupy the same position, as though $|\mathbf{r}_i - \mathbf{r}_j| = 0$. Also, we can say that the strength of this interaction is dependent upon some parameter, $g$, which depends on properties of the particle. We can also assume that the more particles in a particular region, then the larger the interactions in that specific region. Thus, we can say that these interactions can be approximated by $g\rho(\mathbf{r},t)$, where $\rho$ is the particle density in the region.&lt;/p&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}\hat{\Psi}(\mathbf{r}_1,\dots\mathbf{r}_N,t) = \left[\hat{\Psi}(\mathbf{r}_1,\dots\mathbf{r}_N,t), H_N \right]
$$&lt;/p&gt;

&lt;h2 id=&#34;gp-equation&#34;&gt;GP equation&lt;/h2&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = \left[ -\frac{\hbar^2}{2m} \nabla^2 + V(\mathbf{r},t) + \color{violet}{g\vert\Psi(\mathbf{r},t)\vert^2} -\color{teal}{\mathbf{\Omega}\cdot \mathbf{L} }\right]\Psi(\mathbf{r},t)&lt;br /&gt;
$$&lt;/p&gt;

&lt;h3 id=&#34;madelung-transform&#34;&gt;Madelung transform&lt;/h3&gt;

&lt;p&gt;$$
 \Psi(\mathbf{r},t) = \sqrt{\rho\left(\mathbf{r},t\right)}\exp\left[i\theta\left(\mathbf{r},t\right)\right],
$$
where $$\rho(\mathbf{r},t) = |\Psi\left(\mathbf{r},t\right)|^2$$&lt;/p&gt;

&lt;h3 id=&#34;evolution&#34;&gt;Evolution&lt;/h3&gt;

&lt;p&gt;$$
\Psi(\mathbf{r},t+\delta t) = \exp\left(-\frac{i H}{\hbar}\delta t\right)\Psi(\mathbf{r},t)
$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 2</title>
      <link>https://mlxd.github.io/post/2015-09-20-quantum-vortices/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-20-quantum-vortices/</guid>
      <description>

&lt;h1 id=&#34;quantum-vortices&#34;&gt;Quantum vortices&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Consider, if you will, a bucket of water. We can also do this with a closed bottle of water, to prevent from getting wet, but let&amp;rsquo;s assume we have a bucket. We drop a spoon/stick/paddle in there, and begin to draw a circle, stirring the water. If the item is removed, the water continues to rotate, gradually slowing down before coming to a halt. Let us now assume that the water is spinning quickly, such that a hole develops in the centre. We call this a vortex. As it rotates faster and faster, the vortex increases in size, until we rotate so fast that the water flies out over the edge of the bucket. Hopefully, you have a towel on hand.&lt;/p&gt;

&lt;p&gt;Now, let us assume that we have a really small bucket, namely a &lt;em&gt;quantum bucket&lt;/em&gt;. This quantum bucket, like the normal bucket, holds atoms, but very few of them in comparison. These atoms are also very cold, and form what is known as a [Bose-Einstein condensate](). Now, imagine we have a really small spoon/stick/paddle, and we once again begin to stir. What do we assume will happen?&lt;/p&gt;

&lt;p&gt;Nothing may happen. Otherwise, something strange may happen. Both &lt;em&gt;nothing&lt;/em&gt;, and &lt;em&gt;something strange&lt;/em&gt; are equally interesting. What causes these two separate, yet related, cases is a (not unique) property of Bose-Einstein condensates known as &lt;em&gt;superfluidity&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Let us go back to stirring our condensate. If we stir slowly enough, the condensate will remain stationary. That is to say, it will be as if we were not stirring at all. To allow it rotate, the stirring rate must be above a specific value. This is because, in a superfluid, the circulation occurs in discrete units only. That is to say, it is quantised.&lt;/p&gt;

&lt;p&gt;Unlike a classical fluid, such as water, a condensate cannot accept a continuous range of values with which it rotates. Also, unlike a classical fluid, a superfluid in rotation will continue to rotate without slowing, provided the quantum bucket holds it in place. Beyond the critical value for rotation in a condensate a vortex will be visible. This vortex will not grow or shrink with changes around the critical value, as though a vortex in water might. However, since it does not grow, what happens with faster rotation?&lt;/p&gt;

&lt;p&gt;Since the rotation is quantised, we could assume that beyond another specific value, the vortex might just become wider,  with a circulation of 2 units, instead of just 1. This, however, is not the case (in most cases encountered). Instead of a &lt;em&gt;winding&lt;/em&gt; 2 vortex, we obtain 2 &lt;em&gt;winding&lt;/em&gt; 1 vortices.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 3</title>
      <link>https://mlxd.github.io/post/2015-09-22-tdsim/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-22-tdsim/</guid>
      <description>

&lt;h1 id=&#34;time-dependent-simulations&#34;&gt;Time dependent simulations&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;I will focus on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pseudo-spectral_method&#34;&gt;pseudo-spectral&lt;/a&gt; Fourier split operator (or split step) method.&lt;/p&gt;

&lt;p&gt;Firsly, we need to quantised position space by making a grid over a specific range of position values. Assume $-10$ $\mu$m to $+10$ $\mu$m, giving a grid divided into $xDim=2^8$ equispaced elements. Let us call this grid $\mathbf{x}$, and the maximum value $x_\textrm{max}$. The following Julia code will carry out the above:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;xDim = 2^8; # The resolution of your grid.
xMax = 4e-4;
x = linspace(-xMax, xMax, xDim);
dx = abs(x[2]-x[1]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, so now that we have our grid in position space, we need to also consider generating another grid, this time in &lt;a href=&#34;https://en.wikipedia.org/wiki/Position_and_momentum_space&#34;&gt;momentum space&lt;/a&gt; (also known as reciprocal space, $k$ space). Position and momentum space are related by the Fourier transform.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;kxMax = (2*pi/xMax)*(xDim/2);
kx = circshift(linspace(-kxMax,kxMax,xDim),xDim/2);
dkx = abs(kx[2] - kx[1]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, as you may know, knowledge of position can affect your knowledge of momentum, and vice-versa. In this case, our fundamental limit is defined by the size of our grid dimension, $d$. Just as the wavenumber is given by the relation $k = \frac{2\pi}{\lambda}$, we can obtain our smallest $k$ value using our largest position space value, $x_\textrm{max}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;#Define properties of the system
omegaX = 2*pi*1 # Harmonic trapping potential frequency
hbar = 1.0545718e-34;
m = 1.4431607e-25; #Rb87 mass
a_s = 4.76e-9; #S-wave scattering length
dt = 1e-4; #Timestep

#Make an initial guess
wfc = pdf(Normal(0,xMax/100),x) + 0*im;

#Define the trapping potential and kinetic energy operators
V = 0.5*m*x.^2.*omegaX^2;
K = (0.5*hbar^2/m).*(kx.^2);

GV = exp(-0.5*V*dt/hbar);
GK = exp(-K*dt/hbar);

wfc /= sqrt(sum(abs(wfc).^2)*dx);
for t=1:10000
        wfc = wfc.*GV;
        wfc = ifft(fft(wfc).*GK);
        wfc = wfc.*GV;
        wfc /= sqrt(sum(abs(wfc).^2)*dx);
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;function energy(wfc,dx,V,K)
        EV = V.*wfc;
        EK = ifft(K.*fft(wfc));
        E = conj(wfc).*(EV + EK)
        return real(sum(E)*dx)/hbar
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;e_0 = 1e100 #Arbitrarily large unrealistic value
e_1 = energy(wfc,dx,V,K);

while e_0-e_1 &amp;gt; 1e-7
        push!(E,e_1)
        wfc = wfc.*GV;
        wfc = ifft(fft(wfc).*GK);
        wfc = wfc.*GV;
        wfc /= sqrt(sum(abs(wfc).^2)*dx);
        e_0 = e_1;
        e_1 = energy(wfc,dx,V,K)
        println(e_1)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$$  k_\textrm{max} = \frac{2\pi}{x_\textrm{max}}d $$
n A&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Permutations of n-D data</title>
      <link>https://mlxd.github.io/post/2017-09-04-nd-data/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-09-04-nd-data/</guid>
      <description>&lt;p&gt;Something I have been (occasionally) thinking about for quite a long time is the means to manipulate high-dimensional data-sets (dense grids, specifically), and do so efficiently. Namely, I wish to make the data along any specific orthgonal basis direction to become adjacent in memory by strides of the length of samples along that axis.&lt;/p&gt;

&lt;p&gt;The reason for this? To allow for optimal vectorisation and caching of data when performing computations. Take for example a GPU: if we put data on GPU memory we want to access and manipulate it in chunks given by the chosen thread-size. If we access elements out of order, we essentially lose all of the parallelism offered by the device, as the data access will not be performed in the optimal $n$-element wide chunks, but individually at worst, and somewhere in between most likely.&lt;/p&gt;

&lt;p&gt;For a problem with a Cartesian gridded data set in the space given by $ijk$, we can define the lexicographical order from fastest to slowest indices to be in the $ijk$ order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;for(int k=0; k &amp;lt; k_size; ++k)
    for(int j=0; j &amp;lt; j_size; ++j)
        for(int i=0; i &amp;lt; i_size; ++i)
            data[i + i_size*(j + j_size*k)] = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example, $i$ is the fast index and the axis along which the data is linearly adjacent in memory, and $k$ is the slow axis (with $j$ being slower than fast and faster than slow).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mlxd.github.io/img/ndData.jpg&#34; alt=&#34;alt text&#34; title=&#34;A sample layout permutation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The included image above is an example of rotation about the $j$ axis, showing on the right the respective mappings to new index values (for the sake of my interest I&amp;rsquo;ve taken slices along $j$ and $i$, but worked with the latter for the rest of this discussion).&lt;/p&gt;

&lt;p&gt;The bottom of the image shows the rearrangements of memory from the original (upper) to the rotated (lower) memory configurations. The indices themselves seem to take the following mappings (orig. $\rightarrow $ rot.):&lt;/p&gt;

&lt;p&gt;$$ \begin{align}
i &amp;amp; \rightarrow \textrm{stride}(j)-k, \\&lt;br /&gt;
j &amp;amp; \rightarrow j, \\&lt;br /&gt;
k &amp;amp; \rightarrow i, \
\end{align}$$&lt;/p&gt;

&lt;p&gt;where the stride() operation returns the spacing between the elements in the given dimension (in this case, the stride of $j$ is the size of $i$).&lt;/p&gt;

&lt;p&gt;I intend to find an optimal way to perform this in time. Even suboptimal, but good enough would be fine though.&lt;/p&gt;

&lt;p&gt;L.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FFTs over time and space... and devices</title>
      <link>https://mlxd.github.io/post/2017-07-11-ffts/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-07-11-ffts/</guid>
      <description>

&lt;p&gt;&lt;code&gt;The following article is a work in progress, and will be continually updated over time. I&#39;ll issue a RELEASE tag or similar when everything has been finished.&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;q-how-do-available-fft-routines-compare-over-different-libraries-and-accelerator-hardwares&#34;&gt;Q. How do available FFT routines compare over different libraries and accelerator hardwares?&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;This is something I have wondered for sometime, though it can be difficult for an apples-to-apples comparison. I will consider the above question in relation to the following plan:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Comparing FFT implementations in a pseudospectral solver for linear and nonlinear Schrodinger equation dynamics&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To decide on how to proceed, it is instructive to list all (or most) widely known and used implementations.&lt;/p&gt;

&lt;h2 id=&#34;standard-implementations&#34;&gt;Standard implementations&lt;/h2&gt;

&lt;h3 id=&#34;cpu&#34;&gt;[CPU]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FFTW: &lt;a href=&#34;http://fftw.org/&#34;&gt;http://fftw.org/&lt;/a&gt; and &lt;a href=&#34;https://github.com/FFTW/fftw3&#34;&gt;https://github.com/FFTW/fftw3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MKL-FFT: &lt;a href=&#34;https://software.intel.com/en-us/articles/the-intel-math-kernel-library-and-its-fast-fourier-transform-routines&#34;&gt;https://software.intel.com/en-us/articles/the-intel-math-kernel-library-and-its-fast-fourier-transform-routines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;clFFT: &lt;a href=&#34;https://github.com/clMathLibraries/clFFT&#34;&gt;https://github.com/clMathLibraries/clFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Eigen FFT (using kissfft backend): &lt;a href=&#34;http://eigen.tuxfamily.org/index.php?title=EigenFFT&#34;&gt;http://eigen.tuxfamily.org/index.php?title=EigenFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sFFT: &lt;a href=&#34;http://groups.csail.mit.edu/netmit/sFFT/code.html&#34;&gt;http://groups.csail.mit.edu/netmit/sFFT/code.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KFR FFT: &lt;a href=&#34;https://github.com/kfrlib/fft&#34;&gt;https://github.com/kfrlib/fft&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gpu&#34;&gt;[GPU]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;cuFFT: &lt;a href=&#34;http://docs.nvidia.com/cuda/cufft/index.html&#34;&gt;http://docs.nvidia.com/cuda/cufft/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;clFFT: &lt;a href=&#34;https://github.com/clMathLibraries/clFFT&#34;&gt;https://github.com/clMathLibraries/clFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;fbfft: &lt;a href=&#34;https://github.com/facebook/fbcuda/tree/master/fbfft&#34;&gt;https://github.com/facebook/fbcuda/tree/master/fbfft&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1412.7580&#34;&gt;https://arxiv.org/abs/1412.7580&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cutting-edge&#34;&gt;[Cutting edge]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FPGA FFT (Xilinx and Altera/Intel): &lt;a href=&#34;https://www.xilinx.com/products/intellectual-property/fft.html&#34;&gt;https://www.xilinx.com/products/intellectual-property/fft.html&lt;/a&gt; and &lt;a href=&#34;https://www.altera.com/products/intellectual-property/ip/dsp/m-ham-fft.html&#34;&gt;https://www.altera.com/products/intellectual-property/ip/dsp/m-ham-fft.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IBM TrueNorth FFT: No link/source found (yet)&lt;/li&gt;
&lt;li&gt;Rigetti pyQuil quantum FFT: &lt;a href=&#34;http://pyquil.readthedocs.io/en/latest/getting_started.html&#34;&gt;http://pyquil.readthedocs.io/en/latest/getting_started.html&lt;/a&gt; (currently emulated AFAIK, but will eventually/hopefully run directly on quantum hardware)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;test-cases&#34;&gt;Test cases&lt;/h2&gt;

&lt;p&gt;To ensure sufficient time is spent in the FFT routines I will opt for a 2D transform of an NxN grid, requiring N transforms, a transpose, and another N. The value of N can be scaled to determine sweet spots for all implementations. Granted, memory size will be the determining factor of how large we can go. $N=2^j$ where $j \in \mathbb{Z}, 7 \leq j \leq 11$ is a reasonable range of values to examine that should fit readily on most hardware.&lt;/p&gt;

&lt;p&gt;For this, the following test precisions will be instructive:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;$\mathbb{C}2\mathbb{C}$ - 32-bit float (32-bits for each real and imaginary component)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{C}2\mathbb{C}$ - 64-bit float&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{R}2\mathbb{C}$ - 32-bit float&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{R}2\mathbb{C}$ - 64-bit float&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a sample system to investigate, I will consider the case of a quantum harmonic oscillator (QHO). To investigate dynamics and their resulting accuracy, a known and analytically calculable result is useful. For this, I will opt for a a superposition state of the groundstate along the $xy$ plane, and the first excited state along $x$ with the groundstate along $y$. To put things more formally:&lt;/p&gt;

&lt;p&gt;$$
\Psi(x,y) = \frac{ \Psi_{00}(x,y) + \Psi_{10}(x,y) }{\sqrt{2}}.
$$
To construct the above wavefunction we will assume that the states $\Psi_{00}(x,y)$ and $\Psi_{10}(x,y)$ are outer products of the solutions to the QHO, as given by:&lt;/p&gt;

&lt;p&gt;$$
\Psi_n(x) = \frac{1}{\sqrt{2^{n}n!}}\left(\frac{m\omega_x}{\pi\hbar}\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}}H_n(x),
$$
where $$
H_n(x)=(-1)^n\mathrm{e}^{x^2}\frac{d^n}{dx^n}\left(\mathrm{e}^{-x^2}\right),$$
are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Hermite_polynomials&#34;&gt;physicists&amp;rsquo; Hermite polynomials&lt;/a&gt;. As we are looking for the ground and first excited states ($n=0,1$) we can simplify a lot of the above calculations: $H_0(x)=1$ and $H_0(x)=2x$. Next, we determine the states $\Psi_0(x)$ and $\Psi_1(x)$ as:&lt;/p&gt;

&lt;p&gt;$$ \begin{eqnarray}
\Psi_0(x) = \left(\frac{m\omega_x}{\pi\hbar}\right)^\frac{1}{4}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}},~
\Psi_1(x) = \frac{2x}{\sqrt{2}} \left(\frac{m\omega_x}{\pi\hbar}\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}}.
\end{eqnarray}
$$&lt;/p&gt;

&lt;p&gt;Along a single dimension, our system can potentially be in any of the allowed harmonic oscillator states. Therefore, the overall state is given by a tensor product of the state along $x$ and that along $y$. If we assume the dimensionality of the Hilbert space along the $i$-th orthogonal spacial index is finite and given by $d_i$, then the overall system dimensionality (ie the total number of states we can consider) is $d = \displaystyle\prod_{i} d_i$.&lt;/p&gt;

&lt;p&gt;Assuming an $n$-dimensional system, where each individual dimension is in the groundstate of the harmonic oscillator, we can define the tensor product state as
$$
\Psi_n = \Psi_0^{\otimes n} = \Psi_0 \otimes \Psi_0  \cdots \otimes \Psi_0.
$$&lt;/p&gt;

&lt;p&gt;While the above is fine for a general case, for the purposes of FFTs we have assumed a much simpler system, dealing with combinations of only 2 states. We can then define them as $\Psi_{00}(x,y) = \Psi_{0}(x)\otimes\Psi_{0}(y)$ and $\Psi_{10}(x,y) = \Psi_{1}(x)\otimes\Psi_{0}(y)$. Thus, our final superposition state when filling everything in is given by
$$
\Psi(x,y) = \left(\frac{m}{\pi\hbar}\right)^{\frac{1}{2}}\left(\omega_x\omega_y\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m}{2\hbar}\left(\omega_x x^2 + \omega_y y^2\right)}\left(x + \frac{1}{\sqrt{2}}\right).
$$&lt;/p&gt;

&lt;p&gt;To simplify life, I will assume some of the above quantities are set to unity (i.e. $m=\omega_x = \omega_y = \hbar = 1$). This will not change the dynamics of the simulation, but simplify the equations and the numerical implementation, which can help with improving accuracy. The above equation then becomes
$$
\Psi(x,y) = \left(\frac{1}{\pi}\right)^{\frac{1}{2}}\mathrm{e}^{-\frac{1}{2}\left( x^2 + y^2 \right)}\left(x + \frac{1}{\sqrt{2}}\right).
$$&lt;/p&gt;

&lt;p&gt;For a more detailed explanation and approach to the above have a look at Christina Lee&amp;rsquo;s (&lt;a href=&#34;https://github.com/albi3ro&#34;&gt;albi3ro&lt;/a&gt;) blog post on &lt;a href=&#34;http://albi3ro.github.io/M4//prerequisites%20required/Time-Evolution.html&#34;&gt;time evolution&lt;/a&gt;, which will cover the method I use next.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;To be continued&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/***

This document will implement the quantum simulation aspects of the code, in as simple a means as possible.

***/
#include&amp;lt;stdio.h&amp;gt;
#include&amp;lt;stdlib.h&amp;gt;
#include&amp;lt;math.h&amp;gt;

#define GRIDSIZE 128
#define GRIDMAX 5
#define PI 3.14159
#define DT 1e-4


//################################################//

struct double2{
    double x;
    double y;
};

//Define the grid on which the simulation will be run.
struct Grid{
    double *x = (double*) malloc(GRIDSIZE*sizeof(double));
    double *y = (double*) malloc(GRIDSIZE*sizeof(double));
    double *xy2 = (double*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double));

    double *kx = (double*) malloc(GRIDSIZE*sizeof(double));
    double *ky = (double*) malloc(GRIDSIZE*sizeof(double));
    double *kxy2 = (double*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double));

    double2 *wfc = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
    double2 *U_V = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
    double2 *U_K = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
};

void setupGrids(Grid *grid){
    double invSqrt2 = 1/sqrt(2);
    //Position space grids
    for (int j=0; j &amp;lt; GRIDSIZE; ++j){
        grid-&amp;gt;x[j] = -GRIDMAX + j*(2*GRIDMAX)/((double)GRIDSIZE);
        grid-&amp;gt;y[j] = grid-&amp;gt;x[j];
    }
    for(int i=0; i &amp;lt; GRIDSIZE; ++i){
        for(int j=0; j &amp;lt; GRIDSIZE; ++j){
            grid-&amp;gt;xy2[j+GRIDSIZE*i] = 0.5*(grid-&amp;gt;x[i]*grid-&amp;gt;x[i]+grid-&amp;gt;y[j]*grid-&amp;gt;y[j]);
            //Evolution operator in position space
            grid-&amp;gt;U_V[j+GRIDSIZE*i].x = cos(-grid-&amp;gt;xy2[j+GRIDSIZE*i]*DT);
            grid-&amp;gt;U_V[j+GRIDSIZE*i].y = sin(-grid-&amp;gt;xy2[j+GRIDSIZE*i]*DT);
            
            //Wavefunction
            grid-&amp;gt;wfc[j+GRIDSIZE*i].x = sqrt( 1/PI )*exp( -0.5 * ( grid-&amp;gt;x[i]*grid-&amp;gt;x[i] + grid-&amp;gt;y[j]*grid-&amp;gt;y[j] ) ) * ( grid-&amp;gt;x[i] + invSqrt2 );
            grid-&amp;gt;wfc[j+GRIDSIZE*i].y = 0.;
        }
    }

    //Momentum space grids
    for (int j=0; j &amp;lt; GRIDSIZE; ++j){
        grid-&amp;gt;kx[j] = (j&amp;lt;(GRIDSIZE/2)) ? j*2*PI/(GRIDMAX) : -(GRIDSIZE - j)*(2*PI/(GRIDMAX));
        grid-&amp;gt;ky[j] = grid-&amp;gt;kx[j];
    }
    for(int i=0; i &amp;lt; GRIDSIZE; ++i){
        for(int j=0; j &amp;lt; GRIDSIZE; ++j){
            grid-&amp;gt;kxy2[j+GRIDSIZE*i] = 0.5*(grid-&amp;gt;kx[i]*grid-&amp;gt;kx[i]+grid-&amp;gt;ky[j]*grid-&amp;gt;ky[j]);

            //Evolution operator in momentum space
            grid-&amp;gt;U_K[j+GRIDSIZE*i].x = cos(-grid-&amp;gt;kxy2[j+GRIDSIZE*i]*DT);
            grid-&amp;gt;U_K[j+GRIDSIZE*i].y = sin(-grid-&amp;gt;kxy2[j+GRIDSIZE*i]*DT);
        }
    }
}

//################################################//
int fileIO(Grid *grid){
    //Open files to write
    FILE *f_x = fopen(&amp;quot;x&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_y = fopen(&amp;quot;y&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_xy2 = fopen(&amp;quot;xy2&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_kx = fopen(&amp;quot;kx&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_ky = fopen(&amp;quot;ky&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_kxy2 = fopen(&amp;quot;kxy2&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_U_V = fopen(&amp;quot;U_V&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_U_K = fopen(&amp;quot;U_K&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_wfc = fopen(&amp;quot;wfc&amp;quot;, &amp;quot;w&amp;quot;);

    //No safety checks because I&#39;m a bad person

    fwrite(grid-&amp;gt;x, sizeof(double), GRIDSIZE, f_x);
    fwrite(grid-&amp;gt;y, sizeof(double), GRIDSIZE, f_y);
    fwrite(grid-&amp;gt;xy2, sizeof(double), GRIDSIZE*GRIDSIZE, f_xy2);
    fwrite(grid-&amp;gt;kx, sizeof(double), GRIDSIZE, f_kx);
    fwrite(grid-&amp;gt;ky, sizeof(double), GRIDSIZE, f_ky);
    fwrite(grid-&amp;gt;kxy2, sizeof(double), GRIDSIZE*GRIDSIZE, f_kxy2);
    fwrite(grid-&amp;gt;U_V, sizeof(double2), GRIDSIZE*GRIDSIZE, f_U_V);
    fwrite(grid-&amp;gt;U_K, sizeof(double2), GRIDSIZE*GRIDSIZE, f_U_K);
    fwrite(grid-&amp;gt;wfc, sizeof(double2), GRIDSIZE*GRIDSIZE, f_wfc);

    //No moar opin

    fclose(f_x); fclose(f_y); fclose(f_xy2); fclose(f_kx);  fclose(f_ky);
    fclose(f_kxy2); fclose(f_U_V); fclose(f_U_K); fclose(f_wfc);
    return 0;
}

//################################################//
int main(){
    Grid grid;
    setupGrids(&amp;amp;grid);
    fileIO(&amp;amp;grid);
}


//################################################//

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://mlxd.github.io/img/x_y_kx_ky.png&#34; alt=&#34;alt text&#34; title=&#34;X Y Kx Ky&#34; /&gt;
&lt;img src=&#34;https://mlxd.github.io/img/xy2_kxky2_UV_UK.png&#34; alt=&#34;alt text&#34; title=&#34;Ops&#34; /&gt;
&lt;img src=&#34;https://mlxd.github.io/img/wfc_abs2.png&#34; alt=&#34;alt text&#34; title=&#34;WFC&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Overdue todo</title>
      <link>https://mlxd.github.io/post/2016-05-11-todo/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2016-05-11-todo/</guid>
      <description>&lt;p&gt;Granted I have not published any of the articles I am writing since my initial post, they are still in the works. Unfortunately, they will also  need to wait until my thesis has been written and published (as some of them will be used therein).&lt;/p&gt;

&lt;p&gt;As a snapshot, I will intend to discuss the following topics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GPU acceleration of Schrodinger-like problems using &lt;a href=&#34;https://github.com/mlxd/gpue&#34;&gt;GPUE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Implementing the pseudospectral Fourier split-operator method for time dependent simulations&lt;/li&gt;
&lt;li&gt;An easy introduction to simulation of Bose-Einstein condensates (BECs)&lt;/li&gt;
&lt;li&gt;Numerically solving the Bogoliubov equations for BEC fun&lt;/li&gt;
&lt;li&gt;Playing with vortices in a BEC&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, do not hold your breath for these&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Questions to expand upon</title>
      <link>https://mlxd.github.io/post/2017-07-11-questions/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-07-11-questions/</guid>
      <description>

&lt;h1 id=&#34;questions-to-consider&#34;&gt;Questions to consider&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;What is the optimal choice of FFTs over competing HPC software and device architectures for quantum dynamics using pseduospectral methods?&lt;/li&gt;
&lt;li&gt;Do space filling curves have a performance impact on multidimensional data when performing FFTs along the i-th dimension?&lt;/li&gt;
&lt;li&gt;Is there an optimal way to permute an n-D data set so that the elements along a specific basis direction are linear in memory? Reasons for this are optimal data access when performing operations, allowing for higher cache hits (such as with FFTs on GPUs are an example).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Initiali[sz]e</title>
      <link>https://mlxd.github.io/post/2015-10-17-init/</link>
      <pubDate>Mon, 18 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-10-17-init/</guid>
      <description>

&lt;p&gt;(Original post 2015-10-17; updated 2017-01-18)&lt;/p&gt;

&lt;p&gt;As this is my first post I will keep things simple. Unless otherwise specified, I will be using the following as my default tools.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;editors-ide-cool-things&#34;&gt;Editors/IDE/Cool things&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;ViM (pretty much everything code related)&lt;/li&gt;
&lt;li&gt;Atom (Markdown, text files, and the like)&lt;/li&gt;
&lt;li&gt;Jupyter (IPython, IJulia)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;languages-toolchains&#34;&gt;Languages [toolchains]&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;C/C++ [g++, icc]&lt;/li&gt;
&lt;li&gt;CUDA/OpenCL [nvcc, icc]&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;MATLAB&lt;/li&gt;
&lt;li&gt;Julia&lt;/li&gt;
&lt;li&gt;Mathematica&lt;/li&gt;
&lt;li&gt;Bash/Zsh&lt;/li&gt;
&lt;li&gt;English (occasionally)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;os&#34;&gt;OS&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Arch Linux&lt;/li&gt;
&lt;li&gt;CentOS 7&lt;/li&gt;
&lt;li&gt;OS X 10.12&lt;/li&gt;
&lt;li&gt;Windows 10&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;devices-as-of-2017-01-18&#34;&gt;Devices (as of 2017-01-18)&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Lenovo Thinkpad T430&lt;/li&gt;
&lt;li&gt;Apple MBP (2012)&lt;/li&gt;
&lt;li&gt;Sango cluster @ OIST&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;These lists will be updated to reflect whatever I am using in time. I may make this into a spreadsheet table, so I can tag posts with hardware&amp;hellip; if it makes sense to do so.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
