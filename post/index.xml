<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Lost in Computation</title>
    <link>https://mlxd.github.io/post/</link>
    <description>Recent content in Posts on Lost in Computation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Lee James O&#39;Riordan (mlxd)</copyright>
    <lastBuildDate>Tue, 19 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Thesis</title>
      <link>https://mlxd.github.io/post/thesis/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/thesis/</guid>
      <description>

&lt;p&gt;&lt;span&gt;Thesis submitted for the degree &lt;/span&gt;
&lt;span&gt;Doctor of Philosophy&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;by
&lt;span&gt;February, 2017&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;declaration-of-original-and-sole-authorship&#34;&gt;Declaration of Original and Sole Authorship&lt;/h1&gt;

&lt;p&gt;I, &lt;span&gt;Lee James O’Riordan&lt;/span&gt;, declare that this thesis entitled &lt;em&gt;&lt;span&gt;Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates&lt;/span&gt;&lt;/em&gt; and the data presented in it are original and my own work.&lt;/p&gt;

&lt;p&gt;I confirm that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;This work was done solely while a candidate for the research degree at the Okinawa Institute of Science and Technology Graduate University, Japan and the University College Cork, Ireland.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;No part of this work has previously been submitted for a degree at this or any other university.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;References to the work of others have been clearly attributed. Quotations from the work of others have been clearly indicated, and attributed to them.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In cases where others have contributed to part of this work, such contribution has been clearly acknowledged and distinguished from my own work.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Date: &lt;span&gt;February, 2017&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Signature:&lt;/p&gt;

&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;

&lt;h3 id=&#34;span-non-equilibrium-vortex-dynamics-in-rapidly-rotating-bose-einstein-condensates-span&#34;&gt;&lt;span&gt;Non-equilibrium vortex dynamics in rapidly rotating Bose–Einstein condensates&lt;/span&gt;&lt;/h3&gt;

&lt;p&gt;This body of work examines the non-equilibrium dynamics of vortex lattice carrying Bose–Einstein condensates. We solve the mean-field Gross–Pitaevskii equation for a two-dimensional pancake geometry, in the co-rotating frame within the limit of high rotation frequencies. The condensate responds to this by creating a large periodic lattice of vortices with 6-fold triangular symmetry. By applying two distinct perturbations to this lattice, we examine the resulting effects on the vortices during time evolution. The first perturbation involves applying an optical potential with matching geometry to the vortex lattice. We observe the appearance of interference fringes, and we show that these can be described by moiré interference theory. This is backed up by a decomposition of the kinetic energy spectra of the condensate. The applied perturbation only modifies the condensate density, with the vortex positions largely unaffected. From this we conclude that the vortex lattice is very stable and robust against phononic disturbances.&lt;/p&gt;

&lt;p&gt;Next, by removing vortices at predefined positions in the lattice using phase imprinting techniques, we examine the resulting order of the lattice. By performing this we generate stable topological defects in the crystal structure. The resulting lattice remains highly ordered in the presence of low numbers of these defects, where crystal structure and order of the lattice shows to be highly robust. By varying the type of imprinted phases we can create controllable degrees of disorder in the lattice. This disorder is analysed using orientational correlations, Delaunay triangulation, and Voronoi diagrams of the vortex lattice, and demonstrates a method for examining order and generating disorder in vortex lattices in Bose–Einstein condensates.&lt;/p&gt;

&lt;p&gt;All work described makes extensive use of GPU computing techniques, and allows for the simulation of these systems to be realised in short times. The implementation of the calculations using GPU computing are also discussed, where the software is shown to be the fastest of its kind out of the independently tested software suites.&lt;/p&gt;

&lt;h1 id=&#34;license-and-copyright-information&#34;&gt;License and copyright information&lt;/h1&gt;

&lt;p&gt;The work contained in this thesis includes materials that have been published elsewhere. Notably, Chapters 3, 5 and 6 include figures and text that are published in adapted and original form in the American Physical Society’s journal Physical Review A. Copyright permission has been obtained for use of these figures, and for brevity the copyright notice is given here.&lt;/p&gt;

&lt;h3 id=&#34;chapter-3-numerical-methods&#34;&gt;Chapter 3. Numerical methods&lt;/h3&gt;

&lt;p&gt;Reprinted excerpts and figures with permission from Tadhg Morgan, Lee James O’Riordan, Neil Crowley, Brian O’Sullivan and Thomas Busch, Physical Review A &lt;strong&gt;88&lt;/strong&gt;, 053618 (2013). Copyright (2013) by the American Physical Society.&lt;/p&gt;

&lt;h3 id=&#34;chapter-5-moiré-superlattice-structures&#34;&gt;Chapter 5. Moiré superlattice structures&lt;/h3&gt;

&lt;p&gt;Reprinted excerpts and figures with permission from Lee James O’Riordan, Angela White and Thomas Busch, Physical Review A &lt;strong&gt;93&lt;/strong&gt;, 023609 (2016). Copyright (2016) by the American Physical Society.&lt;/p&gt;

&lt;h3 id=&#34;chapter-6-defect-engineering-of-the-vortex-lattice&#34;&gt;Chapter 6. Defect engineering of the vortex lattice&lt;/h3&gt;

&lt;p&gt;Reprinted excerpts and figures with permission from Lee James O’Riordan, and Thomas Busch, Physical Review A &lt;strong&gt;94&lt;/strong&gt;, 053603 (2016). Copyright (2016) by the American Physical Society.&lt;/p&gt;

&lt;h1 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h1&gt;

&lt;p&gt;/* Firstly, I would like to express my sincerest gratitude to my family back in the ’mel who have always been there for me, and provided amazing support from across the planet since I started my PhD (and before I started too) — most notably, to Mum, Nan, and Maria, who have helped so much over the past few years. Next, my sincerest gratitude and thanks goes to Prof. Thomas Busch, for freeing me from the working world and introducing me to the (ultra)cool world of atomic physics, as well as the guidance he has offered over the years. To past and present members of both the Ultracold Quantum Gases group at University College Cork, and Quantum Systems Unit at OIST, thanks for keeping me sane and helping out through the work and writing over the years — in no particular order: Mossy, Steve, Jeremie, Tara, Albert, Angela, Sawako, Rashi, James, Irina, the magnificent Dave Rea, and of course Tadhg. Next, I would like to thank the Graduate School for all of their help removing bureaucratic dealings from my everyday life here. A special thanks goes to IT &amp;amp; the Scientific Computing Section, for allowing me access to some very amazing toys over these past few years. A special thanks also to Annie, for supplying me with enough caffeine to get to the moon and back. Lastly, but not least-ly, to Christina for her compassion, understanding, and companionship over the past few years. */&lt;/p&gt;

&lt;p&gt;*i*← ありがとうございます!&lt;/p&gt;

&lt;p&gt;&lt;span&gt;
- &lt;span&gt;D&lt;/span&gt;&lt;span&gt;o&lt;/span&gt;&lt;span&gt;o&lt;/span&gt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt; &lt;span&gt;6) [1]&lt;/span&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The purpose of this work is to understand the dynamics of rapidly rotating Bose–Einstein condensates subjected to perturbations, and to develop techniques to control and engineer specific non-equilibrium states. While it is possible to derive some analytical solutions for rapidly rotating condensates (e.g. lowest Landau level approach), such solutions are rare. This thesis concentrates on the numerical solutions of the Gross–Pitaevskii equation, and the resulting dynamics within this framework. It focuses on gaining an understanding of the dynamical behaviour of quantum vortices in an Abrikosov geometry following a perturbation. This body of work was carried out during my time as a Ph.D student at Okinawa Institute of Science and Technology Graduate University (OIST), and grew out of work and ideas I started to pursue at University College Cork (UCC), Ireland.&lt;/p&gt;

&lt;p&gt;Understanding ultracold Abrikosov vortex systems can help with engineering quantum states for future technologies. Ideally, these systems can be used for long-term memory storage in computing applications as individual vortices are topologically protected and, therefore, very robust. They also allow the study of quantum mechanical effects on mesoscopic scales, and the inherent periodicity makes them a promising tool for simulating condensed matter physics. Furthermore, perturbed vortex lattices can be used to investigate turbulent, and possibly chaotic, quantum behaviour. While turbulent classical systems are notoriously hard to understand and control, quantum turbulence is thought to offer a more controllable route to understanding the nature of turbulence, due to the quantisation condition of the circulation. It is therefore of large interest to develop new tools for manipulating and engineering specific states of rotating condensates. In the following work I concentrate on two types of perturbations to the equilibrium state of a rotating condensate: i) the modification of the phonon spectrum of the condensate which does not influence the angular momentum, in particular through the use of a kicked optical potential; ii) the direct control of the topological excitations, and hence the angular momentum, which is performed with direct phase engineering of the condensate wavefunction. I examine both in the above order, and investigate their usefulness in controlling and manipulating condensate dynamics.&lt;/p&gt;

&lt;p&gt;For investigating these perturbances I assume a system of a rapidly rotating BEC having a large number of vortices, arranged in a triangular Abrikosov lattice pattern. This requires the solution of a two-dimensional partial differential equation at high grid resolution with a variety of different initial conditions and controllable perturbations. The solution of the proposed system is a non-trivial numerical problem, and requires the use of advanced numerical computing techniques to allow for results in a reasonable time. For this I make use of graphics processing unit (GPU) computing, and I will discuss the development of such tools, my numerical contributions, and compare them against conventional simulation techniques.&lt;/p&gt;

&lt;p&gt;The thesis is organised as follows:&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;I will first give a brief introduction to the field of cold-atomic gases, and discuss the theoretical framework to describe Bose–Einstein condensation. Emphasis will be placed on material and works relevant to the studies I have performed in this thesis. I will present a derivation of the Gross–Pitaevskii equation, used to model Bose–Einstein condensates, as well as a discussion of the Bogoliubov-de Gennes equations. I will then discuss the hydrodynamic description of the condensate, and give the hydrodynamic form of the Gross–Pitaevskii equation. Here I introduce superfluidity, and the nature of quantised vortices in these systems. I will conclude with an outlook on the cutting edge work in the field in the context of condensate trapping and control.&lt;/p&gt;

&lt;h2 id=&#34;numerical-methods&#34;&gt;Numerical methods&lt;/h2&gt;

&lt;p&gt;In this chapter I will discuss methods for numerically solving the Gross–Pitaevskii equation for simulating the dynamics of Bose–Einstein condensates. The Fourier split-operator method will be introduced, as well as the need for imaginary time evolution, and considerations required to effectively simulate the condensate. Graphics processing unit (GPU) computing will be introduced here, with the implementation of the Gross–Pitaevskii equation discussed. To demonstrate the power of GPU computing we will present and solve a difficult numerical problem, namely the solution of an experimentally realistic situation for a single, ultracold atom on an atomchip, for which the treatment of the fully three-dimensional Schrödinger equation is required. The use of GPU computing makes this problem tractable in realistic times. The work focuses on the area of adiabatic control techniques, and demonstrates the use of GPU computing to describe the long-time dynamics of a system for observing matter-wave spatial adiabatic passage. This work has been published in Phys. Rev. A &lt;strong&gt;88&lt;/strong&gt;, 053618 (2013) .&lt;/p&gt;

&lt;h2 id=&#34;bose-einstein-condensate-dynamics&#34;&gt;Bose–Einstein condensate dynamics&lt;/h2&gt;

&lt;p&gt;In this chapter I will examine the dynamics of Bose–Einstein condensates under rotation, and discuss the methods used for perturbing the condensate system. I begin by introducing the dynamical behaviour of the condensate in the presence of vortices, and introduce a model system used for further discussions. I present the velocity profiles and discuss some of the dynamics a condensate with many vortices is expected to follow. This will be followed by an introduction to the two main perturbation methods for the condensate that I will later use: optical kicking, and phase imprinting. I will also discuss the techniques that I use to analyse the vortex dynamics, concentrating primarily on the kinetic energy spectrum, Delaunay triangulation and Voronoi tessellation.&lt;/p&gt;

&lt;h2 id=&#34;moiré-superlattice-structures&#34;&gt;Moiré superlattice structures&lt;/h2&gt;

&lt;p&gt;Here I investigate effects stemming from the optical kicking of a condensate carrying a vortex lattice. The dynamics of the condensate after a kick with an optical potential of the same geometry as the vortex lattice is demonstrated, and shows little to no deviation of ideal vortex positions. However, the resulting condensate density shows the appearance of a superlattice pattern. I analyse this system, and demonstrate that the resulting superlattice pattern stems from interference between the optical kicking potential and the present vortex lattice in reciprocal space. Moiré interference theory accurately predicts the observed behaviour, and is backed up by examining the kinetic energy spectrum of the condensate. To conclude, I discuss applications of this optical kicking technique and the resulting moiré interference. The results presented in this chapter have been published in Phys. Rev. A &lt;strong&gt;93&lt;/strong&gt;, 023609 (2016) .&lt;/p&gt;

&lt;h2 id=&#34;defect-engineering-of-the-vortex-lattice&#34;&gt;Defect engineering of the vortex lattice&lt;/h2&gt;

&lt;p&gt;To investigate the robustness of a vortex lattice in a rapidly rotating BEC, I will in this chapter discuss the effect of perturbations induced by adding or removing angular momentum through phase imprinting. This technique creates lattice imperfections, with stable topological lattice defects appearing during time evolution. The behaviour of these resulting defects is investigated over long times. I show that the vortex lattice demonstrates highly robust behaviour, even in the presence of such defects. I discuss the use of this method for creating varying degrees of disorder in the lattice, and propose it as a system for investigating transitions from ordered to disordered lattice geometries. The results presented in this chapter have been published in Phys. Rev. A &lt;strong&gt;94&lt;/strong&gt;, 053603 (2016) .&lt;/p&gt;

&lt;h2 id=&#34;conclusions-and-outlook&#34;&gt;Conclusions and outlook&lt;/h2&gt;

&lt;p&gt;In this chapter I conclude the work discussed in the thesis, and discuss extensions, and future ideas for the field.&lt;/p&gt;

&lt;h1 id=&#34;background-1&#34;&gt;Background&lt;/h1&gt;

&lt;p&gt;[chp:background]&lt;/p&gt;

&lt;h2 id=&#34;ultracold-atoms&#34;&gt;Ultracold atoms&lt;/h2&gt;

&lt;h3 id=&#34;cooling-of-atomic-gases&#34;&gt;Cooling of atomic gases&lt;/h3&gt;

&lt;p&gt;One of the major advances in experimental physics towards creating matter in extreme situations has been the cooling of trapped atoms to temperatures near absolute zero. This feat resulted from the pioneering work of C. Cohen-Tannoudji, S. Chu and W. Phillips, and earned them the Nobel Prize in Physics, 1997 . It relies on the use of counter-propagating detuned laser fields which act upon a trapped cloud of atoms. Due to Doppler shifting of the frequencies, atoms moving towards the respective beams see resonant photons, absorb them and slow down due to the momentum absorbed. This is followed by a spontaneous emission in a random direction, for which the recoil kicks average out to zero; hence, the atoms become cooler. This technique is known as “Doppler cooling”. As a result, the atoms eventually reach a velocity below that which no photons can be absorbed from the lasers due to the change in resonance frequency and the limit imposed by the resonance width of the atomic levels, leaving a narrower velocity distribution with a peak at a lower value. Although Doppler cooling allowed temperatures to reach micro-Kelvin regimes, additional techniques, such as evaporative cooling, must be used to obtain atoms deep in the nano-Kelvin temperature range. A further discussion of these cooling methods is presented in . These cooling techniques allow for the creation of Bose–Einstein condensates in dilute atomic gases.&lt;/p&gt;

&lt;h3 id=&#34;introduction-to-bose-einstein-condensation&#34;&gt;Introduction to Bose–Einstein condensation&lt;/h3&gt;

&lt;p&gt;Upon learning of a work by S. N. Bose on the statistical behaviour of photons, A. Einstein translated and arranged for publication of his work, and generalised it to also describe systems of ideal bosons with mass . This led to the Bose–Einstein distribution, which in the framework of the grand canonical ensemble and following the description given by Pitaevskii and Stringari , can be written as
$$\bar{n}_i = \frac{1}{e^{\beta(\epsilon_i - \mu)} -1},$$
 where $\bar{n}_i$ is the average occupation number of the &lt;em&gt;i&lt;/em&gt;-th energy state, *β* = (&lt;em&gt;k&lt;/em&gt;&lt;sub&gt;B&lt;/sub&gt;&lt;em&gt;T&lt;/em&gt;)&lt;sup&gt;−1&lt;/sup&gt; with &lt;em&gt;k&lt;/em&gt;&lt;sub&gt;B&lt;/sub&gt; being the Boltzmann constant and &lt;em&gt;T&lt;/em&gt; the temperature, &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; is the &lt;em&gt;i&lt;/em&gt;-th energy eigenvalue, and &lt;em&gt;μ&lt;/em&gt; is the chemical potential giving the energy required to add an atom to the system for a fixed volume and entropy. The total number of particles in the system, can be evaluated by summing over the individual occupation numbers, as
$$N=\displaystyle\sum_i \bar{n}_i.$$
 This work predicted that non-interacting, indistinguishable bosonic particles would undergo a phase transition below a critical temperature into a new phase in which all particles would occupy the same lowest lying energy state of the system. The number of atoms occupying this lowest lying state, &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, at a given temperature is provided by
$$N_0 \equiv \bar{n}_0 = \frac{1}{e^{\beta(\epsilon_0 - \mu)} - 1},$$
 with &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; representing the lowest energy eigenvalue. Since negative occupation numbers would be a nonphysical result, the chemical potential is limited to values of *μ* &amp;lt; &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;. As &lt;em&gt;μ&lt;/em&gt; tends to &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, the occupation of the lowest energy state grows large. Separating the total number of atoms into the lowest lying (condensed), &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, and higher lying (thermal), &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;T&lt;/em&gt;&lt;/sub&gt;, states as
$$N = N_0 + N_T = N_0 + \displaystyle\sum_{i\neq 0}\bar{n}_i(T,\mu),$$
 allows for a relation for the onset of Bose–Einstein condensation to be given. For a finite temperature system (*T* &amp;gt; 0) this will happen when the temperature drops below a critical value, &lt;em&gt;T&lt;/em&gt;&lt;sub&gt;c&lt;/sub&gt;, where &lt;em&gt;μ&lt;/em&gt; will approach &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;. This results in the macroscopic occupation of the lowest lying state, yielding a Bose–Einstein condensate (BEC).&lt;/p&gt;

&lt;p&gt;Given a cloud of identical bosons at temperatures higher than &lt;em&gt;T&lt;/em&gt;&lt;sub&gt;c&lt;/sub&gt;, the particles behave classically and exhibit hard-core scattering interactions. As they are cooled, their thermal de Broglie wavelength increases as
$$\lambda_{\textrm{dB}} = \sqrt{\frac{\hbar^2}{2\pi mk_{B}T}},$$
 where &lt;em&gt;m&lt;/em&gt; is the atom mass, and the wave-nature of the atoms becomes more prominent. The de Broglie waves start to overlap when &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;dB&lt;/sub&gt;≈ inter-particle separation. The quantity *χ* = *ρ*&lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;dB&lt;/sub&gt;&lt;sup&gt;3&lt;/sup&gt;, where &lt;em&gt;ρ&lt;/em&gt; is the density of the gas, is known as the &lt;em&gt;phase-space density&lt;/em&gt;. Physically this denotes the number of particles present in a box with sides of &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;dB&lt;/sub&gt; length. The phase transition to the condensate sets in at *χ* = &lt;em&gt;ζ&lt;/em&gt;(&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;) ≈ 2.612, where $\zeta(s) = \displaystyle\sum\limits_{n=1}^{\infty}\frac{1}{n^s}$ is the Riemann-Zeta function.  . The value of &lt;em&gt;T&lt;/em&gt;&lt;sub&gt;c&lt;/sub&gt; for this to occur in a uniform gas is given by
$$k_{\textrm{B}}T_{\textrm{c}} = \frac{2\pi}{\zeta\left( 3 / 2 \right)^{&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}}\frac{\hbar^2\rho^{&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}}{m}.$$
 It is worth noting that the above derivation assumes an ideal gas, in which there are no interactions between particles. As this is not the case for most physical systems, one must consider systems where interactions are weak. Fritz London, in 1938, following on from the body of work derived by Einstein and Bose drew the connection between superfluidity in liquid **&lt;sup&gt;4&lt;/sup&gt;He and Bose–Einstein condensation . However, due to the strongly interacting nature of liquid **&lt;sup&gt;4&lt;/sup&gt;He at low temperatures only approximately 10% of the atoms condense into a BEC . In order to achieve the large occupation of the lowest energy state the system must be prepared so that the inter-particle interaction strength does not degrade the coherence, as is the case for liquid **&lt;sup&gt;4&lt;/sup&gt;He.&lt;/p&gt;

&lt;p&gt;Due to their weak interactions, dilute atomic gases are closer to the ideal case discussed by Bose and Einstein. One negative impact, though, were the diluteness requirements and higher masses of most atoms compared to **&lt;sup&gt;4&lt;/sup&gt;He, which required reaching much lower transition temperatures. As such, the use of lighter elements was considered. Spin-polarised hydrogen was one of the first systems to be investigated to create a BEC in the 1970’s. Using trapping and cooling techniques available at the time, this type of system came close, but did not quite reach the required temperatures and phase-space densities for Bose–Einstein condensation to occur until over twenty years later . With the advent of laser cooling in the 1980’s, the use of alkali atoms was considered partly due to the ease of accessibility of their optical transition frequencies. It was not until 1995 that the first BECs were experimentally realised .&lt;/p&gt;

&lt;p&gt;For a finite number of atoms in a realistic experimental scenario, one can consider the case of a BEC trapped in a harmonic oscillator potential. For this finite-sized sample and inhomogeneous density profile, the transition temperature is given by 
$$k_{\textrm{B}}T_{\textrm{c}} = \frac{\hbar\bar{\omega}N^{&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}}{\zeta(3)^{&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}},$$
 where $\bar{\omega}=(\omega_x\omega_y\omega_z)^{&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}$ is the geometric mean of the harmonic oscillator frequencies, and interactions between the particles have been neglected. Critical temperatures for harmonically trapped dilute gases are on the order of nano-Kelvin for experimentally realistic systems.&lt;/p&gt;

&lt;h3 id=&#34;theoretical-description-of-becs-gross-pitaevskii-equation&#34;&gt;Theoretical description of BECs: Gross–Pitaevskii equation&lt;/h3&gt;

&lt;p&gt;We will, in the following section, outline the derivation of the mean-field Gross–Pitaevskii equation, which is widely used to study the behaviour of condensates in many works cited in this review. Following the &lt;em&gt;Les Houches 2013 Lecture Course&lt;/em&gt; by J. Walraven the second quantized form of the many-body Hamiltonian for interacting particles in an external potential is given by
$$\label{eqn:ham2ndq}
\hat{\mathcal{H}} = \hat{H_1} + \hat{H_2} = \int \hat{\Psi}^{\dagger}(\mathbf{r}) H_0\left(\textbf{r},\textbf{p} \right)  \hat{\Psi}(\mathbf{r}) \; d\textbf{r}  + \frac{1}{2} \iint\hat{\Psi}^{\dagger}(\mathbf{r}^\prime)\hat{\Psi}^{\dagger}(\mathbf{r})V_{\textrm{int}}(\textbf{r}^\prime,\textbf{r})\hat{\Psi}(\mathbf{r})\hat{\Psi}(\mathbf{r}^\prime) \; d\textbf{r}^\prime d\textbf{r},$$
 with &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;,&lt;strong&gt;p&lt;/strong&gt;) = &lt;strong&gt;p&lt;/strong&gt;&lt;sup&gt;2&lt;/sup&gt;/(2&lt;em&gt;m&lt;/em&gt;)+&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;) = −(ℏ/2&lt;em&gt;m&lt;/em&gt;)∇&lt;sup&gt;2&lt;/sup&gt; + &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;), and &lt;strong&gt;r&lt;/strong&gt; = (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;, &lt;em&gt;z&lt;/em&gt;). The external potential, &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;) is taken as harmonic, of the form
$$V_{\text{ext}}(\mathbf{r}) = \frac{m}{2}\displaystyle\sum_{i}{\left(\omega_i r_i \right)^2},$$
 where &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; represents the trapping frequency in the &lt;em&gt;i&lt;/em&gt;-th spatial dimension. The interaction potential, &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;int&lt;/sub&gt; is assumed to be point-like as
&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;int&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;,&lt;strong&gt;r&lt;/strong&gt;&lt;sup&gt;′&lt;/sup&gt;) = *g&lt;strong&gt;δ*(&lt;/strong&gt;r&lt;strong&gt;−&lt;/strong&gt;r**&lt;sup&gt;′&lt;/sup&gt;),
 where &lt;em&gt;δ&lt;/em&gt; is the Dirac delta function and the mean-field interaction, &lt;em&gt;g&lt;/em&gt;, is given by
$$g = \frac{4\pi\hbar^2 a_s}{m},$$
 with &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;s&lt;/em&gt;&lt;/sub&gt; being the &lt;em&gt;s&lt;/em&gt;-wave scattering length. Inserting the contact potential Eq. into the second quantised interaction Hamiltonian $\hat{H}_2$ from Eq. above yields the relations&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
\hat{H}_2 &amp;amp;= \frac{g}{2} \int \hat{\Psi}^{\dagger}(\mathbf{r})\hat{\Psi}^{\dagger}(\mathbf{r}^{\prime}) \delta\left(\textbf{r} - \textbf{r}^{\prime}\right)\hat{\Psi}(\mathbf{r}^{\prime})\hat{\Psi}(\textbf{r})d\textbf{r}d\textbf{r}^{\prime} \&lt;br /&gt;
 &amp;amp; = \frac{g}{2}\int \hat{\Psi}^{\dagger}(\textbf{r})\hat{\Psi}^{\dagger}(\mathbf{r}) \hat{\Psi}(\mathbf{r})\hat{\Psi}(\mathbf{r})d\mathbf{r}d\mathbf{r} \&lt;br /&gt;
 &amp;amp; = \frac{g}{2}\int \hat{\Psi}^{\dagger}\left(\mathbf{r}\right)\hat{n}\left(\mathbf{\mathbf{r}}\right)\hat{\Psi}(\mathbf{r})d\textbf{r}.\end{aligned}$$&lt;/p&gt;

&lt;p&gt;In the Heisenberg picture, the evolution of the system is governed by the equation
$$\label{eqn:heisenberg}
\textrm{i}\hbar \frac{d}{d t}\hat{\Psi}_H\left(\mathbf{r}, t\right) = \left[\hat{\Psi}_{H}\left(\mathbf{r}, t\right), \hat{\mathcal{H}}  \right],$$
 where the Heisenberg field annihilation operator, $\hat{\Psi}_H\left(\textbf{r}, t\right)$, is given by
$$\label{eqn:psi_heisenberg}
\hat{\Psi}_H\left(\mathbf{r}, {t} \right) = e^{{\textrm{i}\hat{\mathcal{H}}t / \hbar}}\hat{\Psi}\left(\mathbf{r}\right) e^{{-\textrm{i}\hat{\mathcal{H}}t / \hbar}}.$$
 The operator, $\hat{\Psi}_H$, can be interpreted as the one removing an atom from a given state of the system. Therefore, if all &lt;em&gt;N&lt;/em&gt; atoms in the system are in the ground state, |0&lt;sub&gt;&lt;em&gt;N&lt;/em&gt;&lt;/sub&gt;⟩, as would be the case in an ideal condensate, the following relationship holds&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
\hat{\Psi}_{H}(\mathbf{r},t)\vert 0_N \rangle &amp;amp;= e^{\frac{\textrm{i}E_0(N-1)t}{\hbar}}\hat{\Psi}(\mathbf{r})e^{\frac{-\textrm{i}E_0(N)t}{\hbar}}\vert 0_N \rangle \&lt;br /&gt;
&amp;amp;= \hat{\Psi}(\mathbf{r})e^{\frac{\textrm{i}[E_0(N-1) - E_0(N)]t}{\hbar}} \vert 0_N \rangle \&lt;br /&gt;
&amp;amp;= \hat{\Psi}(\mathbf{r})e^{\frac{-\textrm{i}\mu t}{\hbar}} \vert 0_N \rangle,\label{eqn:psi_dagger_time} $$&lt;/p&gt;

&lt;p&gt;where the chemical potential is defined as *μ* = &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(&lt;em&gt;N&lt;/em&gt;)−&lt;em&gt;E&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(*N* − 1). Using the bosonic commutation relations
$$\begin{aligned}
\left[\hat{\Psi}(\mathbf{r}&amp;lsquo;), \hat{\Psi}^{\dagger}(\mathbf{r})\right] &amp;amp;=&amp;amp; \delta(\mathbf{r}&amp;rsquo; - \mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}&amp;lsquo;), \hat{\Psi}(\mathbf{r})\right] &amp;amp;=&amp;amp; \left[\hat{\Psi}^{\dagger}(\mathbf{r}&amp;lsquo;), \hat{\Psi}^{\dagger}(\mathbf{r})\right] = 0,\end{aligned}$$
 and noting the following relations
$$\begin{aligned}
\left[\hat{\Psi}(\mathbf{r}),\hat{H}_1 \right] &amp;amp; = \hat{H}_0(\mathbf{r},\mathbf{p})\hat{\Psi}(\mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}),\hat{H}_2 \right] &amp;amp; = g\hat{n}(\textbf{r})\hat{\Psi}(\mathbf{r}), \&lt;br /&gt;
\left[\hat{\Psi}(\mathbf{r}),\hat{N} \right] &amp;amp; = \hat{\Psi}(\textbf{r}) ,\end{aligned}$$
 upon substitution of Eq.  into Eq. , it can be rewritten as
$$\label{eqn:almost_gpe}
    \textrm{i} \hbar \frac{d}{d t} \left( \hat{\Psi}(\mathbf{r}) e^{-{\textrm{i}\mu t / \hbar}} \right) = H \hat{\Psi}(\mathbf{r}) e^{-{\textrm{i}\mu t / \hbar}}$$
 with
$$\label{eqn:h_many}
H =  -\frac{\hbar^2}{2m}\nabla^2  + V(\mathbf{r}) + g\hat{n}(\mathbf{r}).$$
 Due to the macroscopic occupation of the lowest lying single-particle state, $\hat{\Psi}$ can be treated as the sum of a condensed term and a quantum fluctuation (uncondensed) term, as
$$\label{eqn:gpe_fluc}
    \hat{\Psi} = \Psi + \delta\hat{\Psi},$$
 where $\Psi = \langle \hat{\Psi} \rangle$ is known as the condensate wavefunction. &lt;em&gt;Ψ&lt;/em&gt; takes the form of a classical field, and can be used to model the behaviour of the condensate, provided the number of atoms is sufficiently large (*N* &amp;gt; 10&lt;sup&gt;3&lt;/sup&gt; for most experimental set-ups) and the correlations are not too strong i.e. the gas is sufficiently dilute that only two-body interactions occur. By substituting Eq.  into , and assuming a condensate at *T* = 0 K, the number of uncondensed atoms will be essentially zero, and thus we can safely ignore all terms in $\delta\hat{\Psi}$ and $\delta\hat{\Psi}^{\dagger}$. The above procedure gives the time dependent mean-field Gross–Pitaevskii equation (GPE) as
$$\label{eqn:gpe}
\textrm{i}\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = H_{\textrm{GP}} \Psi(\textbf{r},t),$$
 with the nonlinear GPE Hamiltonian,
$$\label{eqn:h_gp}
H_{\textrm{GP}} = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\textbf{r}) + g\vert\Psi(\mathbf{r},t)\vert^2 \right],$$
 where &lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;)&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i*μ&lt;strong&gt;t*/ℏ&lt;/sup&gt;. The time independent form can be found by evaluating the left-hand side derivative in and dividing across by &lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−*i&lt;/strong&gt;μ*&lt;em&gt;t&lt;/em&gt;/ℏ&lt;/sup&gt;, yielding
$$\mu\Psi(\mathbf{r}) = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}) + g\vert\Psi(\mathbf{r})\vert^2 \right]\Psi(\mathbf{r}),$$
 where the wavefunction is normalised to the particle number, &lt;em&gt;N&lt;/em&gt;, as follows
$$\label{eqn:norm}
\displaystyle\int\limits_{-\infty}^{\infty}d\mathbf{r} \left\vert \Psi\left(\mathbf{r},t\right) \right\vert^2 = N.$$&lt;/p&gt;

&lt;p&gt;Assuming a large number of bosons in the condensate *N* ≫ 1, the interaction term dominates over the kinetic term of the Hamiltonian which can therefore be neglected. This approximation turns finding the ground state of the system into a solvable, algebraic problem, and is known as the Thomas–Fermi approximation . The Hamiltonian can thus be reduced to a combination of the trapping potential and the mean-field interaction, where the ground state wavefunction, &lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;TF&lt;/sub&gt;, can be determined from the time independent GPE as
$$\Psi_{\textrm{TF}}(\mathbf{r}) = \sqrt{ g^{-1}[\mu - V(\textbf{r})] \Theta(\mu - V(\textbf{r}))},$$
 where &lt;em&gt;μ&lt;/em&gt; is the chemical potential, and &lt;em&gt;Θ&lt;/em&gt; is the Heaviside step function, which ensures that the condensate density does not become negative. The boundary of the cloud is determined by the surface at which the density becomes zero, and corresponds to the point where the trapping potential and chemical potential are equal. This gives the Thomas–Fermi radius along the &lt;em&gt;i&lt;/em&gt;-th direction of the cloud as
$${R}_i = a_{\textrm{}}\left(\frac{15Na_s}{a_{\textrm{}}}\right)^{&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt;}\frac{\bar{\omega}_{\textrm{}}}{\omega_i},$$
 where the characteristic length of the harmonic oscillator is given by ${a} = \sqrt{{\hbar}/{m\bar{\omega}}}$, and
$$\bar{\omega} = \left(\displaystyle\prod\limits_j \omega_j\right)^{&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;},$$
 is the geometric mean of the harmonic oscillator trapping frequencies. This approximation holds valid for stationary condensate solutions.&lt;/p&gt;

&lt;p&gt;To investigate condensate dynamics, it is convenient to consider rotation of the condensate about an axis. For such a rotating condensate, an additional term appears in the GPE Hamiltonian, −&lt;strong&gt;Ω&lt;/strong&gt; ⋅ &lt;strong&gt;L&lt;/strong&gt;, where &lt;strong&gt;Ω&lt;/strong&gt; is the angular rotation frequency, and &lt;strong&gt;L&lt;/strong&gt; is the angular momentum operator. Assuming rotation about a single axis, the longitudinal direction &lt;em&gt;z&lt;/em&gt;, &lt;strong&gt;L&lt;/strong&gt; can be replaced with &lt;em&gt;L&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;, giving the form of the GPE in the co-rotating frame as
$$\label{eqn:gpe_rotation}
\textrm{i}\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = \left[-\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}) + g\vert\Psi(\textbf{r},t)\vert^2 - \Omega L_z  \right]\Psi(\mathbf{r},t).$$
 Within the Thomas-Fermi approximation, it is possible to determine analytical results for the profile of the BEC, and compare with exact results from numerically integrating the full GPE. However, in the case of a rotating condensate to solve the above form of the Gross–Pitaevskii equation will require numerical integration as the kinetic energy term can no longer be neglected.&lt;/p&gt;

&lt;h3 id=&#34;bogoliubov-de-gennes-equations&#34;&gt;Bogoliubov-de Gennes equations&lt;/h3&gt;

&lt;p&gt;While the Gross–Pitaevskii equation captures the rich array of dynamics exhibited by a condensate system, it is often necessary to examine the stability of its solutions. The previously neglected small quantum fluctuations (see Eq. ) can be included by writing them as a combination of counterpropagating waves as
$$\delta\hat{\Psi} = e^{{-\textrm{i}\mu t/\hbar}}[u(\mathbf{r})e^{-\textrm{i}t\omega} + v^{*}(\mathbf{r})e^{it\omega}].$$
 From this expression, the wavefunction can be written as
&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i*μ&lt;strong&gt;t*/ℏ&lt;/sup&gt;[&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(&lt;/strong&gt;r&lt;strong&gt;)+&lt;em&gt;u&lt;/em&gt;(&lt;/strong&gt;r&lt;strong&gt;)&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i*t&lt;/strong&gt;ω*&lt;/sup&gt;+&lt;em&gt;v&lt;/em&gt;&lt;sup&gt;*&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;)&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;i*t&lt;strong&gt;ω*&lt;/sup&gt;],
 where &lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(&lt;/strong&gt;r**) is the stationary state solution. Firstly, we calculate the time-derivative of Eq. , which after simplification becomes
$$\label{eqn:bogo_lhs}
    \textrm{i}\hbar\partial_t \Psi(t) = e^{\frac{-\textrm{i}\mu t}{\hbar}}\left[\mu\Psi_0 + (\mu+\hbar\omega)ue^{-\textrm{i}t\omega} + (\mu-\hbar\omega)v^{*}e^{\textrm{i}t\omega} \right],$$
 where the dependence on &lt;strong&gt;r&lt;/strong&gt; is dropped for notational simplicity. Next, the nonlinear interaction term is given as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
\label{eqn:bogo_nonlin}
    g|\Psi|^2\Psi &amp;amp;= g\Psi^{*}\Psi\Psi \&lt;br /&gt;
    &amp;amp;= g e^{\frac{-\textrm{i}\mu t}{\hbar}}(\Psi_0^{*} + u^{*}e^{\textrm{i}t\omega} + ve^{-\textrm{i}t\omega})\\ &amp;amp;~~~~&lt;del&gt;\times (\Psi_0 + u e^{-\textrm{i}t\omega} + v^{*} e^{\textrm{i}t\omega})^2, \nonumber \&lt;br /&gt;
    &amp;amp; \approx g e^{\frac{-\textrm{i}\mu t}{\hbar}}[|\Psi_0|^2(\Psi_0 + 2(u e^{-\textrm{i}t\omega} + v^{*} e^{\textrm{i}t\omega} )) \\ &amp;amp;&lt;/del&gt;~~~~+ \Psi_0^2( u^{*} e^{\textrm{i}t\omega} + v e^{-\textrm{i}t\omega})]. \nonumber\end{aligned}$$&lt;/p&gt;

&lt;p&gt;with the resulting equations linearised in terms of &lt;em&gt;u&lt;/em&gt; and &lt;em&gt;v&lt;/em&gt;. Plugging these terms into the GPE yields the Bogoliubov-de Gennes (BdG) equations,&lt;/p&gt;

&lt;p&gt;[eqn:bogo_lhsrhs]
$$\begin{aligned}
    \mu \Psi_0 &amp;amp;= (H_0 - \Omega L_z + g |\Psi_0|^2)\Psi_0,\&lt;br /&gt;
    (\mu +\hbar\omega)u &amp;amp;= (H_0 - \Omega L_z + 2g|\Psi_0|^2)u + g\Psi_0^2 v,\&lt;br /&gt;
    (\mu -\hbar\omega)v^{*} &amp;amp;= (H_0 - \Omega L_z + 2g|\Psi_0|^2)v^{*} + g\Psi_0^2 u^{*},\end{aligned}$$&lt;/p&gt;

&lt;p&gt;where
$$\label{eqn:bogo_h0}
H_0 = -\frac{\hbar^2}{2m}\nabla^2 + V(\mathbf{r}).$$
 This can be written in matrix form as
$$\begin{pmatrix}
        H_0 + 2g|\Psi_0|^2- \mu -\Omega L_z &amp;amp; g\Psi_0^2 \&lt;br /&gt;
        -g\Psi_0^{*2} &amp;amp; -H_0 - 2g|\Psi_0|^2 + \mu +\Omega L_z
    \end{pmatrix}
    \begin{pmatrix}
        u \&lt;br /&gt;
        v
    \end{pmatrix}
    = \hbar\omega
    \begin{pmatrix}
        u \&lt;br /&gt;
        v
    \end{pmatrix},$$
 where the eigenvalues of these modes can be used to determine the stability of the system. The norm of these functions is given by &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;BdG&lt;/sub&gt; = ∫*d*&lt;strong&gt;r&lt;/strong&gt;(|&lt;em&gt;u&lt;/em&gt;|&lt;sup&gt;2&lt;/sup&gt; − |&lt;em&gt;v&lt;/em&gt;|&lt;sup&gt;2&lt;/sup&gt;). If the norm is positive, with positive eigenvalues, the system is energetically stable. If the norm is positive with negative eigenvalues, the system will have an energetic instability, which will cause the system to move towards the lowest energy state only in the presence of dissipation. If, however, the norm is 0 with imaginary eigenvalues, the modes of the fluctuations are dynamically unstable. Due to the complex eigenvalues these modes will dominate exponentially over time and destroy the initial state of the condensate.&lt;/p&gt;

&lt;h3 id=&#34;lower-dimensional-condensates&#34;&gt;Lower dimensional condensates&lt;/h3&gt;

&lt;p&gt;Whilst the full three dimensional GPE describes the dynamics of a condensed cloud of cold atoms, often the physics of lower dimensional systems can also be quite interesting. For a BEC tightly confined along one axis, the system can be described as a pancake shaped condensate, or cigar shaped for tight confinement along two axes. These tightly confined systems allow for the examination of both two and one dimensional physics. For a BEC harmonically confined in a trap with a transverse frequency, &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, and tightly confined along &lt;em&gt;z&lt;/em&gt; with frequency &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; ≫ &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, all dynamics can be frozen out along &lt;em&gt;z&lt;/em&gt;, leaving the system in the ground state of the oscillator along &lt;em&gt;z&lt;/em&gt;. This assumes that the energy to excite the system along &lt;em&gt;z&lt;/em&gt;, ℏ&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; is significantly greater than that to excite along the transverse plane ℏ&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, and also the chemical potential &lt;em&gt;μ&lt;/em&gt;. This assumption allows for the wavefunction to be written as &lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;, &lt;em&gt;t&lt;/em&gt;)&lt;em&gt;ϕ&lt;/em&gt;(&lt;em&gt;z&lt;/em&gt;) where &lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;, &lt;em&gt;t&lt;/em&gt;) is the transverse wavefunction, and &lt;em&gt;ϕ&lt;/em&gt;(&lt;em&gt;z&lt;/em&gt;)=(*m&lt;strong&gt;ω*&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;/(*π*ℏ))exp(−&lt;em&gt;z&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;*m&lt;/strong&gt;ω*&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;/(2ℏ)) is the ground state along &lt;em&gt;z&lt;/em&gt;. Substituting this separable wavefunction into the GPE and integrating over &lt;em&gt;z&lt;/em&gt; modifies the nonlinear interaction strength as 
$$\label{eqn:g2d_efint}
    g_{\textrm{2D}} = g\sqrt{\frac{m\omega_z}{2\pi\hbar}}.$$
 Though still technically a 3D system, this separation and integration allows one to consider a quasi-2D model, which can be modelled in two-dimensions and which reproduces the main aspects of the same vortex dynamics as a tightly confined three dimensional model. This is advantageous for numerical simulations, but also ensures that only the physics of interest, i.e. in this case the vortex-vortex interactions, play a role. Three dimensional effects, such as the possibility of excitations along the vortex line are removed. The above assumptions have been observed in many experimental systems , and therefore all work and models discussed later will be within the quasi-2D condensate regime, unless otherwise specified.&lt;/p&gt;

&lt;h2 id=&#34;superfluidity&#34;&gt;Superfluidity&lt;/h2&gt;

&lt;h3 id=&#34;introduction-to-superfluidity&#34;&gt;Introduction to superfluidity&lt;/h3&gt;

&lt;p&gt;Superfluidity is a macroscopic quantum effect that is closely related to Bose–Einstein condensation. Liquid helium has been known for many years to exhibit superfluid behaviour . One interesting property of superfluids is that they have quantized circulation which can lead to the appearance of quantum vortices under rotation. Traditionally, such excitations have been created in liquid **&lt;sup&gt;4&lt;/sup&gt;He by a “rotating bucket” type of experiment, where the container holding the superfluid is rotated about a single axis. When the fluid is initially above the &lt;em&gt;λ&lt;/em&gt;-critical point, the temperature at which **&lt;sup&gt;4&lt;/sup&gt;He moves from a classical fluid to a superfluid, the atoms will undergo classical rotation with the container. On cooling the atoms below the &lt;em&gt;λ&lt;/em&gt;-critical point, liquid **&lt;sup&gt;4&lt;/sup&gt;He will undergo a transition to the superfluid state. If the velocity is above a critical rotation frequency, &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt;, vortices are nucleated in the rotating superfluid helium system. Due to the strongly interacting nature of liquid helium, the nucleated vortices are difficult to visualise as the healing length, &lt;em&gt;ξ&lt;/em&gt;, of liquid **&lt;sup&gt;4&lt;/sup&gt;He is only on the order of ngstr&lt;span&gt;ö&lt;/span&gt;ms .&lt;/p&gt;

&lt;p&gt;In order to visualise these vortices experimentally it was necessary to use an indirect means of visualisation in the form of tracer particles . Limited success was had with this technique using solid hydrogen, and later plastic microspheres, as they tended to join together due to static charges. An improved technique, using charged particles, showed much greater success . Ions, or electrons, were trapped inside the vortex lines, and an electric field along the direction of the lines allowed for acceleration of the charges towards a luminescent screen where they could be observed. Current experimental work in vortex visualisation with liquid **&lt;sup&gt;4&lt;/sup&gt;He has advanced significantly , yet fine control over the behaviour of the liquid and the vortex dynamics remains difficult.&lt;/p&gt;

&lt;p&gt;Superfluid behaviour is observed in liquid helium due partly to a portion of the atoms condensing into the ground state. Given that BECs show superfluidity, the use of a dilute gas where the majority of atoms are in the condensate state provides a more controlled means to investigate superfluidity and quantised vortices . In contrast with liquid **&lt;sup&gt;4&lt;/sup&gt;He, which has a healing length of the order of ngstr&lt;span&gt;ö&lt;/span&gt;ms, the healing length of a dilute gas of alkali atoms is on the order of microns . This places condensates in a much more accessible regime for visualising vortices compared with liquid **&lt;sup&gt;4&lt;/sup&gt;He experiments. For many condensates visualisation of the vortices is provided by absorption imaging, following a time-of-flight expansion of the cloud to allow the vortex cores to expand and become more easily visible . One drawback of this method is that it is destructive, and requires multiple experimental realisations to acquire any dynamical information. To examine the dynamics of the vortices, successive imaging techniques are required. Single-shot experiments have been demonstrated, where a small percentage of the condensate is repeatedly transferred to an untrapped atomic state. This allows for the untrapped atoms to expand, and vortices have been imaged this way . With this method the precession of the vortices in a trapped condensate can be directly observed, in a single-shot experiment. More recently, &lt;em&gt;in-situ&lt;/em&gt; imaging of a condensate with a vortex lattice was demonstrated and allowed resolution of the cores without time-of-flight expansion with a minimally destructive optical refraction technique .&lt;/p&gt;

&lt;p&gt;To fully understand the behaviour of these systems, it is necessary to have a framework for modeling the condensate, in the absence and the presence of vortices. As described above, a dilute gas of condensed atoms close to absolute zero temperature can be readily modelled by the Gross–Pitaevskii equation , offering a direct means to examine condensate behaviour. It is, however, useful to obtain a hydrodynamic description for the condensate, performed by treating its wave-function as
$$\label{eqn:madelung}
\Psi(\textbf{r},t) = \sqrt{\rho(\mathbf{r},t)} e^{\textrm{i}\theta(\textbf{r},t)},$$
 with
&lt;em&gt;ρ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;Ψ&lt;/em&gt;&lt;sup&gt;*&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=|&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)|&lt;sup&gt;2&lt;/sup&gt;.
 where &lt;em&gt;θ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) is the condensate phase . Multiplying Eq.  by &lt;em&gt;Ψ&lt;/em&gt;&lt;sup&gt;*&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) then subtracting the complex conjugate of that expression allows one to obtain the continuity equation as 
$$\label{eqn:continuity}
\frac{\partial}{\partial t}\rho(\textbf{r},t)  + \nabla\cdot \textbf{j}(\textbf{r},t) = 0,$$
 where the current density of the condensate is
$$\label{eqn:current_density}
\textbf{j}(\textbf{r},t) = \frac{-\textrm{i}\hbar}{2m}\left[\Psi^*(\textbf{r},t)\nabla\Psi(\textbf{r},t) - \Psi(\textbf{r},t)\nabla\Psi^*(\textbf{r},t)\right].$$
 Using ansatz and substituting it into Eq. then gives the form for the current density,
$$\textbf{j}(\textbf{r},t) = \vert\Psi(\textbf{r},t)\vert ^2\frac{\hbar}{m}\nabla\theta(\textbf{r},t).$$
 The velocity of the superfluid, &lt;strong&gt;v&lt;/strong&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;), is defined as the ratio of the current density to the density, which is then given by
$$\label{eqn:velocity}
\textbf{v}(\textbf{r},t)\equiv \frac{\textbf{j}(\textbf{r},t)}{\rho(\textbf{r},t)} = \frac{\hbar}{m}\nabla\theta(\textbf{r},t).$$
 The gradient of the phase therefore determines the velocity of the condensate atoms; this indicates that the superfluid behaviour in a condensate is irrotational (∇ × (∇&lt;em&gt;θ&lt;/em&gt;)=0). Assuming a closed loop integral about a central point in the condensate, and recalling the single-valued nature of the wavefunction, yields the relationship
$$\label{eqn:circulation}
\oint \textbf{v}\cdot d\textbf{l} = \frac{\hbar}{m}2\pi l.$$
 This shows the quantised nature of circulation in a superfluid, with &lt;em&gt;l&lt;/em&gt; representing the integer charge of the circulation. The phase winding around the central region is given by multiples of 2&lt;em&gt;π&lt;/em&gt;, with the centre of the phase becoming ill-defined. To circumvent this problem the density at this point drops to zero, signalling the presence of a vortex in the condensate. This drop happens over the scale of the healing length, which, for repulsive interactions, is given by
$$\xi = \frac{1}{\sqrt{8\pi \rho_b a_s}},$$
 where &lt;em&gt;ρ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;b&lt;/em&gt;&lt;/sub&gt; is the bulk density of the condensate, and &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;s&lt;/em&gt;&lt;/sub&gt; is the &lt;em&gt;s&lt;/em&gt;-wave scattering length. For a cylindrically symmetric rotating condensate carrying a single vortex in its centre the wavefunction can be written as
*Ψ* = |&lt;em&gt;Ψ&lt;/em&gt;|&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;i*l*&lt;em&gt;θ&lt;/em&gt;&lt;/sup&gt;,
 where &lt;em&gt;l&lt;/em&gt; is the vortex charge. The velocity profile at a distance &lt;em&gt;r&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; away from the core can then be given as
$$\label{eqn:1_over_r}
    v =\frac{\hbar l}{m r_v}.$$&lt;/p&gt;

&lt;p&gt;To sustain a vortex the condensate must have sufficient angular momentum, which is imparted via the angular rotation frequency times the angular momentum operator −*Ω*&lt;em&gt;L&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; in the Hamiltonian given by Eq. . The rotation frequency, &lt;em&gt;Ω&lt;/em&gt;, of the condensate has an upper-bound stability limit equivalent to the transverse trapping frequency, &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, of the harmonically trapped condensate.&lt;/p&gt;

&lt;h3 id=&#34;vortices-in-bose-einstein-condensates&#34;&gt;Vortices in Bose–Einstein condensates&lt;/h3&gt;

&lt;p&gt;Given that the circulation of a vortex in a superfluid is quantised, one may assume that for faster rotation rates the circulation increases in integer multiples of &lt;em&gt;h&lt;/em&gt;/&lt;em&gt;m&lt;/em&gt;, beyond critical rotation thresholds to excite each higher multiple. To understand the effect of vortex charge on the condensate, it is necessary to examine the energy functional, as given by
&lt;em&gt;E&lt;/em&gt;[&lt;em&gt;Ψ&lt;/em&gt;]=∫&lt;em&gt;Ψ&lt;/em&gt;&lt;sup&gt;*&lt;/sup&gt;(&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;E&lt;/sub&gt;)*Ψ&lt;strong&gt;d&lt;/strong&gt;*r&lt;strong&gt;,
 where &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;E&lt;/sub&gt; = ( − ℏ&lt;sup&gt;2&lt;/sup&gt;/2&lt;em&gt;m&lt;/em&gt;)∇&lt;sup&gt;2&lt;/sup&gt; + *V* + &lt;em&gt;g&lt;/em&gt;|&lt;em&gt;Ψ&lt;/em&gt;|&lt;sup&gt;2&lt;/sup&gt;/2 − *Ω&lt;/strong&gt;L*&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;. By substituting into Eq.  the energy functional is given as
$$\label{eqn:functional_full}
    E[\Psi] = \int \frac{\hbar^2}{2m} \left(|\nabla\Psi|^2  + \frac{|\Psi|^2 l^2 m \mathbf{v}^2}{2}  \right) + V|\Psi|^2 + \frac{g}{2}|\Psi|^4 + \Omega \Psi^{*} L_z \Psi,$$
 where &lt;strong&gt;v&lt;/strong&gt; is the superfluid velocity, as given by Eq. . The &lt;em&gt;l&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; term shows that the energy scales quadratically with an increase in charge. This energy growth dependence indicates that it will be more favourable to allow for two singly charged vortices, than a single doubly charged vortex, which will decay due to the presence of complex eigenmodes . For rates of rotation &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt; &amp;lt; *Ω* &amp;lt; &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, where &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt;, is the threshold rotation rate to create a vortex, the condensate will favour many singly quantised vortices, rather than one or several multiply charged ones. For a superfluid condensate in the rotating frame &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;/*L* = &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;/(*N*ℏ), where &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; is the energy of the vortex, and &lt;em&gt;L&lt;/em&gt; is the angular momentum component of the superfluid along *z* .&lt;/p&gt;

&lt;p&gt;The stability of vortex states in a condensate is also a widely discussed topic , as non-rotating traps show an instability for small displacements of the vortex from the trap centre. Since the “rotating bucket” technique used to generate vortices in **&lt;sup&gt;4&lt;/sup&gt;He cannot be used for gaseous BECs, many other techniques have been developed . For the work presented in this thesis, the method proposed by Dobrek &lt;em&gt;et al&lt;/em&gt;. , is of particular interest, as it allows one to optically generate vortices by the use of what they term a “phase-imprinting” method. The authors describe a scheme where the phase of the condensate is directly controlled in such a way that the required topological charge to induce a vortex during evolution is provided by external lasers. Through use of an absorption plate whose absorption coefficient depends on the axis angle, the condensate can be imprinted with the required phase pattern. This method will form the basis of one work carried out in this thesis, and will be discussed in detail later in Sec. [sec:phase].&lt;/p&gt;

&lt;h3 id=&#34;vortex-lattices&#34;&gt;Vortex lattices&lt;/h3&gt;

&lt;p&gt;Although a large number of works exist which investigate systems with low numbers of vortices , such systems do not necessarily form periodic vortex lattices. We will therefore concentrate primarily on studies of systems containing many vortices, assuming large values of *Ω* ≲ &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;. For such systems, the vortices are arranged in a periodic triangular Abrikosov lattice, reminiscent of that which appears in type-II superconductors with magnetic flux lines . This triangular lattice configuration is the most energetically favourable and stable arrangement . Experimental setups have demonstrated upwards of over 130 vortices in a well ordered triangular formation. The resulting lattices are shown to be highly stable and are ideal setups for investigations of periodic systems .&lt;/p&gt;

&lt;p&gt;The Thomas–Fermi limit discussed earlier describes the case where the kinetic energy term of the Hamiltonian may be neglected in comparison to the interaction energy, as it offers little contribution to the condensate behaviour. This remains true for low rotation rates, however kinetic energy becomes important in the limit of fast rotation. In this case &lt;em&gt;Ω&lt;/em&gt;/&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; ≈ 1, and the centrifugal force term, *m&lt;strong&gt;Ω*&lt;sup&gt;2&lt;/sup&gt;&lt;em&gt;r&lt;/em&gt;, almost balances with the trapping force term, −*m&lt;/strong&gt;ω*&lt;sup&gt;2&lt;/sup&gt;&lt;em&gt;r&lt;/em&gt;. The condensate behaviour then closely resembles that of the two-dimensional quantum Hall regime, where the system is residing in the lowest Landau level, (LLL) (*n* = 0) . As the rotation of the cloud approaches the trapping frequency, the system tends to the LLL, wherein the nonlinear interaction term becomes relatively weak due to the centrifugal forces on the atomic cloud. In this regime the Thomas–Fermi approximation becomes invalid, as the interaction term no longer dominates over the kinetic energy. The interaction energy is then much smaller than the gap between energy levels for single particle Landau levels. While there have been studies using harmonic-plus-quartic potentials to allow condensates to remain trapped beyond the harmonic trapping frequency limit , we will in this thesis consider only systems in a harmonic confinement.&lt;/p&gt;

&lt;p&gt;At high rotation rates very close to the trap frequency (&lt;em&gt;Ω&lt;/em&gt;/&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; ≈ 1) the system enters a fractional quantum Hall (FQH) state , and will require treatment beyond that of mean-field methods. This state will require the use of a discrete boson model, which becomes next to impossible to simulate for a realistic number of atoms in a condensate. However, for rotation rates just below this limit a mean-field approach can be used in the so-called “mean-field quantum Hall” (MFQH) regime . The differences between these two regimes are characterised purely by the ratio of the kinetic energy to the interaction energy of the system, and in the MFQH regime we can assume that the LLL has been achieved . To identify these different regimes one may use the the “filling factor”, *ν* = &lt;em&gt;N&lt;/em&gt;/&lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; , which examines the ratio of atoms, &lt;em&gt;N&lt;/em&gt;, to vortices in the system, &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;. This becomes an important characteristic at high rotation rates, and in the case where 1000 &amp;gt; *ν* &amp;gt; 10, the system may be accurately described to be in the MFQH regime. For values *ν* ≤ 10 the system is said to be strongly correlated , and the system enters the FQH regime. For an almost perfectly regular vortex lattice, the rotation rate must be sufficiently large so that the condensate width extends to large distances and a large number of vortices are generated, without entering the FQH regime . To ensure the applicability of mean-field theory choosing rotational frequencies that guarantee this is important.&lt;/p&gt;

&lt;p&gt;The distribution of the vortices in the MFQH regime forms a triangular lattice pattern that is almost regular . As discussed earlier, the condensate has an irrotational flow profile due to velocity being defined as Eq. . This relation holds true provided that &lt;em&gt;θ&lt;/em&gt; is well defined, which is not the case at the centre of a vortex. As the phase at the vortex core is ill-defined, this singular region creates a non-zero curl. A generalisation of the irrotational flow condition (i.e. ∇ × &lt;strong&gt;v&lt;/strong&gt; = 0) to account for this can be given as as 
$$\nabla\times \mathbf{v}=\frac{2\pi l\hbar}{m}\delta^{(2)}(\mathbf{r}_\perp) \hat{z},$$
 where &lt;em&gt;δ&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; is a two-dimensional Dirac delta function, $\hat{z}$ is the unit vector along &lt;em&gt;z&lt;/em&gt; and &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;⊥&lt;/sub&gt; = (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;). For large rotation frequencies this value becomes very similar to that of a solid-body rotation, as given by ∇ × &lt;strong&gt;v&lt;/strong&gt; = 2&lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;. This result arises for a large regular vortex lattice, where the areal density of vortices can be specified by the Feynman relation 
$$\label{eqn:feynman}
n_{v} = \frac{m\Omega}{\pi\hbar}.$$
 In the case of realistic condensates systems, where the densities are not uniform due to harmonic trapping, deviations exist from this value which have been calculated theoretically and observed experimentally . However, for the values chosen in all later discussed simulations these deviations tend to be small, and can in most cases be neglected.&lt;/p&gt;

&lt;p&gt;Some key details for the classification of the regime of the condensate are :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mean-field theory and experiment agree well for large atom numbers (*N* &amp;gt; 10&lt;sup&gt;3&lt;/sup&gt;) and rotational frequencies reaching approximately 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The density profile of slowly rotating condensates differs very little from that of non-rotating condensates, except for the inclusion of the vortex cores.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Thomas–Fermi regime holds true for frequencies of 0.75 ≤ &lt;em&gt;Ω&lt;/em&gt;/&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; ≤ 0.99, where kinetic energy remains negligible compared to flow velocity.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The MFQH regime description, holding for 0.99 ≤ &lt;em&gt;Ω&lt;/em&gt;/&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; ≤ 0.999, sees the vortex cores expanding and forming a densely packed lattice.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given the above criteria, the rapidly rotating condensate system in our work can be described using mean-field Gross–Pitaevskii theory at a rotation rate of *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, assuming *N* ≈ 10&lt;sup&gt;6&lt;/sup&gt; atoms, as used in typical experimental setups.&lt;/p&gt;

&lt;h2 id=&#34;recent-progress-and-outlook&#34;&gt;Recent progress and outlook&lt;/h2&gt;

&lt;p&gt;Recently there have been many advances in the control of atomic BEC systems. A notable example is the work of Gauthier &lt;em&gt;et&lt;/em&gt; al. , wherein they demonstrate arbitrary optical potential generation for Bose–Einstein condensates through use of digital micromirror devices (DMD). The authors demonstrate high resolution control and patterning of the condensate, and show near perfect control of the condensate atomic distribution. Given the current state of the art high performance imaging and control techniques available, these experimental systems can allow for high precision control and manipulations of the atoms, and therefore also vortices.&lt;/p&gt;

&lt;p&gt;Another recent experimental work of note is that of Wigley &lt;em&gt;et&lt;/em&gt; al. , with a completely automated approach to BEC generation and control. Such automation can allow for much higher throughput of experimental data collection, and allow for a much wider breadth of physics to be explored in condensate systems.&lt;/p&gt;

&lt;p&gt;The current state of the art experimental systems can offer a very high degree of control of condensates, and their ensuing dynamics. In fact, all further methods discussed can be built using currently available state of the art systems, and hence are experimentally realisable.&lt;/p&gt;

&lt;h1 id=&#34;numerical-methods-1&#34;&gt;Numerical methods&lt;/h1&gt;

&lt;p&gt;Numerical solutions to problems in quantum physics are important, given the limited availability of exact solutions. Many such models and methods exist when dealing with many-body systems, and have been shown to provide good estimates of physical behaviour . Techniques such as Monte Carlo methods, exact diagonalisation, and DMRG are used to solve a wide variety of many-body problems, but often fail to capture the full system dynamics of such problems . For understanding the behaviour of systems such as Bose–Einstein condensates, the use of these methods is rather limited. For DMRG, the complexity of the problem grows quickly with increasing dimensionality and renders this technique unusable. Exact diagonalisation requires a linearised system to obtain realistic solutions, and also grows significantly in complexity with increased dimensionality. Monte Carlo methods generally do not allow for real-time dynamics, or allow one to calculate the underlying wavefunction.&lt;/p&gt;

&lt;p&gt;To obtain solutions to BEC problems we make use of a mean-field approach, outlined previously in Sec. [sub:gpederiv]. Using the GPE and performing a numerical integration allows for almost all examinable dynamics that are valid in the mean-field limit. It can be noted though that the computational cost increases significantly with increased dimensions, and is already non-trivial for two-dimensions. The following chapter will introduce the necessary requirements to numerically solve quantum problems using state-of-the-art computational methods.&lt;/p&gt;

&lt;p&gt;We will begin with an introduction to the time evolution of a quantum state. We then discuss the use of the time evolution approach to find the ground state of a quantum system using imaginary time evolution. After this necessary mathematical introduction we will discuss the implementation of both real and imaginary time evolution using the Fourier split-operator (split-step) algorithm. We give error bounds for the algorithm, and discuss its use in the context of solving for Hamiltonian dynamics. Though the discussed algorithm is well suited to solving quantum dynamics, the computational cost can be quite high, especially for systems with large grid sizes.&lt;/p&gt;

&lt;p&gt;We next discuss ways to overcome this through the use of high performance computing methods, and introduce the concept of graphical processing unit (GPU) computing. We present many of the necessary considerations for mapping a computational problem onto GPUs. Making use of GPUs to numerically solve the Schrödinger equation with the Fourier split-operator method, we present the problem of coherent atomic transport. We introduce the “matter-wave spatial adiabatic passage” technique, with the goal of coherently transporting an atom between trapping potentials with high fidelity. The design of the model system is presented, and the results are shown.&lt;/p&gt;

&lt;p&gt;We finish the chapter by introducing the developed algorithms for condensate systems. Performance metrics and considerations are given in the context of solving the Gross–Pitaevskii equation in the presence of vortices.&lt;/p&gt;

&lt;h2 id=&#34;time-evolution&#34;&gt;Time evolution&lt;/h2&gt;

&lt;p&gt;Given a quantum state, to examine the dynamics requires an understanding of how it evolves in time. Assuming a quantum state at time &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; to be defined as |&lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;)⟩, and a state at time &lt;em&gt;t&lt;/em&gt; to be |&lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;)⟩, the two states can be connected with a unitary evolution operator as
|&lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;)⟩ = 𝒰(&lt;em&gt;t&lt;/em&gt;, &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;)|&lt;em&gt;Ψ&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;)⟩, 
 where we have assumed that *t* &amp;gt; &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;. One can write the wavefunction of a quantum system as the linear superposition of a set of basis states |&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;m&lt;/em&gt;&lt;/sub&gt;⟩ as
$$\label{eqn:psicomplete}
    |\Psi \rangle = \displaystyle\sum\limits_{m} C_m |\Psi_m \rangle,$$
 with coefficients &lt;em&gt;C&lt;/em&gt;&lt;sub&gt;&lt;em&gt;m&lt;/em&gt;&lt;/sub&gt;. The unitary evolution operator can be written as
$$\begin{aligned}
   \mathscr{U}(t,t_0) &amp;amp;= \exp\left(-\frac{i\mathcal{H}(t - t_0)}{\hbar} \right) \\ &amp;amp;= \exp\left(\frac{-\text{i}\mathcal{H}\delta t}{\hbar}\right),\end{aligned}$$
$$\begin{aligned}
   \mathscr{U}(t,t_0) &amp;amp;= \exp\left(-\frac{i}{\hbar}\displaystyle\int\limits_{t_0}^{t}\mathcal{H}\text{d}t\right),\end{aligned}$$
 where ℋ is the Hamiltonian of the system, and *δ**t* = *t* − &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;. The effect of 𝒰(&lt;em&gt;t&lt;/em&gt;, &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;) on any arbitrary state can be examined by expanding it as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
        \mathscr{U}(t,t_0) &amp;amp;= 1 - \frac{\textrm{i}\mathcal{H}\delta t}{\hbar} + \mathcal{O}(\delta t^2) \&lt;br /&gt;
        &amp;amp;= 1 - \frac{\textrm{i}\delta t}{\hbar}{\displaystyle\sum\limits_{n} E_n |\Psi_n\rangle \langle \Psi_n |} + \mathcal{O}(\delta t^2),
    \end{aligned}$$&lt;/p&gt;

&lt;p&gt;where the Hamiltonian operator has been written as a complete set of energy eigenkets, ℋ|&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;⟩=&lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;|&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;⟩. Applying this to gives&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
        |\Psi (t) \rangle &amp;amp;= \left( 1 - \frac{\textrm{i}\delta t}{\hbar}\displaystyle\sum\limits_{n}E_n|\Psi_n\rangle\langle \Psi_n |  \right)\displaystyle\sum\limits_{m} C_m |\Psi_m \rangle \&lt;br /&gt;
            &amp;amp;= \displaystyle\sum\limits_{m} C_m |\Psi_m \rangle + \displaystyle\sum\limits_{n}\left( - \frac{\textrm{i}\delta t}{\hbar}E_n \right) C_n|\Psi_n\rangle,
    \end{aligned}$$&lt;/p&gt;

&lt;p&gt;where terms of order 𝒪(*δ*&lt;em&gt;t&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) and higher have been temporarily left out for notational simplicity, but are still included in the analysis. Time evolving the state from &lt;em&gt;t&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; to a final time &lt;em&gt;t&lt;/em&gt; by applying the evolution operator can then be written as
$$\mathscr{U}(t,t_0)|\Psi(t_0) \rangle = \displaystyle\sum\limits_{n} C_n \exp\left(\frac{-\textrm{i}{E_n}\delta t}{\hbar}\right)|\Psi_n \rangle.$$
 It follows from here that each state oscillates at a different rate, proportional to its eigenenergy; higher energy states will oscillate faster than those of lower energy. For a given set of states the dynamics and evolution of the quantum system can be fully determined for all times using the above evolution operation.&lt;/p&gt;

&lt;p&gt;As systems will prefer to reside in the lowest energy state where they are most stable, it is often required to determine the ground state solution of a particular Hamiltonian. A common method for this is by evolving the system in imaginary time. Taking the evolution operator, and applying a Wick rotation rotates the time component through &lt;em&gt;π&lt;/em&gt;/2 into the imaginary plane, as *t* → −*i&lt;strong&gt;t*. This new evolution operator applied to the wavefunction gives
$$\mathscr{U^{&amp;lsquo;}}(t,t_0)|\Psi \rangle = \displaystyle\sum\limits_{n} C_n \exp\left(\frac{-{E_n}\delta t}{\hbar}\right)|\Psi_n \rangle.$$
 This process removes the complex term in the operator, which now takes the form of sums of exponentially decaying states. When applied to the wavefunction the higher energy terms will decay at a rate faster than lower energy components increasing *δ&lt;/strong&gt;t*. This process also causes a loss of probability density, and so the wavefunction must be renormalised after each application. Through repeated application of this operator, and a renormalisation afterwards, the simulated quantum system converges to the ground state solution. To begin, however, we must make an initial guess for the wavefunction, which has some finite overlap with the lowest lying state. It should be noted that this method is a mathematical trick used to obtain a simulated ground state, with a real-world system only tending to the ground state in the presence of some form of dissipation. As effective as this technique is, the convergence to the lowest lying energy state becomes less effective as the computation approaches the expected value , and if many eigenstates are lying close to each other. To ensure the system converges to a sufficient degree the resulting energy can be checked after each iteration, and the evolution stopped only when the energy change fluctuates about a stable value.&lt;/p&gt;

&lt;p&gt;With the time evolution method introduced, we will next discuss implementing this method. Although many such algorithms exist to implement time evolution, one that is well suited for this task is the Fourier split-operator method. This method works equally for real, as well as imaginary, time evolution.&lt;/p&gt;

&lt;h2 id=&#34;fourier-split-operator-method&#34;&gt;Fourier split-operator method&lt;/h2&gt;

&lt;p&gt;The Gross–Pitaevskii equation is a second order nonlinear partial differential equation, and so very few exact solutions exist; the problem must often be tackled by a numerical approach. Though there are many ways to solve such a system numerically, with the Crank–Nicolson and Trotter–Suzuki algorithms being notable examples, the method we have chosen is the pseudospectral Fourier split-operator method, described below .&lt;/p&gt;

&lt;p&gt;If we consider a unitary evolution operator of the form
$$\label{eqn:1}
\Psi(\mathbf{x},t+\tau) = \exp\left( -\frac{\text{i}\hat{H}\tau}{\hbar}\right)\Psi(\mathbf{x},t),$$
 where $\hat{H}$ is the Hamiltonian, composed of momentum, potential, nonlinear interaction, and rotation terms defined in Eq. , we can solve for the wavefunction and its resulting dynamics over a specified timescale, assuming &lt;em&gt;τ&lt;/em&gt; is a short time increment such that the formalism given in Sec. [sec:timeev] is valid. Care must be taken during the implementation of such integration methods, as the loss of precision due to floating-point rounding, as well as the propagation of errors cannot be neglected. If we take $\hat{H}$ in terms of its components as a combination of position and momentum space operators we obtain
$$\label{eqn:2}
\hat{H} = \hat{H}_{\textbf{r}} + \hat{H}_{\textbf{k}} + \hat{H}_{\textbf{L}},$$
 where we first ignore the angular momentum operator, $\hat{H}_{\textbf{L}}$, and consider only the two other non-commuting parts, $\hat{H}_{\textbf{r}}$, containing the operators acting in position space, and $\hat{H}_{\textbf{k}}$, containing the operators acting in momentum space only. The Baker–Campbell–Hausdorf formula gives the relation for non-commuting operators as
$$\exp\left( \tau(A+B) \right) = \exp\left(\tau A\right)\exp\left(\tau B\right)\exp\left(-\frac{\tau^2}{2}[A,B] + \cdots\right),$$
 with ⋯ representing higher order commutators. This is directly mappable to the above Hamiltonian for time evolution. Due to the non-commutativity of $\hat{H}_{\textbf{r}}$ and $\hat{H}_{\textbf{k}}$, the above expression cannot be evaluated exactly, and so it is common to Taylor expand and truncate it. The resulting error can be determined as&lt;/p&gt;

&lt;p&gt;[eqn:error_calc]
$$\begin{aligned}
    \text{err} = \left\| \exp\left(-\frac{\textrm{i}\hat{H}_{\textbf{k}}\tau}{\hbar}\right)\exp\left(-\frac{\textrm{i}\hat{H}_{\textbf{r}}\tau}{\hbar}\right) - \exp\left(-\frac{\textrm{i}(\hat{H}_{\textbf{k}} + \hat{H}_{\textbf{r}})\tau}{\hbar}\right) \right\| \&lt;br /&gt;
    = \left\|  \left(1 + \left(\frac{-\textrm{i}\hat{H}_{\textbf{k}}}{\hbar}\right)\tau + \left(\frac{-\textrm{i}\hat{H}_{\textbf{k}}}{\hbar}\right)^2\frac{\tau^2}{2}  \right)\left(1 + \left(\frac{-\textrm{i}\hat{H}_{\textbf{r}}}{\hbar}\right)\tau + \left(\frac{-\textrm{i}\hat{H}_{\textbf{r}}}{\hbar}\right)^2\frac{\tau^2}{2}  \right) \right. &amp;amp;- \nonumber \\ \left. \left(1 + \left(\frac{-\textrm{i}(\hat{H}_{\textbf{r}} + \hat{H}_{\textbf{r}})}{\hbar}\right)\tau + \left(\frac{-\textrm{i}(\hat{H}_{\textbf{r}} + \hat{H}_{\textbf{r}})}{\hbar}\right)^2\frac{\tau^2}{2}  \right)  + \mathcal{O}(\tau^3) \right\|,\end{aligned}$$&lt;/p&gt;

&lt;p&gt;which, upon simplification reduces to
$$\text{err} = \left\| \frac{\tau^2[{\hat{H}_{\textbf{r}}},{\hat{H}_{\textbf{k}}}]}{2\hbar^2} + \mathcal{O}(\tau^3)\right\| = \mathcal{O}(\tau^2).$$&lt;/p&gt;

&lt;p&gt;The error can be further reduced through the use of 2**&lt;sup&gt;nd&lt;/sup&gt; order Strang splitting , taking the error in the numerical integration scheme to 𝒪(&lt;em&gt;τ&lt;/em&gt;&lt;sup&gt;3&lt;/sup&gt;), with the resulting operator implementation given as&lt;/p&gt;

&lt;p&gt;$$\label{eqn:3}
\exp\left( -\frac{ \textrm{i}\left(\hat{H}_{\textbf{r}} + \hat{H}_{\textbf{k}}\right)\tau}{\hbar} \right) = \exp\left(- \frac{\textrm{i}\hat{H}_{\textbf{r}}\tau}{2\hbar} \right)\exp\left(-\frac{\textrm{i}\hat{H}_{\textbf{k}}\tau}{\hbar}\right)\exp\left( -\frac{\textrm{i}\hat{H}_{\textbf{r}}\tau}{2\hbar}\right) + \mathcal{O}\left(\tau^3\right).$$&lt;/p&gt;

&lt;p&gt;In the case of a nonlinear system, such as for solving the GPE, the above scheme attains a second-order error, resulting from the combination of the potential and nonlinear terms, with the respective mapping as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
\hat{H}_{\textbf{r}} &amp;amp;= V(\mathbf{r}) + g\vert\Psi(\mathbf{r},t)\vert^2, \\ \hat{H}_{\textbf{k}} &amp;amp;= \frac{-\hbar^2}{2m}\nabla^2.
    \end{aligned}$$&lt;/p&gt;

&lt;p&gt;Following Bauke &lt;em&gt;et al&lt;/em&gt;. , we can numerically solve this differential equation as
$$\label{eqn:baukeetal}
\Psi\left(\textbf{r},t+\tau\right) = \left[\hat{U}_{\mathbf{r}}\left(\frac{\tau}{2}\right) \mathscr{F}^{-1} \left[ \hat{U}_{\mathbf{k}}(\tau) \mathscr{F} \left[ \hat{U}_{\mathbf{r}}\left(\frac{\tau}{2}\right) \Psi\left(\mathbf{r},t\right) \right] \right] \right]  \\ + \mathcal{O}\left(\tau^2\right),$$
 where $\hat{U}_{\mathbf{r}}(\tau)=e^{-\textrm{i}\hat{H}_{\mathbf{r}}t/\hbar}$ is the time evolution operator in position space, $\hat{U}_{\mathbf{k}}(\tau)=e^{-i\hat{H}_{\mathbf{k}}t/\hbar}$ the time evolution operator in momentum space, and ℱ and ℱ&lt;sup&gt;−1&lt;/sup&gt; are the forward and inverse Fourier transform respectively. Taking the Fourier transform of the wavefunction allows the basis to be transformed between position and reciprocal space, wherein the time evolution operators are diagonal in each respective space. Figure [fig:num_splitop] outlines a schematic representation of the method during a single pass of the algorithm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./ch3_numerics/splitop&#34; alt=&#34;A single pass through the Fourier split-operator method.&amp;lt;span data-label=&amp;quot;fig:num_splitop&amp;quot;&amp;gt;&amp;lt;/span&amp;gt;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The underlying theory of the Fourier split-operator method for the Gross–Pitaevskii equation is given by Javanainen &lt;em&gt;et al&lt;/em&gt;. , showing how the choice of nonlinearity and operator splitting affects the outcome of the method. By taking the initial step as evolution in momentum space, the choice of the most current wavefunction attains an error of third-order for the algorithm. However, this will require an additional two Fourier transform steps, and as such is rather costly in compute time for large systems. For an initial step in position space, the nonlinear term is best calculated using a linear combination of all available wavefunctions through the algorithm as *Ψ* = &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; + &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; + &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;em&gt;Ψ&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt;, where the subscripts denote the wavefunction at each stage of the evolution in position space, as indicated in Fig. [fig:num_splitop], and the &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;x&lt;/sub&gt; are linear coefficients. This gives third order accuracy for the parameters &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt; = ±1, &lt;em&gt;c&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt; = −&lt;em&gt;c&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;. However, for simplicity and resource limitations we chose to work with the 𝒪(&lt;em&gt;τ&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) accurate scheme as depicted by Eq. , which was sufficient for the physics we aimed to describe.&lt;/p&gt;

&lt;p&gt;An implementation of this method is a straight-forward process using MATLAB, and has been performed for the purpose of this study. However, due to the computational overhead required to time-evolve such a system, the procedure takes a long time to simulate at the required degree of accuracy for any dimension greater than one. Therefore, it is necessary to further develop the methods used, and to improve the implementation of this algorithm to leverage the recent advances in computational acceleration.&lt;/p&gt;

&lt;h3 id=&#34;resolution-considerations&#34;&gt;Resolution considerations&lt;/h3&gt;

&lt;p&gt;As the Fourier split-operator method requires special consideration of resolution in both position and momentum space, care must be taken while choosing numerical grids. The reciprocal relationship between position and momentum space is
$$k_{\text{max}} = \frac{2\pi}{\Delta x},$$
 which follows directly from the uncertainty relation; better resolution in one space leads naturally to worse in the other. To allow for a condensate to be simulated efficiently in both spaces, it must fit within the grid on which it is defined, and resolve to at least half the size of the smallest structure. It is easy to estimate a radius for the position space wavefunction, following the Thomas–Fermi approximation. It is also rather easy to know that for a non-rotating condensate the wavefunction should occupy the lowest lying mode (&lt;strong&gt;k&lt;/strong&gt; = 0), and those close to it, assuming a harmonic trap. Rotating the condensate, however, has the effect of expanding the wavefunction in position space due to centrifugal forces. Additionally, the momentum space wavefunction also expands with increased angular momentum. With the addition of vortices to the system, there are now small scale structures to resolve. This leads to a system that is difficult to simulate; we have a simultaneously growing position space and momentum space wavefunction.&lt;/p&gt;

&lt;p&gt;For a grid to effectively sample the wavefunction and capture all dynamics it will require a sampling rate of at least twice the smallest feature size following the Nyquist sampling theorem . From this it is essential to have a large and finely sampled grid in order to resolve both position and momentum of the wavefunction, with all included features. For the simulations presented below a minimum grid size on the order of 2&lt;sup&gt;8&lt;/sup&gt; = 256 for low rotation rates, to 2&lt;sup&gt;11&lt;/sup&gt; = 2048 at high rotation rates in 2D for both &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;Y&lt;/em&gt; dimensions is necessary to correctly resolve the system dynamics in both position and momentum space with vortices present. One such way of ensuring accurate resolution of the system is to define a sufficient smallest length scale on one such grid (such as position). By ensuring the position grid remains defined with the same lowest increment, it is possible to increase resolution in the reciprocal space with a larger grid. As vortex core sizes are on the order of *μ*m, the above parameters allow between sub-*μ&lt;strong&gt;m* (2&lt;sup&gt;10&lt;/sup&gt; and above) to few *μ&lt;/strong&gt;m* resolution. This also holds true for features in &lt;strong&gt;k&lt;/strong&gt;-space. Computationally, this can be costly, but quite effective when using compute accelerators (GPUs), which we will introduce next.&lt;/p&gt;

&lt;h2 id=&#34;parallel-computing&#34;&gt;Parallel computing&lt;/h2&gt;

&lt;p&gt;As the dimensionality of a problem increases, so often too does the time required for performing simulations. One method for accelerating numerical solutions involves the use of multiple compute cores on a central processing unit (CPU) operating independently on different data elements in unison. This form of parallel computation can be achieved through the use of the OpenMP (Open Multi-Processing) application programming interface (API), which defines how a program may parallelise certain elements of code. It allows the developer to fully utilise the power of a multicore processor. However, the limit on how much performance can be gained by this method is set by the number of compute cores available to the system, as well as the limited support offered by compilers. It should also be noted that &lt;span style=&#34;font-variant:small-caps;&#34;&gt;MATLAB&lt;/span&gt; has inherent support for such programming paradigms, and fully abstracts the implementation from the developer. In this instance writing a program from scratch in C/C++/Python/etc. for such a means of parallelisation may not be very beneficial due to the cost of diminishing returns; results would likely be obtained much faster from simply using a multicore supported package, provided that one includes the time to write, as well as simulate. However, this is not always the case, given that the size of problems can often require more cores than available on a single machine.&lt;/p&gt;

&lt;p&gt;Another widely used programming paradigm that gets around this CPU core limitation is that of MPI (message passing interface). Where OpenMP allows a user to utilise all available processing cores on a single system, MPI allows the use of an (almost) unlimited number of networked computer systems operating in parallel together, each known as a node. This is the method generally preferred in programs written for compute clusters, where a large number of nodes are available to use. It is the preferable choice for distributed computing applications, with the best performance gains given if there is minimal dependence between data. A bottleneck may occur if data spread over multiple nodes is required for an operation, requiring continual transmission of data between individual nodes. At current data rates this would be limited to bus speeds (assuming an Infiniband optical connection) on the order of tens of gigabytes per second. Compared to a local calculation requiring few to no transfers, the memory bandwidth (data quantity transferred between RAM and CPU per second) can be as high as 60 gigabytes per second . It is important to note that transfers should be minimised to avoid bottlenecks, but transfers are often necessary to make use of the large number of processing cores. Therefore, to give a significant performance benefit, a large number of cores, a high memory bandwidth, a high-speed interconnect between cores (nodes), as well as sufficient space to store the problem in memory are required.&lt;/p&gt;

&lt;p&gt;One means of achieving the required high performance is through the use of graphics processing units (GPUs). GPUs are signal processing devices created to offload from the central processing unit (CPU) much of the heavy computation required for displaying two and three-dimensional graphics. As a result, GPUs have been given the task of performing operations necessary to update a large number of pixels in a short amount of time, as well as complex 3D mathematics for image rendering. This has been achieved by giving the GPUs a large number of specialised compute cores for floating-point arithmetic, effectively operating in parallel. With the advent of general purpose GPU (GPGPU) computing, the ability to exploit these cores for the purpose of numerical computation has become possible. If a problem can be mapped effectively to the hardware of a GPU, it can reduce the overall compute time required for evaluating results, as well as reducing overall power usage for similar performance as cluster nodes. For the previous generation flagship industry standard GPUs used in computational acceleration (Nvidia M2090) the memory bandwidth for the device global memory (equivalent of RAM) is given as 288 gigabytes per second, with upwards of thousands of cores on demand, yielding a theoretical total of 1.41 × 10&lt;sup&gt;12&lt;/sup&gt; floating-point operations per second (FLOPS), following the formula
FLOPS = cores × clock frequency × operations per clock cycle.&lt;/p&gt;

&lt;p&gt;For comparison, Intel Xeon CPU throughput values at best yield approximately 10&lt;sup&gt;11&lt;/sup&gt; FLOPS. As can be seen, performance of an order of magnitude greater can be gained by using a GPU for calculations, over high-performance (Xeon) CPUs. This has been shown to allow for effective implementation of the previously mentioned Fourier split-operator method . We have also shown that it yields performance exceeding that of CPUs for a modest choice of GPU , of which we will discuss in detail in a later section.&lt;/p&gt;

&lt;h3 id=&#34;parallel-operations&#34;&gt;Parallel operations&lt;/h3&gt;

&lt;p&gt;[sub:Parallel operations] For a calculation to fully utilise all of the available throughput of a parallel-capable compute device, it is necessary to break down the problem into parallelised sub-problems, which can be easily achieved if data and required operations are uncoupled (&lt;em&gt;embarrassingly parallel&lt;/em&gt;). Considering summation as an example, imagine that we have a large vector of floating point values that are to be summed together. The traditional way to solve this would be to iteratively add values to an accumulator, and return the final value at the end as the sum. This simple algorithm is 𝒪(&lt;em&gt;n&lt;/em&gt;) complexity in time, as we iterate through each element at a time. Given that summation is associative, we easily parallelise this operation. By dividing our vector amongst a number of available processing cores recursively, we can reduce the computation to 𝒪(log&lt;em&gt;n&lt;/em&gt;) in time (see Fig. [fig:prefixsum]). This algorithm can give a significant benefit when a large number of summations are performed, such as for wavefunction normalisation, and can reduce the accumulated error resulting from floating point addition from 𝒪(&lt;em&gt;n&lt;/em&gt;) to 𝒪(log&lt;em&gt;n&lt;/em&gt;) .&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;./ch3_numerics/CUDA/prefixsum.pdf&#34; style=&#34;width:75.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Another typical algorithm following this is the Hadamard product (element-wise multiplication) of two vectors or matrices. Although in parallel the number of operations and complexity remains the same, the advantage comes from the lack of interdependence between elements. The multiplications can be carried out asynchronously, allowing all freely available cores to work continuously until every element pair is multiplied.&lt;/p&gt;

&lt;p&gt;Mapping the above problems onto GPU devices requires an understanding of some of the architecture and hierarchies of the programming model. We will next introduce this model, and discuss some optimal uses of the available memory and structures.&lt;/p&gt;

&lt;h2 id=&#34;cuda-programming-model&#34;&gt;CUDA programming model&lt;/h2&gt;

&lt;p&gt;Although many multicore programming models exist for both CPUs and GPUs, with OpenCL and OpenACC being two such examples, we will concentrate on Nvidia’s CUDA . CUDA is a mature programming model and API for Nvidia GPUs, and has been well-received for high-performance parallel computing. CUDA operates on a single instruction multiple thread (SIMT) architecture, wherein a single operation is mapped to multiple compute threads independently operating on individual units of data. Writing a program using CUDA C/C++ is very similar to standard C/C++ programming, albeit with some minor differences to account for control of GPU compute threads. CUDA manages calculations in a hierarchical structure with differing levels of fine-grained control over these threads. At the finest grained level (&lt;em&gt;T&lt;/em&gt;) we have compute threads which operate directly on a single datum from memory. The maximum number of threads which can run simultaneously on the device in a single compute unit are known as a &lt;em&gt;warp&lt;/em&gt;. Threads are grouped into blocks (&lt;strong&gt;B&lt;/strong&gt;), which is the next hierarchical level, which will optimally contain multiples of the maximum warp number for the device (32 elements is the standard warp size for Nvidia architecture).&lt;/p&gt;

&lt;p&gt;At the coarsest level, the blocks are grouped together into a grid (&lt;strong&gt;G&lt;/strong&gt;), which encompasses the entire problem space. Hardware limits are specified limiting the upper-values of how many elements can appear in these units, and thus the hierarchy exists to allow for fine-grained control on memory usage, and hence performance optimisation on calculations. For a given problem it is necessary to find a mapping from data values in memory to execution threads. To ensure optimal use of GPU cores, the number of threads worked on simultaneously can be (for current hardware) up to 1024 threads per block, though keeping this value divisible by the warp size is recommended to allow an exact mapping to device cores. Optimal values can be found for balancing data computation and transfers, giving, depending on system size, necessary values for block size, as well as grid size. The dimensions of each hierarchical layer are independent of one another, and may be up to 3, with a hardware dependent limit only imposed on the maximum number of elements. Figure [fig:gpu_threads] gives a sample layout for a system of 2D threads and 2D blocks within a single grid.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;./ch3_numerics/CUDA/gputhreads.pdf&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Unlike programming for a CPU-based system, GPUs require explicit control of several different types of memory, and so it is necessary to be aware of the different aspects of managing this memory. Nvidia’s CUDA programming model defines these different physical memories into &lt;em&gt;global&lt;/em&gt;, &lt;em&gt;constant&lt;/em&gt;, &lt;em&gt;shared&lt;/em&gt; and &lt;em&gt;private&lt;/em&gt;. Global memory is analogous to random access memory (RAM) on a CPU-based system, and is the location where we primarily store data for computation on the GPU. This memory block is accessible (readable and writable) to all threads in the computation. This is also the slowest memory on the GPU, with bandwidths of approximately 10&lt;sup&gt;11&lt;/sup&gt; bytes per second. Constantly reading and writing to global memory can hinder the performance of a computation. For memory that is statically defined at the start of a program and will only be read thereafter, the constant memory can be used. This is a special area of memory that can be used to store constants and other values that are often read during a computation. Once set, these values cannot be modified. The next memory level is shared memory, which is block accessible only i.e. threads within the same block have access. This allows threads to exchange information with close neighbours, and is the preferred method of inter-thread communication. Although higher performance than global, the size of shared memory is much smaller. An ideal use case is the parallel summation example given in Sec. [subsec:par_op]. Performing this algorithm requires the copying of data from global to shared memory, performing the calculations, then copying the results back. Lastly, private memory which maps directly to device cache, is thread-accessible only i.e. each thread has access only to its own private values. This memory can be used for local variables defined in a function (known as a &lt;em&gt;kernel&lt;/em&gt; for GPUs). Private memory has the highest performance, but the smallest available size. If possible, copying variables from global memory into private memory, performing all operations on private, then saving back to global can yield the highest performance, as global memory (slow) is read from and written to once each.&lt;/p&gt;

&lt;p&gt;Limiting transfers between the CPU/RAM to the GPU/global memory are of high importance, as the slowest line of communication is the PCI-Express bus, connecting the GPU to the host system (≈16 GB/s max). Eliminating unnecessary communication will almost certainly allow for a gain in performance. Mapping a problem to the GPU requires parallelising the calculation and removing transfers where applicable. For maximum performance, a sample model of performing a GPU calculation is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Define all variables and data on the host system.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Identify the optimal mapping onto the GPU thread execution model.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Send the data from RAM to the GPU global memory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Perform computation, with necessary elements copied to shared/private memory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Return final output of computation to host system when completed.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Although idealised and highly simplified, close adherence to such a model should yield significant performance gains compared to multicore CPU-based computation. An important point with memory access in GPUs is that to ensure optimal performance all access should be assumed to be in-order and adjacent. As an example, though the parallel sum method discussed in Sec. [subsec:par_op] is superior to an iterative summation, it is not an optimal example for GPU architectures . With a small improvement, this can be highly optimised, as highlighted by Fig. [fig:prefixsum2]. In this case, the memory access is carried out in strided linear chunks, and by ensuring that all memory accesses are performed this way as much as possible an overall higher degree of performance can be achieved . As GPUs operate on blocks of memory simultaneously, minimising the amount of misaligned memory accesses can optimise the access performance. In this instance, these structures can be packed efficiently together and ensure a large number of copies are performed optimally, with coalesced memory access.&lt;/p&gt;

&lt;p&gt;While details for the internal workings of the device are often abstracted, an awareness of these can prove useful. If we assume the number of data elements to be summed is larger than the available number of threads, this routine can perform several passes before the threads become sub-optimally used, as in the previous case. In this way, the summation ensures that the available threads are working mostly optimally.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;./ch3_numerics/CUDA/prefixsum_2.pdf&#34; style=&#34;width:75.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Given that GPUs are first and foremost image processing devices, their ability to perform Fourier transforms rapidly is a well developed strength. Due to the large number of available cores, fast Fourier transforms (FFTs) can be significantly faster on a GPU than performing the same operation on many CPUs . The CUFFT library allows for a seamless way to take advantage of this performance increase using GPUs. Next, we will discuss an example of GPU-enabled simulations for an experimentally realistic problem making use of the GPU to perform the necessary operations discussed in Secs. [sec:timeev] and [sec:fso], and offer some realistic performance measurements.&lt;/p&gt;

&lt;h2 id=&#34;gpu-enabled-parallel-schrödinger-simulations&#34;&gt;GPU-enabled parallel Schrödinger simulations&lt;/h2&gt;

&lt;p&gt;Here, we will introduce the problem of atomic transport in cold atomic systems, present the resulting model system, and give all the essential physics. Controlling the centre-of-mass movement of atoms has recently become a popular topic of investigation . One family of techniques that aim to solve this are those of &lt;em&gt;spatial adiabatic passage&lt;/em&gt;. In the following section we will describe the motivation, physical system, and the numerical implementation for the solution of the problem of transporting a single atom among three trapping potential wells. The fully three-dimensional numerical solution of this problem will then be provided using GPU computing methods, and the results discussed for both the physical and computing aspects.&lt;/p&gt;

&lt;p&gt;For performance metrics, we will discuss the use of a GPU-enabled Schrödinger equation integrator developed by myself, based on and compared with the results of a multi-core MPI enabled version by T. Morgan and N. Crowley. The solution of the Schrödinger equation for a fully three-dimensional potential, will demonstrate the effectiveness and improved performance compared to standard HPC methods.&lt;/p&gt;

&lt;h3 id=&#34;spatial-adiabatic-passage&#34;&gt;Spatial adiabatic passage&lt;/h3&gt;

&lt;p&gt;Controlling the internal degrees of freedom of atoms is well understood and many spectroscopic techniques exist. External degrees of freedom have, however, only recently become interesting due to the advancements in atom trapping, and techniques for controlling the centre of mass state of a single atom are still in development. One promising group of techniques for the generation of spatial superposition states or high fidelity transfer relies on ideas from spatial adiabatic passage (SAP) , which are analogous to STIRAP in optical systems . These techniques are highly robust against variation in the system parameters , but suffer from being slow due to the adiabatic requirement. The use of SAP has recently been experimentally demonstrated in Lieb lattices , and many other accessible systems have been proposed .&lt;/p&gt;

&lt;p&gt;To describe the method for SAP, we will first consider the case of a two-state system, which can be realised using two separated harmonic potential traps, with ground states |*L*⟩ and |*R*⟩. A reduction of the distance between the traps will increase the coupling, and hence tunneling rate, between them. This can be modelled with a two-level Hamiltonian as
$$H = -\frac{\hbar}{2}
    \begin{pmatrix}
        0 &amp;amp; J_{LR} \&lt;br /&gt;
        J_{RL} &amp;amp; -2\Delta
    \end{pmatrix},$$
 where &lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*L&lt;strong&gt;R*&lt;/sub&gt; = &lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*R&lt;/strong&gt;L*&lt;/sub&gt; are the couplings between states, and &lt;em&gt;Δ&lt;/em&gt; is the detuning of state |*R*⟩, relative to |*L*⟩. Assuming an atom initially localised in |*L*⟩, and with an increase in coupling strength between the levels, the localised atom will tunnel from |*L*⟩ to |*R*⟩. However, this processes is difficult to control, as Rabi oscillations introduce an explicit time-dependence as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    |c_L(t)|^2 &amp;amp;\propto \sin^2 \frac{\omega t}{2} ,\&lt;br /&gt;
    |c_R(t)|^2 &amp;amp;\propto \cos^2 \frac{\omega t}{2},\end{aligned}$$&lt;/p&gt;

&lt;p&gt;where the |&lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;L&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;&lt;/sub&gt;(&lt;em&gt;t&lt;/em&gt;)|&lt;sup&gt;2&lt;/sup&gt; are the populations of the respective states. This time dependence causes the atomic population to continuously tunnel between both traps. It will therefore require precise timing and control to ensure a full, robust transfer of population. From this we see that a double-well potential is a difficult system in which to realise coherent control, though methods such as rapid adiabatic passage (RAP) exist and can allow for this . A more robust method, using three adjacent harmonic traps and the aforementioned matter-wave SAP process, can improve upon the standard double-well system. For this SAP technique, we model the trapping potentials arranged in a single line and coupled with their nearest neighbour only. For three equivalent potentials, &lt;em&gt;L&lt;/em&gt;, &lt;em&gt;M&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;, with degenerate states {|*L*⟩,|*M*⟩,|*R*⟩}, the system can be described by the Hamiltonian
$$\label{eqn:sap_ham}
    H = -\frac{\hbar}{2}
    \begin{pmatrix}
        0 &amp;amp; J_{LM} &amp;amp; 0 \&lt;br /&gt;
        J_{LM} &amp;amp; 0 &amp;amp; J_{MR} \&lt;br /&gt;
        0 &amp;amp; J_{MR} &amp;amp; 0
    \end{pmatrix},$$
 where &lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*L&lt;strong&gt;M*&lt;/sub&gt;,  &lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*M&lt;/strong&gt;R*&lt;/sub&gt; describe the left-middle and middle-right couplings respectively. Diagonalising this Hamiltonian gives three distinct eigenstates,&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    | \pm \rangle &amp;amp;= \frac{J_{LM} |L\rangle \pm \sqrt{J_{LM}^2 + J_{MR}^2}|M\rangle + J_{MR} |R\rangle  }{\sqrt{2(J_{LM}^2 + J_{MR}^2)}}, \&lt;br /&gt;
    | D \rangle &amp;amp;= \frac{J_{MR} |L\rangle }{\sqrt{J_{LM}^2 + J_{MR}^2}} - \frac{J_{LM} |R\rangle}{\sqrt{J_{LM}^2 + J_{MR}^2}},\end{aligned}$$&lt;/p&gt;

&lt;p&gt;with respective eigenvalues $E_{\pm} = \pm {\sqrt{J_{LM}^2 + J_{MR}^2}}$, &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;D&lt;/em&gt;&lt;/sub&gt; = 0. Here, only one eigenstate is of interest. For the zero-valued eigenstate of this Hamiltonian, |*D*⟩, known as the &lt;em&gt;dark state&lt;/em&gt;, the dependence on the middle potential vanishes. The state can be written as
|*D*⟩=cos &lt;em&gt;Θ&lt;/em&gt;|*L*⟩−sin&lt;em&gt;Θ&lt;/em&gt;|*R*⟩,
 where tan*Θ* = &lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*L&lt;strong&gt;M*&lt;/sub&gt;/&lt;em&gt;J&lt;/em&gt;&lt;sub&gt;*M&lt;/strong&gt;R*&lt;/sub&gt; is the mixing angle, following directly from the trigonometric identities $\cos (\arctan (x)) = 1/\sqrt{1+x^2}$, $\sin (\arctan (x)) = x/\sqrt{1+x^2}$. From the adiabatic theorem of quantum mechanics, it is known that if a system has its Hamiltonian perturbed slowly enough, then we can follow its evolution ensuring that it always remains in an eigenstate of the Hamiltonian. By preparing the system in state |*L*⟩, and varying &lt;em&gt;Θ&lt;/em&gt; slowly, we can shift the population from the leftmost harmonic potential to the rightmost, without populating the center. To ensure full transfer from |*L*⟩ to |*R*⟩, the mixing angle must change smoothly from *Θ* = 0 → &lt;em&gt;π&lt;/em&gt;/2. From the properties of arctan, this can be achieved by applying the same spatial variation between |*M*⟩ and |*R*⟩, as between |*L*⟩ and |*M*⟩, with the latter coupling pulse following a delay, &lt;em&gt;τ&lt;/em&gt;. A diagram of this is given by Fig. [fig:ch3_stirap]. Due to the robustness of this process a variety of coupling profiles can be used , as long as they have a smoothly varying background envelope &lt;em&gt;p&lt;/em&gt; given by&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    J_{LM}(t) &amp;amp;= J_0 p(t-\tau), \&lt;br /&gt;
    J_{MR}(t) &amp;amp;= J_0 p(t).\end{aligned}$$&lt;/p&gt;

&lt;p&gt;Varying the couplings between the trapping potentials, and hence controlling this mixing angle, can be achieved by either lowering the barrier height of adjacent potentials, or decreasing the distance between them. Here, we will discuss varying the spatial separation of the traps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./ch3_numerics/stirap_delay&#34; alt=&#34;Three trapping potential model for matter-wave SAP. The atom (green) is initially localised in the leftmost potential, |L\rangle, at t=0, with the couplings between adjacent traps controlled by varying the distance dependent parameters J_{LM}, J_{MR}. By varying the couplings between traps in the manner shown, with J_{MR} increasing initially, followed by J_{LM} after a delay \tau, the atom is transferred completely from |L\rangle to | R \rangle.&#34; style=&#34;width:65.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Typically, any method to adjust the couplings would be performed with time-dependent potentials. However, a static potential variant can be considered using parallel atomic waveguides, where the separation varies as a function of distance along the parallel axis. If we consider an atom that travels along such a waveguide, the couplings, and hence tunneling rates, seen by the atom in the waveguide are altered as the atom propagates. Such work has been discussed and considered in a realistic system for two spatial dimensions . Although a two dimensional model is effective at describing much of the relevant dynamics, the realism of the model is reduced by the lack of a third dimension. This is due to the lack of effects stemming from dispersion, curvature of the waveguides, as well as the absence of any such eigenstates along this dimension.&lt;/p&gt;

&lt;h3 id=&#34;atom-chip-model&#34;&gt;Atom-chip model&lt;/h3&gt;

&lt;p&gt;As discussed previously, to fully understand ultracold atom dynamics in appropriately shaped waveguide systems we must investigate the fully three-dimensional model. One method of creating the required potential landscape in experiments is through the use of atom-chips . These systems consist of micro-fabricated current-carrying wires, and can be used to create a variety of trapping potential shapes for controlled guidance of the atomic centre-of-mass . The currents produce a magnetic field around individual wires, each of which has a minima at the wire core. Assuming the wire thickness to be negligible, this magnetic field at position &lt;strong&gt;r&lt;/strong&gt; can be calculated using the Biot–Savart law
$$\mathbf{B}(\mathbf{r}) = \frac{\mu_0}{4\pi}\oint I \frac{\text{d}\mathbf{l}\times \hat{\mathbf{r}}^{&amp;lsquo;}}{|\mathbf{r^{&amp;lsquo;}}|^2},$$
 where &lt;em&gt;I&lt;/em&gt; is the current through the wire, &lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; is the vacuum permeability, d&lt;strong&gt;l&lt;/strong&gt; is the differential wire length, and $\hat{\mathbf{r}}^{&amp;lsquo;}$ is the unit vector along &lt;strong&gt;r&lt;/strong&gt;&lt;sup&gt;&lt;strong&gt;′&lt;/strong&gt;&lt;/sup&gt; = &lt;strong&gt;r&lt;/strong&gt; − &lt;strong&gt;l&lt;/strong&gt;. To be able to trap atoms the minima must be raised to a position above the wire surface. This can be done using an orthogonally applied bias field, &lt;em&gt;B&lt;/em&gt;&lt;sub&gt;&lt;em&gt;b&lt;/em&gt;&lt;/sub&gt;, which raises the minima to a height of
$$\mathbf{r}_0 = \frac{\mu_0 I}{2\pi {B}_b},$$
 above the surface. Though, an issue still remains with the presence of the magnetic minima. If the field drops to zero at the centre of the trap, the atoms can be lost due to Majorana spin flips . This can be prevented with the application of an additional field, &lt;em&gt;B&lt;/em&gt;&lt;sub&gt;*i*&lt;em&gt;p&lt;/em&gt;&lt;/sub&gt;, parallel to the wire direction, lifting the degeneracy of the atomic states, and ensuring they remain trapped. Spatial and temporal adjustments of the potentials are possible, with a fine degree of control, either during the production process, or by using time-dependent currents. These have been studied extensively in recent years for highly controllable trapping potentials , and as atomic manipulators .&lt;/p&gt;

&lt;p&gt;For this work, we model the system as three adjacent wires on the atom-chip surface. The direction of propagation is along &lt;em&gt;z&lt;/em&gt;, and an additional harmonic oscillator potential, &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; = *m*&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;(*z* − &lt;em&gt;z&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;/2, is applied in the same direction to impart motion to the atom, which is initially at the *z* = 0 position of the atom-chip. We set &lt;em&gt;z&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; = (max&lt;em&gt;z&lt;/em&gt;)/2 to ensure the oscillator potential is symmetric around the centre of the atomchip. This potential also conveniently guarantees that the wavefunction refocuses after the transition at the opposite side of the atom-chip. A schematic of the atom-chip device and the respective potentials is given by Fig. [fig:schematic_atom-chip].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/MWSTIRAP/Schematic3&#34; title=&#34;fig:&#34; alt=&#34;Schematic of the atom-chip and the resulting potentials. Reprinted from Morgan et al. .&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch3_numerics/MWSTIRAP/3dpot_schem&#34; title=&#34;fig:&#34; alt=&#34;Schematic of the atom-chip and the resulting potentials. Reprinted from Morgan et al. .&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The initial state is created by localising the atom with the help of a barrier at one end of the potential (*z* = 0), and in the leftmost waveguide using an additional barrier potential. After finding the ground state, the barriers are removed, and the atom is allowed to propagate along the length of the waveguide. The populations in each waveguide |&lt;em&gt;c&lt;/em&gt;&lt;sub&gt;&lt;em&gt;X&lt;/em&gt;&lt;/sub&gt;|&lt;sup&gt;2&lt;/sup&gt; are tracked at each step of the process as
$$|c_X|^2 = \int\limits_{\mathcal{V}_X} d\mathbf{r}  \Psi^{*} \Psi$$
 where 𝒱&lt;sub&gt;&lt;em&gt;X&lt;/em&gt;&lt;/sub&gt; is the volume encompassing each waveguide *X* ∈ {&lt;em&gt;L&lt;/em&gt;, &lt;em&gt;M&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;}, and &lt;em&gt;Ψ&lt;/em&gt; is the state of the system. The final populations were taken as the atom approached the other classical turning point of the harmonic oscillator along &lt;em&gt;z&lt;/em&gt;. The fidelity of the process could then be calculated by comparing the initial populations in |*L*⟩ and final ones in |*R*⟩, as well as any ones left in |*M*⟩.&lt;/p&gt;

&lt;p&gt;Given that fully three-dimensional simulations of the Schrödinger equation are numerically expensive, the use of GPU computing methods were ideal for accelerating the simulation . At the time of writing, as far as we had been aware, no other work using GPU computing to solve a three dimensional Schrödinger equation had been presented. We will now discuss the data and metadata of the simulations.&lt;/p&gt;

&lt;h3 id=&#34;3d-simulations&#34;&gt;3D Simulations&lt;/h3&gt;

&lt;p&gt;Simulations of the proposed system assumed a single **&lt;sup&gt;6&lt;/sup&gt;Li atom localised in the left . A localised harmonic oscillator potential was added along &lt;em&gt;z&lt;/em&gt;, with the transverse guiding potential, and the resulting ground state solution found numerically. The harmonic oscillator width was chosen to closely match the expected size in the transverse direction. The atom was then allowed to propagate along the waveguide potential (&lt;em&gt;z&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;As the shift in magnetic moment of the atoms is given by *Δ&lt;strong&gt;E* = −*μ* ⋅ &lt;/strong&gt;B**, for regions with a larger magnetic field the atom will experience a greater energy shift, and thus the assumption of all traps being on resonance (degenerate) has to be carefully checked. In fact, the simulations showed that the addition of the magnetic fields stemming from the different wires at the center of the atom-chip leads to the central potential moving out of resonance with the outer two. To make SAP work, it therefore required adjusting the current in the central wire, such that the magnetic minima were in resonance within the tunneling region near the atom-chip centre. The resulting potentials for non-optimal (left) and optimal (middle) currents are shown in Fig. [fig:equaloptcurrent], which also depicts a three dimensional isosurface of the potential minima along the chip surface for both situations (right).&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch3_numerics/MWSTIRAP/potentials2.pdf&#34; title=&#34;fig:&#34; style=&#34;width:55.0%&#34; /&gt; &lt;embed src=&#34;ch3_numerics/MWSTIRAP/3dpot.pdf&#34; title=&#34;fig:&#34; style=&#34;width:30.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The populations for both the direct tunneling case, and the matter-wave SAP processes are shown in Fig. [fig:mwsVsDT]. The direct tunneling case can be seen to show Rabi-type oscillations between the waveguides, while the matter-wave SAP process shows a much cleaner transfer, and only a minor occupation of the central potential. The dependence of the transfer probability on the current in the central wire is shown in Fig. [fig:DIRVSMWSTIRAP].&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch3_numerics/MWSTIRAP/STIRAP_CINT_POP.pdf&#34; title=&#34;fig:&#34; style=&#34;width:47.0%&#34; /&gt; &lt;embed src=&#34;ch3_numerics/MWSTIRAP/STIRAP_INT_POP.pdf&#34; title=&#34;fig:&#34; style=&#34;width:47.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch3_numerics/MWSTIRAP/SAPvsDirect.pdf&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;gpu-computing-performance&#34;&gt;GPU computing performance&lt;/h3&gt;

&lt;p&gt;Given the large parameter space over which this system could be evaluated (e.g wire current, spatial separations, trap frequencies), a large number of simulations were required to determine optimal system behaviour. As discussed in Sec. [sec:cuda_prog], one example where GPU computing offers large performance gains are FFTs, which makes the Fourier split operator method an ideal candidate for GPU systems . The body of work for implementing this algorithm was using C, CUDA and Nvidia’s CUFFT libraries for the Fourier transforms, whereas the MPI-enabled code was implemented using C.&lt;/p&gt;

&lt;p&gt;To demonstrate the performance offered by GPU computing we compared it to using FFTW with MPI, a well used parallel programming library and paradigm. The MPI implementation allows code to be run across multiple machines, benefiting from the parallelism which may be offered by a supercomputing cluster. Although MPI-enabled FFTW is fast and supports extremely large grid sizes, it requires cluster access of a significant size to be a viable option for this type of system. The MPI work on this project was carried out on the Irish Center for High-End Computing (ICHEC) supercomputer system “Stoney” over the period 2011 to 2012, with all performance metrics data calculated therefrom. This cluster system had 64 available compute nodes, each housing two 2.8GHz Intel Xeon X5560 processors with 4-cores each, and a total of 48GB of RAM per node with inter-node communication using double data rate Infiniband.&lt;/p&gt;

&lt;p&gt;Due to the hardware limited memory on the GPU, and because the dynamics along the *x* − &lt;em&gt;z&lt;/em&gt; plane were of most importance, the grid-size of the simulations were scaled as 256 × 64 × 1024 (*x* × *y* × &lt;em&gt;z&lt;/em&gt;). Of next importance were the choice of timesteps for the simulations. To ensure minimal loss in accuracy, the timesteps were chosen as *Δ**t* = 10&lt;sup&gt;−6&lt;/sup&gt; s. By approximating the waveguides as harmonic oscillators, the relevant timescales of the dynamics are of the order &lt;em&gt;T&lt;/em&gt;&lt;sub&gt;t&lt;/sub&gt; ≈ 10&lt;sup&gt;−4&lt;/sup&gt; s, and so we can accurately capture all relevant dynamics in the transverse direction. The timescales in the longitudinal direction, which requires a large oscillation period compared to the transverse plane to ensure the adiabaticity condition (&lt;em&gt;T&lt;/em&gt;&lt;sub&gt;l&lt;/sub&gt; ≈ 10&lt;sup&gt;−1&lt;/sup&gt; s), are also fulfilled. For the GPU simulations, the test system was an Intel Core i7 2600K CPU at stock frequency, 8GB DDR3 memory operating at 1600 MHz, 7200 RPM HDD, Nvidia GeForce GTX 580 with 3GB of onboard memory running at 783 MHz GPU core frequency, 1566 MHz shader processor frequency, and 2010 MHz memory frequency. For all simulations the desktop was running Ubuntu 11.10 64-bit operating system and all calculations were performed in double precision (64-bit floating point) where applicable.&lt;/p&gt;

&lt;p&gt;Table [tbl:timing] shows the approximate timings for the completion of runs using GPU and CPU codes. Not only does GPU computing offer a 6-fold improvement over a single CPU, it also allows us to achieve a performance level which is comparable to an 8-node 8-core (64 cores) core MPI enabled CPU calculation. Even for a modest choice of gaming GPU this offers substantial performance gains. Higher performance was achieved by using specific compute accelerators designed for double precision arithmetic. Making use of eight Nvidia M2090 GPUs available at OIST, terabytes of numerical results were generated, and allowed the problem to become tractable on a short timescale.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Device&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Num. Devices&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Timing&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Rel. Improvement&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;CPU (MPI)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∼6 Hr&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∼4 Hr&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∼1.5 Hr&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.0×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∼1 Hr&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.0×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GPU&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∼1 Hr&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.0×&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;gpue-gpu-gross-pitaevskii-equation-solver&#34;&gt;GPUE: GPU Gross–Pitaevskii equation solver&lt;/h2&gt;

&lt;p&gt;Given the effectiveness of GPU computing in the simulation of the linear Schödinger equation system for SAP, we next applied the newly-developed techniques to simulating Bose–Einstein condensates, which formed the bulk of work during my thesis. The body of software developed for this project has been released as the tool “GPUE”, available at &lt;a href=&#34;https://github.com/mlxd/gpue&#34;&gt;https://github.com/mlxd/gpue&lt;/a&gt; . Performance testing of this code was carried out by Peter Wittek, ICFO, Barcelona . A comparison was performed between GPUE, the Trotter–Suzuki (TS) package developed by Wittek &lt;em&gt;et&lt;/em&gt; al. , and the mature GPELab software suite for MATLAB . The sample results taken for time evolution are given in Fig. [fig:gpuevsts]. GPUE and GPU-enabled TS clearly beat MATLAB, and CPU performance by a significant margin. Although TS is a more generalised suite for computing, as far as we are currently aware the GPU computation does not yet allow for Gross–Pitaevskii solutions with angular momentum. GPUE is currently the optimal choice for rotating condensate systems out of the examined software suites.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/GPUEvsTS.png&#34; alt=&#34;Performance benchmark of GPUE and other simulation packages for the evolution of a harmonically trapped atom in a superposition state between ground and first excited states. Lower numbers are better and give results in faster times. Data adapted from . &#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Figures  [fig:profile_ev] and [fig:profile_im] demonstrate some of the resulting calls to different segments of the code, with timings given in Tables [tbl:gpue_ev] and [tbl:gpue_im]. The important data of the figures is both the kernel percentage utilisation, and that the operations are mostly saturating the available number of GPU cores. The data shows the average time spent in each individual kernel during both real and imaginary time evolution for 1010 steps at 2&lt;sup&gt;10&lt;/sup&gt; × 2&lt;sup&gt;10&lt;/sup&gt; resolution with (real) and without (imaginary) angular momentum operators. As can be seen, the inclusion of angular momentum operators lead to a performance hit, compared with an imaginary time evolution for a static condensate. While further optimisations can almost always be provided for such simulations, the performance of the software as a whole is defined by its slowest component. In this case the routines are equally met in performance by the Fourier transforms, which are already fully optimised as an external library. As such, improving performance much beyond this with the other kernels will be wasteful in time and resources.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/CUDA/Profiler_ev_1k_1024.png&#34; alt=&#34;Nvidia Nsight performance analysis of GPUE for real time evolution simulation for 1010 steps at 2^{10}\times 2^{10} resolution. The respective kernel calls and total utilisation are listed on the left.&#34; style=&#34;width:98.0%&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kernel&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Info&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Avg. runtime&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;# Runs&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Total time&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Mem. copy [H2D]&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Memory copy from host to GPU&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.312 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;25.432 ms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Mem. copy [D2H]&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Memory copy from GPU to host&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.18 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;19.62 ms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;cMult&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Complex mult. in time ev.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.342 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3030&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0363 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;cMultDensity&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Complex mult. in time ev. for nonlinear op.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.456 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.921 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;scalarDiv&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Renorm. of &lt;em&gt;Ψ&lt;/em&gt; following FFT&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.2216 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8080&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.791 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;dpRadix0032B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Internal CUFFT operation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.237 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8080&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.915 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;dpVector1024D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Internal CUFFT operation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.252 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8080&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.0362 s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/CUDA/Profiler_im_1k_1024.png&#34; alt=&#34;Nvidia Nsight performance analysis of GPUE for imaginary time simulation for 1010 steps at 2^{10}\times 2^{10} resolution with angular momentum. The respective kernel calls and total utilisation are listed on the left.&#34; style=&#34;width:98.0%&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Kernel&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Info&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Avg. runtime&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;# Runs&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;strong&gt;Total time&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Mem. copy [H2D]&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Memory copy from host to GPU&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.311 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.933 ms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Mem. copy [D2H]&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Memory copy from GPU to host&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.85 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.25 ms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;cMult&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Complex mult. in time ev.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.342 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.345 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;cMultDensity&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Complex mult. in time ev. for nonlinear op.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.346 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.698 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;multipass&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Optimised parallel summation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.125 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3030&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.378 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;scalarDiv&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Renorm. of &lt;em&gt;Ψ&lt;/em&gt; following FFT&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.221 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.446 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;scalarDiv_wfcNorm&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Normalisation of wavefunction during ev.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.226 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.228 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;dpRadix0032B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Internal CUFFT operation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.237 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4040&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.957 s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;dpVector1024D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Internal CUFFT operation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.251 ms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.507 s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A simplified sequence and state diagram combination is given in Figs. [fig:gpue_seq1] and [fig:gpue_seq2] which describes the operating process for GPUE. A document listing all aspects of component dependencies and intercommunication is available at . For brevity, we will refer the reader to this location for more information.[2].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/GPUE_Seq1&#34; alt=&#34;Simplified combined sequence and state diagram for GPUE operation (1 of 2). The operation procedure of GPUE is outlined in sequence from top-to-bottom. While much of the setup and analysis takes place on the host (CPU), the device (GPU) is used to offload all the time-evolution calculations. After setup, the wavefunction and all required operators are sent to the GPU.&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/GPUE_Seq2&#34; alt=&#34;Simplified combined sequence and state diagram for GPUE operation (2 of 2). Following the completion of the time evolution after a predetermined number of steps, the wavefunction is unloaded from the GPU and returned to the CPU for output. Minimising this transfer allows for optimal performance from the device. Further details of dependencies and data flow are given by docs/gpue.pdf.&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;angular-momentum-operators-using-fourier-split-operator-method&#34;&gt;Angular momentum operators using Fourier split-operator method&lt;/h3&gt;

&lt;p&gt;As discussed earlier, in the presence of large values of angular momentum, the condensate wavefunction will accommodate many vortices. To ensure a well ordered lattice, more consideration is required than to just directly numerically solve the GPE at the required rotation rate. Assuming an initial Gaussian guess, and using the imaginary time evolution algorithm to find the ground state, a large number of vortices will enter the condensate from the edge and compete for lattice sites to form the expected Abrikosov pattern. Due to the highly dense spectrum of the condensate close to the ground state in this regime, only minimal energy shifts will be given for deviations from the perfect Abriksov geometry. As a result, it can take a significantly long time to reach an ordered state for rotation frequencies close to the transverse trapping frequency . To overcome this issue, one can choose to follow the ground state of the condensate with a ramp of the rotation rate. This essentially mimics adiabatic evolution, and allows for the determination of the vortex lattice ground state for all rotation frequencies.&lt;/p&gt;

&lt;p&gt;The Fourier split-operator algorithm described earlier works well in handling cases where the individual operators live in position or momentum space respectively. However, the angular momentum operators are a combination of both spaces. Taking the angular momentum operator along the &lt;em&gt;z&lt;/em&gt;-axis, &lt;em&gt;L&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; = *x&lt;strong&gt;p*&lt;sub&gt;&lt;em&gt;y&lt;/em&gt;&lt;/sub&gt; − *y&lt;/strong&gt;p*&lt;sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;/sub&gt;, and applying it to the wavefunction requires each basis element to be in a different space in the different directions. For applying this operator we must therefore Fourier transform along a single dimension, multiply by the respective &lt;strong&gt;k&lt;/strong&gt;-space component, take the inverse, multiply by the respective &lt;strong&gt;r&lt;/strong&gt;-space component in the other direction, and then perform this operation along the other dimensions, summing the results.&lt;/p&gt;

&lt;p&gt;This accrues an error which is not encountered using methods that are solely in position or momentum space. Following the process given in Sec. [sec:fso] the error can be determined by checking the commutativity of the respective components of the angular momentum operator as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \alpha_1 = [x p_y,-y p_x] &amp;amp;= [x p_y,-y] p_x  -  y[x p_y,p_x] = -[-y,x p_y] p_x + y [p_x, x p_y] \nonumber \&lt;br /&gt;
        &amp;amp;= -\left( {\cancelto{0}{[-y,x]}} p_y + x [-y,p_y] \right) p_x + y \left( [p_x,x] p_y + x {\cancelto{0}{[p_x,p_y]}} \right) \nonumber \&lt;br /&gt;
        &amp;amp;= -x {\cancelto{-\textrm{i}\hbar}{[-y, p_y]}} p_x + y {\cancelto{-\textrm{i}\hbar}{[p_x,x]}} p_y \nonumber \&lt;br /&gt;
        &amp;amp;= \textrm{i}\hbar \left(x p_x - y p_y \right).
 \end{aligned}$$&lt;/p&gt;

&lt;p&gt;The complex error term can be seen as, in the case of the above implemented evolution, allowing the angular momentum operator to change from imaginary time to real-time, and vice-versa in each respective case. To overcome this, we simply swap the application order of the operator components, between odd and even steps during the evolution. Starting with the alternate order we obtain a value of &lt;em&gt;α&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt; = [ − *y&lt;strong&gt;p*&lt;sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;/sub&gt;, *x&lt;/strong&gt;p*&lt;sub&gt;&lt;em&gt;y&lt;/em&gt;&lt;/sub&gt;]=iℏ(−*x&lt;strong&gt;p*&lt;sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;/sub&gt;+*y&lt;/strong&gt;p*&lt;sub&gt;&lt;em&gt;y&lt;/em&gt;&lt;/sub&gt;). Since we are applying these operators to the condensate we can overcome the error of one term by the application of the other, as
expi&lt;em&gt;α&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;expi&lt;em&gt;α&lt;/em&gt;&lt;sub&gt;2&lt;/sub&gt; = 1.&lt;/p&gt;

&lt;p&gt;Although alternating will provide a cancellation of this error, it can be assumed that for large timesteps the error will have a significant contribution to the overall dynamics, as the wavefunction evolves during each timestep. For greater accuracy of this method one can perform a decomposition following Eq.  for a third-order error, or using the above splitting for second-order.&lt;/p&gt;

&lt;p&gt;An example of the density of the ground state and the associated wavefunction phase at a rotation frequency of *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;/sub&gt; is given in Fig. [fig:showingoff] at a resolution of 2&lt;sup&gt;11&lt;/sup&gt; × 2&lt;sup&gt;11&lt;/sup&gt; (2048 × 2048). Although aliasing may be apparent in the phase, this is due to the limited resolution of the computer monitor (printer). The presence of a well ordered Abrikosov lattice is clearly visible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/Rho_995&#34; title=&#34;fig:&#34; alt=&#34;Condensate density (left) and phase (right) at a rotation rate of \Omega=0.995\omega_x for a 2^{11}\times 2^{11} grid showing approximately 600 vortices in the visible density regions. For both images the box size is 700~\mu\textrm{m} ~\times ~700~\mu\textrm{m}.&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch3_numerics/phi_995&#34; title=&#34;fig:&#34; alt=&#34;Condensate density (left) and phase (right) at a rotation rate of \Omega=0.995\omega_x for a 2^{11}\times 2^{11} grid showing approximately 600 vortices in the visible density regions. For both images the box size is 700~\mu\textrm{m} ~\times ~700~\mu\textrm{m}.&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;vortex-tracking&#34;&gt;Vortex tracking&lt;/h3&gt;

&lt;p&gt;To efficiently follow the dynamics of individual vortices, a robust algorithm is needed to track their positions. One could track regions where the density drops to zero. However, this gives very little information on the topological excitation, and may miss many vortices, as the numerical wavefunction may never truly approach this value. A more effective way is to locate the ±2&lt;em&gt;π&lt;/em&gt; charge in the wavefunction phase, which is a signature of quantum vortices. For this we examine each 2 × 2 subgrid of the underlying lattice and check if the phase rotates from −&lt;em&gt;π&lt;/em&gt; to +&lt;em&gt;π&lt;/em&gt; (or vice versa). After an initial pass to identify vortex locations closest the nearest grid element, a least-squares fit is performed to more accurately determine the vortex core position . Linear least squares is used generally for an overdetermined linear system &lt;strong&gt;A&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt; = &lt;strong&gt;b&lt;/strong&gt;, where unique solutions are unlikely to exist. Thus, for a solution, we seek the best fit plane that minimises the error, of the form&lt;/p&gt;

&lt;p&gt;&lt;em&gt;S&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;)=∑|&lt;em&gt;b&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; − ∑&lt;em&gt;A&lt;/em&gt;&lt;sub&gt;*i*&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;r&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;|&lt;sup&gt;2&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;where &lt;em&gt;S&lt;/em&gt; is the objective function to be minimised, following $\mathbf{b} = \operatorname*{arg\,min}S(\mathbf{r})$. The solution of this minimisation problem is given by&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \mathbf{A} ^{T}\mathbf{A} \mathbf{r} &amp;amp;= \mathbf{A} ^{T}\mathbf{b}, \&lt;br /&gt;
    \mathbf{r} &amp;amp;= (\mathbf{A}^{T}\mathbf{A})^{-1}\mathbf{A}^{T}\mathbf{b}.\end{aligned}$$&lt;/p&gt;

&lt;p&gt;The best-fit plane is sought of the form $a_0 c + \displaystyle\sum\limits_{i}^{m} a_i r_i = f(\mathbf{r})$ which for a two-dimensional system, &lt;strong&gt;r&lt;/strong&gt; = (&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;), is given by the matrix,
$$\mathbf{A} = \left(
    \begin{array}{ccc}
        0 &amp;amp; 0 &amp;amp; 1 \&lt;br /&gt;
        0 &amp;amp; 1 &amp;amp; 1 \&lt;br /&gt;
        1 &amp;amp; 0 &amp;amp; 1 \&lt;br /&gt;
        1 &amp;amp; 1 &amp;amp; 1
    \end{array}\right).$$
 The above matrix is composed of all possible planes that can fit over a square 2 × 2 grid plaquette, and
$$\mathbf{b} = \left(
    \begin{array}{cccc}
        \Psi(x_0,y_0) &amp;amp; \Psi(x_0,y_1) &amp;amp; \Psi(x_1,y_0) &amp;amp; \Psi(x_1,y_1)
    \end{array} \right)^{T},$$
 are the wavefunction values around the sampled 2 × 2 grid. Upon evaluating the vector &lt;strong&gt;r&lt;/strong&gt; above, one can obtain the best fit plane solution as
$$\left(
    \begin{array}{c}
        x \&lt;br /&gt;
        y \&lt;br /&gt;
        c
    \end{array}\right)
    = \left(
    \begin{array}{c}
        {\left( -\Psi(x_0,y_0) + \Psi(x_0,y_1) - \Psi(x_1,y_0) + \Psi(x_1,y_1) \right)}{/2} \&lt;br /&gt;
        {\left( -\Psi(x_0,y_0) - \Psi(x_0,y_1) + \Psi(x_1,y_0) + \Psi(x_1,y_1) \right)}{/2} \&lt;br /&gt;
        3\Psi(x_0,y_0) + \Psi(x_0,y_1) - \Psi(x_1,y_0) - \Psi(x_1,y_1)
    \end{array}\right).$$&lt;/p&gt;

&lt;p&gt;The goal is to find where both the real and imaginary components cross through zero, and thus we seek a solution of the form *x* + *y* = −&lt;em&gt;c&lt;/em&gt;. Rearranging the above equations as
$$\left(
    \begin{array}{cc}
        \Re(x) &amp;amp; \Re(y) \&lt;br /&gt;
        \Im(x) &amp;amp; \Im(y) \&lt;br /&gt;
    \end{array}\right)
    \left(
    \begin{array}{c}
        \delta x \&lt;br /&gt;
        \delta y
    \end{array}\right)
    = -
    \left(
    \begin{array}{c}
        \Re&amp;copy; \&lt;br /&gt;
        \Im&amp;copy;
    \end{array}\right),$$
 and again solving the linear system by inverting the left-hand matrix and multiplying across allows one to seek the corrections to the vortex position, *δ*&lt;strong&gt;r&lt;/strong&gt; = (*δ&lt;strong&gt;x*, *δ&lt;/strong&gt;y*).&lt;/p&gt;

&lt;p&gt;With this, we can accurately determine the position of the vortices with high precision. To track their motion during the evolution, we create an initial list of positions and give each vortex a unique identifier (UID). Assuming the vortex cores can travel a limited distance (some multiple of the grid resolution) between time steps, we can say at subsequent times which vortex has moved to the newly found positions.&lt;/p&gt;

&lt;p&gt;This process is performed by representing the vortices as a graph, each with an assigned unique identifier, associated location, phase winding and on/off flag. Edges are created between vortices that are separated by at most root-two the average of the inter-vortex spacings. A finite boundary is chosen to examine only vortices in areas of significant condensate density, since vortices can easily appear and disappear close to the condensate boundary. Any vortex which appears without association to an initial vortex, or any tracked vortex that crosses the boundary, is switched off and remains so for all analysis. A graph for an initial (*t* = 0) vortex lattice shown in Fig. [fig:graphit], with the identifiers indicated on each node, and the neighbouring distances indicated by the edge weights.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch3_numerics/Graph_full&#34; alt=&#34;Graph of vortex lattice positions indicating the vortex identifier and the intervortex distances in units of grid-spacing \Delta= \Delta x = \Delta y. A hard-walled boundary is chosen such that the vortex distances remain almost uniform, and are shown here with a mean value of \bar{r} = 30.2451 and variance of \sigma^2 = 0.16118.&#34; style=&#34;width:98.0%&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;bose-einstein-condensate-dynamics-1&#34;&gt;Bose–Einstein condensate dynamics&lt;/h1&gt;

&lt;p&gt;[sec:vortlatt]&lt;/p&gt;

&lt;p&gt;The purpose of this chapter is to introduce the reader to vortex states of BECs, and eventually discuss manipulations of these states. In the following sections we will examine both the static and the dynamical solutions of the Gross–Pitaevskii equation (GPE), using the methods previously discussed. We will first briefly discuss few vortex solutions, with an analysis of their properties via an examination of the velocity field.&lt;/p&gt;

&lt;p&gt;We will follow this by providing the details of the model system of a vortex lattice in a rapidly rotating BEC, using the theoretical framework developed in Chapter [chp:background]. Next, we will discuss the application of two distinct ways for manipulating and controlling the condensate: (1) applying an external potential to the trapped condensate for a short timescale, and (2) direct manipulation of the wavefunction phase. Both of these are experimentally realistic, and though they can be experimentally implemented by similar means, they serve two very different purposes, and they will be treated as such.&lt;/p&gt;

&lt;h2 id=&#34;simulating-bose-einstein-condensate-dynamics&#34;&gt;Simulating Bose–Einstein condensate dynamics&lt;/h2&gt;

&lt;p&gt;In Sections [sub:gpederiv] and [sec:fso] we have outlined both the analytical Thomas–Fermi (TF) and numerical solutions of the GPE. It is instructive to compare the results from these two methods. For a stationary condensate in the ground state of a harmonic trapping potential the profile and width should be comparable, with the TF solution deviating only in the low-density regions. Fig. [fig:gpe_tf_3] shows a comparison of the two-dimensional profile for both methods, for condensates of &lt;strong&gt;&lt;sup&gt;87&lt;/sup&gt;Rb with *N* = 10&lt;sup&gt;5&lt;/sup&gt; atoms, and trapping frequencies of &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;/strong&gt;r**&lt;/sub&gt; = 2*π* × (1, 1, 16) Hz. Both solutions show good agreement, deviating only where expected, and hence showing a well developed numerical procedure.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;Images/ch4_vtx/gpe_tf_3.pdf&#34; /&gt;&lt;/p&gt;

&lt;p&gt;While the Thomas–Fermi solution closely agrees with the numerical solution of the Gross–Pitaevskii equation, this solution is only applicable for stationary states with negligible kinetic energy, i.e. when the nonlinear interaction dominates over the kinetic energy term. For more complex problems involving dynamics, full numerical integration of the Gross–Pitaevskii equation is required.&lt;/p&gt;

&lt;p&gt;One example where the TF approach fails is when investigating superfluid vortex dynamics. To generate vortices in the condensate angular momentum must be added to the system. Seeding a single vortex in the condensate requires that the frequency of rotation, &lt;em&gt;Ω&lt;/em&gt;, must be higher than the critical rotation frequency &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt;, as discussed in Sec. [ss:vorticesinbec], and numerically, this is most easily simulated in the co-rotating frame as given by Eq. . Experimentally, there are many ways to create vortices in a condensate, such as stirring with a blue-detuned laser beam , carefully inverting the trap bias field potential , or through the use of artificial gauge fields , to name but a few. In the next sections we will concentrate on solutions where the vortices are already present in the condensate and have settled into the lowest energy configuration.&lt;/p&gt;

&lt;h3 id=&#34;few-vortex-condensates&#34;&gt;Few vortex condensates&lt;/h3&gt;

&lt;p&gt;As discussed in Section [sec:superfluid], the study of quantum vortices remains an active area of research. As the condensate kinetic energy scales as &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; ∝ &lt;em&gt;l&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; (Sec. [ss:vorticesinbec]), increased angular momentum leads to the appearance of more singly charged vortices rather than one multiply charged vortex. For a single vortex in a rotating condensate the only stationary solution that exists is if the vortex resides at the exact centre of the trapping potential, making the system radially symmetric. For two vortices the radial symmetry of the system is broken, with the two vortices arranging themselves in the most favourable position to minimise the energy of the system, as with all higher vortex states. Placing vortices of the same sign into a condensate will allow them to behave as identically charged particles, and they will repel, and form ordered lattices with increasing vortex numbers (see Fig. [fig:few_rho]). Similarly, if instead we pair a vortex and an antivortex, they will attract, and remain in constant motion, or disappear altogether in the presence of dissipation.&lt;/p&gt;

&lt;p&gt;This stability and dynamical behaviour can be understood by examining the velocity fields of the vortices, as shown in Fig. [fig:vel_field] for like-signed vortices, and Fig. [fig:vel_pm] for a vortex-antivortex pair. The velocity fields of the vortices are additive, which for like-signed windings creates regions of zero flow, and for opposite-windings creates large flows between them respectively. From Eq. [eqn:1_over_r] the velocity field of the irrotational quantum vortex scales as *v* ∝ 1/&lt;em&gt;r&lt;/em&gt;, and hence becomes singular at the vortex centre, giving rise to the large velocities close to the singularity. Fig. [fig:vel_pm_contour] shows a clearer view of the velocity fields as depicted by Fig. [fig:vel_field], where the presence of maxima is easily observed at the cores, with field minima also observed due to the vortex-vortex interactions.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;Images/ch4_vtx/fewvortex_rho.pdf&#34; title=&#34;fig:&#34; style=&#34;width:48.0%&#34; /&gt; &lt;embed src=&#34;Images/ch4_vtx/fewvortex_theta.pdf&#34; title=&#34;fig:&#34; style=&#34;width:48.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/velocity/velocity_fixedmag&#34; alt=&#34;Magnitude of the velocity field and the direction of rotation of the field for clockwise circulating vortices. As the velocity follows a 1/r profile the magnitude becomes singular at the centre of the vortices, which is capped here at v=2.4\times 10^{-3} (ms^{-1}).&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/vtx_anti_velfield&#34; alt=&#34;Velocity field direction and magnitude originating from vortex and antivortex present in a condensate. Colour scale is in units of (ms^{-1}).&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/vtx_anti_velfield&#34; title=&#34;fig:&#34; alt=&#34;(Left) Velocity field originating from vortex and antivortex present in a condensate. (Right) Trajectories of vortex and antivortex in a condensate in the lab frame. Vortices travel on circulating paths which will always intersect through their starting position. Color is used to represent the same times for both vortex and antivortex, which is on the order of seconds.&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;Images/ch4_vtx/vtx_antivtx_traj&#34; title=&#34;fig:&#34; alt=&#34;(Left) Velocity field originating from vortex and antivortex present in a condensate. (Right) Trajectories of vortex and antivortex in a condensate in the lab frame. Vortices travel on circulating paths which will always intersect through their starting position. Color is used to represent the same times for both vortex and antivortex, which is on the order of seconds.&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/velocity/vel.png&#34; alt=&#34;Magnitude of the velocity field for small numbers of like-signed vortices in a condensate. The velocity field can be seen to become singular at the centre, which here has its magnitude capped at a lower value than Figs. [fig:vel_field] and [fig:vel_pm] to aid visibility. Regions of minimal velocity are seen, wherein the opposing field lines compensate one another.&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;rapidly-rotating-vortex-lattice&#34;&gt;Rapidly rotating vortex lattice&lt;/h2&gt;

&lt;h3 id=&#34;model-system&#34;&gt;Model system&lt;/h3&gt;

&lt;p&gt;For the work to follow we assume a standard single component Bose–Einstein condensate in a radially symmetric trap of frequency &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; = 2*π* × 1 Hz. By tightly confining the condensate along the &lt;em&gt;z&lt;/em&gt;-dimension, with trapping frequency &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; = 2*π* × 16 Hz, such that &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; is greater than &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, the condensate enters the desired pancake-shaped geometry. The system is then modelled using the mean-field GPE Hamiltonian as
$$\label{eqn:gpe_h0}
    H_{\mathrm{GP}} = -\frac{\hbar^2}{2m}\nabla^2 + \frac{1}{2}m\omega_{\perp}^2\mathbf{r}^2 + g_{\textrm{2D}}\vert\Psi(\mathbf{r},t)\vert^2.$$&lt;/p&gt;

&lt;p&gt;Here, we define the two-dimensional effective interaction strength &lt;em&gt;g&lt;/em&gt;&lt;sub&gt;2D&lt;/sub&gt; given by Eq. , as
$$g_{\textrm{2D}} = g\sqrt{\frac{m\omega_z}{2\pi\hbar}} = 4g \sqrt{\frac{m}{\hbar}}.$$&lt;/p&gt;

&lt;p&gt;To describe the system we enter the co-rotating frame, which is done by including the angular momentum operator &lt;em&gt;L&lt;/em&gt;&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt; in the Hamiltonian. The time dependent dynamics of the system are then given by the GPE as
iℏ∂&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=[&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;GP&lt;/sub&gt;−*Ω&lt;strong&gt;L*&lt;sub&gt;&lt;em&gt;z&lt;/em&gt;&lt;/sub&gt;]&lt;em&gt;Ψ&lt;/em&gt;(&lt;/strong&gt;r**, &lt;em&gt;t&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;If the angular rotation frequency approaches the condensate trapping frequency, *Ω* ≈ &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, the condensate gains a large triangular lattice of vortices. The effect of setting *Ω* = &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, can be partially understood in a mean-field setting by rewriting the GPE kinetic and rotation terms in the form
$$\frac{\mathbf{p}^2}{2m} + \frac{m\Omega\mathbf{r}^2}{2} - \Omega L_z = \frac{\mathbf{\left(p -{\textit{ m}}\boldsymbol{\Omega}\times\mathbf{r}\right)^2}}{2m}.$$&lt;/p&gt;

&lt;p&gt;The resulting changes to the GPE are then given by
$$\label{eqn:vector_potential_gpe}
    \textrm{i}\hbar\partial_t \Psi =
    \left(\frac{1}{2m}(-i\hbar\nabla - m\boldsymbol{\Omega}\times\mathbf{r})^2 + \frac{m}{2}(\omega_\perp^2 - \Omega^2){r}^2 + g_{\textrm{2D}}|\Psi|^2 \right)\Psi.$$
 The above Hamiltonian demonstrates the correspondence between a rotating condensate and that of a non-relativistic charged particle in a magnetic field . One can see that when the rotation and trapping frequencies are equal, the condensate no longer sees a confining potential, due to the centrifugal force experienced, given by the term −*m*&lt;em&gt;Ω&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;em&gt;r&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;/2.&lt;/p&gt;

&lt;p&gt;As stated earlier in Sec. [sec:sec2_vtxlatt] as &lt;em&gt;Ω&lt;/em&gt; approaches &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, the use of mean-field theory becomes less justified, and the system enters a strongly correlated regime. If the filling fraction &lt;em&gt;ν&lt;/em&gt; is in the range of 10 ≤ *ν* ≤ 1000, the system enters the “mean-field quantum Hall” regime, where the Gross–Pitaevskii theory is still working well. The system examined here is well within this regime for a frequency of *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;. This allows us to work with systems that have a very large vortex lattice, and are still described by mean-field theory .&lt;/p&gt;

&lt;p&gt;In the following we will numerically solve Eq. , using the pseudospectral Fourier split operator method and making use of GPU computing as described in Sec. [sec:GPUE]. For realistic experimental parameters we assume *N* ≈ 10&lt;sup&gt;6&lt;/sup&gt; atoms of **&lt;sup&gt;87&lt;/sup&gt;Rb, with an &lt;em&gt;s&lt;/em&gt;-wave scattering length of &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;s&lt;/em&gt;&lt;/sub&gt; = 4.76 × 10&lt;sup&gt;−9&lt;/sup&gt; m . The numerically evaluated ground-state for the given set of parameters is shown previously in Fig. [fig:showingoff] and has a radius of approximately 3.5 × 10&lt;sup&gt;−4&lt;/sup&gt; m. For these parameters, the number of vortices within the visible density region is approximately 600, giving a filling factor of *ν* ≈ 800. This places the system within the mean-field quantum Hall regime, and therefore a description using Gross–Pitaevskii theory is adequate .&lt;/p&gt;

&lt;p&gt;Following an imaginary time-evolution as outlined in Sec. [sec:timeev], we first find the ground state of the condensate in a harmonic potential, starting with a condensate without vortices. We then linearly ramp the rotation frequency to avoid the lattice disordering issue discussed in Sec. [ss:ang_mom_fso]. This allows us to follow the ground state solution at all times while the rotation frequency is increased, which has the added advantage of returning a ground state solution for any required rotation frequency. Examples of several states obtained during a single simulation are given in Fig. [fig:inc_omega]. The previously discussed resolution considerations become apparent as the rotation rate is increased for both the position and momentum space representations of the wavefunction. A movie of the wavefunction density is available at the following URL , in which the frequency is ramped from &lt;em&gt;Ω&lt;/em&gt;/&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; = 0.39 → 0.995.&lt;/p&gt;

&lt;p&gt;The rapidly rotating vortex lattice is known to exhibit solid-body-like rotation . This can be seen in Fig. [fig:solidbody], where the coarse-grained flow of the velocity field increases as a function of the distance from the lattice centre. This rigid-body behaviour allows us to treat the lattice as a solid object. Recalling the Feynman relation for vortex density Eq. , &lt;em&gt;n&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; = *m*&lt;em&gt;Ω&lt;/em&gt;/(*π*ℏ), we choose an area over which the lattice spacing is almost constant and the vortex density closely matches this relation. In this rapidly rotating regime the vortices close to the centre will have an almost uniform profile ; for the above system parameters this is fulfilled by a hard-walled radial boundary of *r* = 2 × 10&lt;sup&gt;−4&lt;/sup&gt; m, in which the number of vortices are calculated to being &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; ≈ 342. Employing the vortex detection and tracking methods described in Sec. [sec:vortrack], within the same region gives &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; = 341 vortices, with a lattice spacing of &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; ≈ 2.1 × 10&lt;sup&gt;−5&lt;/sup&gt; m, and with a standard deviation of *σ* ≈ 2.7 × 10&lt;sup&gt;−7&lt;/sup&gt; m. These values indicate that within this region the lattice is well ordered. While the condensate has more vortices outside this boundary that are initially ordered, during time evolution many of these move more easily due to the large velocity fields closer to the edges. The above boundary gives a well ordered lattice that remains well ordered for several seconds of time evolution.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;Images/ch4_vtx/ramp_omega_2.pdf&#34; style=&#34;width:85.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If, however, the linear ramp is performed too quickly, or an initial state is chosen that already contains a large amount of angular momentum without being the eigenstate, the vortices tend to enter from the boundary all at once, and fail to converge to the well ordered ground state. A demonstration of this such issue is shown in Fig. [fig:malformed_lattice], and indicates the need for a slow ramp of &lt;em&gt;Ω&lt;/em&gt; that is essentially adiabatic in imaginary time. As higher rotation frequencies are reached, the rate at which vortices enter the condensate increases rapidly. While the rapid entry of vortices was a problem for reaching an ordered lattice without a ramp of rotation frequency, the presence of an existing lattice during ramping allows all newly entered vortices to order more easily. Therefore, a linear ramp is effective and does not require a more complex scaling.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/toofast_099_1e7&#34; alt=&#34;Disordered lattice resulting from starting in imaginary time evolution at the required rotation rate (here \Omega=0.99\omega_\perp). If the rotation frequency is chosen too large without allowing the lattice to form and order, the resulting vortices all enter instantaneously and compete for their final positions. The system only converges one timescales that exceed reasonable computing times.&#34; style=&#34;width:65.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the following section we will discuss perturbations of the condensate in the presence and absence of vortices. For the above system, we will investigate the effect of perturbations to both the global and local condensate order due to changes in the lattice structure.&lt;/p&gt;

&lt;h2 id=&#34;condensate-perturbations&#34;&gt;Condensate perturbations&lt;/h2&gt;

&lt;h3 id=&#34;trapping-potential-control&#34;&gt;Trapping potential control&lt;/h3&gt;

&lt;p&gt;With the model system outlined in Sec. [sec:modelsystem], we will now imagine an abrupt change to the Hamiltonian, such that, &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;GP&lt;/sub&gt; + &lt;em&gt;f&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;)&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;, where &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt; is an external potential, and &lt;em&gt;f&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;) is some function of time to control the application of &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;. In this scenario the initial wavefunction, which is a stationary state of &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;GP&lt;/sub&gt;, will no longer remain so provided that &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;GP&lt;/sub&gt; and &lt;em&gt;f&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;)&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt; are non-commuting. Assuming the time of application of the additional term is much shorter than any other timescale of the condensate dynamics, any modification of the Hamiltonian in this way can be viewed as a method for changing the phase of the wavefunction. The resulting effect on the wavefunction can be given as&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \Psi(t=0) &amp;amp;= |\Psi(t=0)|e^{\textrm{i}\theta_0} \&lt;br /&gt;
    \Psi(t) &amp;amp;= \Psi(t=0) e^{ - \textrm{i} \frac{ V_{\textrm{ext}} \Delta t}{\hbar}} \&lt;br /&gt;
            &amp;amp;= |\Psi(t=0)| e^{\textrm{i}\left(\theta_0 - \frac{V_{\textrm{ext}} \Delta t}{\hbar}\right)} \nonumber\end{aligned}$$&lt;/p&gt;

&lt;p&gt;where we have made use of Eq. . After application of &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt; the wavefunction phase is given by
$$\theta^{&amp;lsquo;} = \theta_0 - \frac{E_{\textrm{ext}} \Delta t}{\hbar},$$
 where &lt;em&gt;E&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt; is the perturbance energy. One commonly used method to manipulate the condensate is through the use of optical potentials, which offer a large degree of control over the respective system’s Hamiltonian . The electric field component of an arbitrary optical field, described by a wavevector &lt;strong&gt;k&lt;/strong&gt;, and frequency, &lt;em&gt;ω&lt;/em&gt; is given by
&lt;strong&gt;E&lt;/strong&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;ε&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;i(&lt;strong&gt;k&lt;/strong&gt;⋅&lt;strong&gt;r&lt;/strong&gt;−*ω&lt;strong&gt;t*)&lt;/sup&gt; +  &lt;em&gt;ε&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i(&lt;/strong&gt;k&lt;strong&gt;⋅&lt;/strong&gt;r&lt;strong&gt;−*ω&lt;/strong&gt;t*)&lt;/sup&gt;,
 where &lt;em&gt;ε&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; is the field amplitude. Using the dipole approximation, the interaction of an atom with a laser field is given by 
𝒱 = −&lt;strong&gt;d&lt;/strong&gt; ⋅ &lt;strong&gt;E&lt;/strong&gt;,
 where &lt;strong&gt;d&lt;/strong&gt; is the electric dipole moment operator. For a two level atom with a ground state |*g*⟩, and an excited state |*e*⟩ with energy difference ℏ&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, the dipole operator can be written as
$$\begin{aligned}
\label{eqn:dipole_approx}
\mathbf{d} &amp;amp;= \langle g|\mathbf{d}|e \rangle | g \rangle \langle e | + \langle e|\mathbf{d}|g \rangle | e \rangle \langle g | \nonumber \&lt;br /&gt;
&amp;amp;= \boldsymbol{\mu}_{eg} | g \rangle \langle e | + \boldsymbol{\mu}_{eg}^{*} | e \rangle \langle g |,\end{aligned}$$
 where we have made use of ⟨&lt;em&gt;g&lt;/em&gt;|&lt;strong&gt;d&lt;/strong&gt;|*g*⟩=⟨&lt;em&gt;e&lt;/em&gt;|&lt;strong&gt;d&lt;/strong&gt;|*e*⟩=0, since the atoms have no permanent dipole moment. From Eq.  the Hamiltonian of the two-level system can then be written as
$$\begin{aligned}
\label{eqn:dip_hamiltonian}
    H &amp;amp;= H_0  + \mathcal{V} \nonumber \&lt;br /&gt;
      &amp;amp;=  \hbar\omega_0 |e\rangle\langle e | - (\boldsymbol{\mu}_{eg} | g \rangle \langle e | + \boldsymbol{\mu}_{eg}^{*} | e \rangle \langle g |)\cdot ( \varepsilon_0 e^{\textrm{i}\left(\mathbf{k}\cdot\mathbf{r} - \omega t\right)} +  \varepsilon_0^{*} e^{-\textrm{i}\left(\mathbf{k}\cdot\mathbf{r} - \omega t\right)}).\end{aligned}$$
 After expanding  we can then rewrite &lt;strong&gt;μ&lt;/strong&gt;&lt;sub&gt;*e*&lt;em&gt;g&lt;/em&gt;&lt;/sub&gt; ⋅ &lt;em&gt;ε&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; = ℏ&lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sub&gt;, where &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sub&gt; is the Rabi-oscillation frequency between the states. Assuming that the detuning *Δ* = *ω* − &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; between the laser field and transition frequency is small, *Δ* ≪ *ω* + &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, allows use of the rotating wave approximation. For this we first perform a unitary transformation of the system into the interaction picture rotating with &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; using the operator *U* = &lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;em&gt;t&lt;/em&gt;|*e*⟩⟨&lt;em&gt;e&lt;/em&gt;|&lt;/sup&gt; as
$$\begin{aligned}
    H_{\textrm{int}} &amp;amp; = U^{\dagger} \mathcal{V} U.\end{aligned}$$
 All resulting terms featuring *ω* + &lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; can be considered to be rapidly oscillating, and average out to zero. Following this approximation, the Hamiltonian can be transformed back into the Schrödinger picture, giving
$$\begin{aligned}
 H^{&amp;lsquo;} = \hbar\omega_0 - \hbar\Omega\left(e^{\textrm{i}\omega t}|e\rangle\langle g|   + e^{-\textrm{i}\omega t}|g\rangle\langle e|  \right).\end{aligned}$$
 The final shift of the energies is then given as
$$\label{eqn:acshift}
\mathcal{V} = -\frac{\alpha}{2}\langle \mathbf{E}^2\rangle_t ,$$
 where &lt;em&gt;α&lt;/em&gt; is the real component of the atomic polarisability, and ⟨ ⋅ ⟩&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; denotes the time average. If the electric field is spatially inhomogeneous, then this leads to a force of the form
$$\mathbf{F}_d = \frac{\alpha}{2}\nabla\langle \mathbf{E}^2 \rangle_t ,$$
 which is known as the dipole force. Assuming counter propagating plane waves, we can then model a standing wave solution of the resulting optical potential as
$$V_{\textrm{ext}} \approx -\frac{\Omega_0^2(\mathbf{r})}{4\Delta}  = V_0 \cos^2 (\mathbf{k} \cdot \mathbf{r}),$$
 where &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; = −&lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;/4&lt;em&gt;Δ&lt;/em&gt; is the field intensity, and &lt;em&gt;Ω&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; ∝ |&lt;em&gt;ε&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;|&lt;sup&gt;2&lt;/sup&gt; is the Rabi-frequency of the standing wave. The optical potential forms a highly periodic system given an appropriately chosen &lt;strong&gt;k&lt;/strong&gt;, and is known as an &lt;em&gt;optical lattice&lt;/em&gt;. Optical lattices have become very common in BEC experiments as they allow for control of the kinetic energy term of the atoms to a very high degree .&lt;/p&gt;

&lt;p&gt;Different geometric potentials can be formed with optical lattices by using laser fields with different &lt;strong&gt;k&lt;/strong&gt; vectors. Assuming standing waves with different polarisation axes or slightly different wavelengths, the interference effects between two or more fields can be ignored, with the resulting optical field given by the summation of lattice potentials with wavevectors &lt;strong&gt;k&lt;/strong&gt;&lt;sub&gt;1, ..,&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;. Creating a 2D lattice with &lt;em&gt;n&lt;/em&gt;-fold rotational symmetry requires &lt;em&gt;n&lt;/em&gt;/2 &lt;strong&gt;k&lt;/strong&gt;-vectors separated by 2&lt;em&gt;π&lt;/em&gt;/&lt;em&gt;n&lt;/em&gt;, and with &lt;em&gt;n&lt;/em&gt;/2 ∈ ℤ&lt;sup&gt;+&lt;/sup&gt;. Taking a square lattice as an example, which has a 4-fold rotational symmetry, it can be created by two &lt;strong&gt;k&lt;/strong&gt;-vectors, separated by &lt;em&gt;π&lt;/em&gt;/2, as
$$\mathbf{k}_0 = \left[ \begin{array}{cc}
    1 \&lt;br /&gt;
    0
    \end{array} \right],~
    \mathbf{k}_1 =
    \left[ \begin{array}{cc}
     0 \&lt;br /&gt;
     1
    \end{array} \right].\label{eqn:sqlatt}$$
 The resulting potential is shown in Fig. [fig:cos2xy].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./Images/ch4_vtx/VOPT/squarelatt&#34; alt=&#34;Square lattice generation using two orthogonal propagating laser fields with wavevectors \mathbf{k}_1 and \mathbf{k}_2, as defined by Eq. .&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The time the optical lattice is applied to the condensate can be controlled by choosing the function &lt;em&gt;f&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;). Applying a lattice for a finite, but short, time only will lead to a modification of the wavefunction phase, which then subsequently, and on a much longer time-scale, will have an effect on the density distribution. Of particular interest to us is the use of an optical potential that is pulsed one or several times, which can be described by &lt;em&gt;f&lt;/em&gt;(&lt;em&gt;t&lt;/em&gt;) as a periodic delta function. The condensate phase profile is the only quantity immediately modified, and any change in the density distribution appears only in the following evolution.&lt;/p&gt;

&lt;p&gt;For the purpose of my system, we intend to create a two-dimensional optical lattice, wherein the structure of the lattice matches that of the triangular Abrikosov vortex pattern. The triangular lattice has 6-fold rotational symmetry, and can be formed with wavevectors&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
        \mathbf{k}_1 &amp;amp;= k_0\left\{\frac{\sqrt(3)}{2},\frac{1}{2}\right\} \&lt;br /&gt;
        \mathbf{k}_2 &amp;amp;= k_0\{0,1\} \&lt;br /&gt;
        \mathbf{k}_3 &amp;amp;= k_0\left\{\frac{\sqrt(3)}{2},-\frac{1}{2}\right\} \&lt;br /&gt;
    \end{aligned}$$&lt;/p&gt;

&lt;p&gt;where $k_0 = 4\pi/(\sqrt(3)a_\text{O})$, and &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;O&lt;/sub&gt; is the lattice spacing.&lt;/p&gt;

&lt;h3 id=&#34;direct-phase-manipulation&#34;&gt;Direct phase manipulation&lt;/h3&gt;

&lt;p&gt;While ground state condensates will have a flat phase across the system, there are two interesting examples where a spatially dependent phase exists: dark solitons  and vortices . We have previously discussed the 2&lt;em&gt;π&lt;/em&gt; phase profile of a vortex that leads to the singularities in the wavefunction. In contrast, dark solitons feature a &lt;em&gt;π&lt;/em&gt; phase jump profile. These excitations are unstable in dimensions higher than one, and will decay via the snake instability to paired vortices and antivortices . Where so far we have only considered the short-term evolution of the wavefunction after being kicked by an optical potential, we will in the following consider what structures can be created in the condensate by careful phase manipulation techniques, besides dark solitons and vortices.&lt;/p&gt;

&lt;p&gt;For this we will assume that the BEC allows for a short enough application of potentials so that only the phase is affected, and discuss direct manipulation of the wavefunction, as opposed to modification of the Hamiltonian. Following and taking Eq. , the phase of the condensate can then be written as
*θ* = &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; + &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;,&lt;/p&gt;

&lt;p&gt;where &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; is the unperturbed condensate phase, and &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; is the phase pattern to be imprinted. Upon solving for the initial condensate ground state with deterministic phase, an additional phase pattern can be imprinted at any time by simply multiplying the wavefunction by &lt;em&gt;e&lt;/em&gt;&lt;sup&gt;i&lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/sup&gt;. However, without careful choice of the phase terms their addition can lead to unwanted dynamics, so care must be taken to choose a well defined initial and imprinted phase pattern.&lt;/p&gt;

&lt;p&gt;The advantage of the phase imprinting model is that for topological defects, one can imprint the required winding instantaneously, allowing them to appear at predefined positions. The density also needs to only adjust itself locally to the phase singularity, with the remaining condensate seeing an almost constant shift in phase. The creation of vortices through application of localised ±2&lt;em&gt;π&lt;/em&gt; phase winding defects in the condensate therefore allows for direct control of the angular momentum and vorticity within the BEC. While discussed in the literature for the creation of vortices, it is worth noting that the phase imprinting method can also be used to annihilate a vortex from the condensate by applying a phase profile of opposite winding, removing the singularity. This will leave the condensate with a density depletion at the prior location of the phase singularity. Without the phase singularity this depletion will fill in and excite phonon modes in the condensate during time evolution. This process will form the basis for further discussions and analysis of vortex carrying condensates.&lt;/p&gt;

&lt;p&gt;Experimental realisation of arbitrary potential patterns to achieve the required phase is accessible through the use of spatial light modulators (SLM) . These devices behave as digital displays, through which visual patterns can be expressed in a time dependent manner, allowing the application of a laser field in the required form. We will assume for all future discussions that the potentials we require are experimentally realisable with sufficient resolution, and focus on the resulting effect on the condensate. For the creation of a single vortex the 2&lt;em&gt;π&lt;/em&gt; phase winding pattern can be created spatially using the two-argument four-quadrant form of arctan as given by
&lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(&lt;strong&gt;x&lt;/strong&gt;, &lt;strong&gt;y&lt;/strong&gt;; &lt;em&gt;x&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, &lt;em&gt;y&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;)=arctan(&lt;strong&gt;y&lt;/strong&gt; − &lt;em&gt;y&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;, &lt;strong&gt;x&lt;/strong&gt; − &lt;em&gt;x&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;),
 which locates the singularity at the position (&lt;em&gt;x&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;,&lt;em&gt;y&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;). The resulting phase is shown in Fig. [fig:atan2phase](left), and including the additional phase singularity term &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;, the condensate wavefunction following an imprint is given as
&lt;em&gt;Ψ&lt;/em&gt;&lt;sup&gt;′&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=|&lt;em&gt;Ψ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)|&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;i(&lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)+&lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;))&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;Images/ch4_vtx/2pi.pdf&#34; title=&#34;fig:&#34; style=&#34;width:45.0%&#34; /&gt; &lt;embed src=&#34;Images/ch4_vtx/3_2pi.pdf&#34; title=&#34;fig:&#34; style=&#34;width:43.5%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Following the imprint this process will create phonons in the condensate density that will radiate outwards from the singularity imprint. As imprinting is directly controlling the condensate phase, it can also be considered a direct manipulation of the kinetic energy since the superfluid velocity depends on the phase gradient (see Eq. ). This, in reverse, means that by applying spatially inhomogeneous phase profiles the atomic velocity can be adjusted to different values in different regions of the condensate. To demonstrate this we consider a simple example of a Gaussian phase profile applied to the condensate. The imprinted profile has the form
$$\theta_{i}(\mathbf{r}) = A\exp\left( -\frac{ |\mathbf{r}-\mathbf{r}_0|^2 }{2\sigma^2 } \right) \mod 2\pi,$$
 where &lt;em&gt;A&lt;/em&gt; is the phase profile amplitude, &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt; is the centre of the Gaussian curve, and &lt;em&gt;σ&lt;/em&gt; is adjusted to match the condensate width. The modulo 2&lt;em&gt;π&lt;/em&gt; ensures that the phase wraps around for amplitudes exceeding the (0, 2&lt;em&gt;π&lt;/em&gt;) range. The Gaussian profile has large radial gradients in two-dimensions, so that an imprint on the condensate should lead to radial velocities and therefore an expansion or contraction of the cloud (see Fig. [fig:gaussian]). This can be expected to lead to interference fringes, as the faster moving atoms have the possibility to overtake the slower ones for sufficiently large amplitudes . In Fig. [fig:gaussian_wfc], where a slice through the condensate centre is given for both position and momentum space, this can be clearly seen.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/velocity/gaussian_imprint&#34; alt=&#34;Velocity fields and magnitude (left) and phase (right) for a condensate directly following a Gaussian phase imprint. The lengths of the arrows give the magnitude of the respective velocity components, with the color map indicating this also for clarity. The sign of the imprint changes the direction of the respective kinetic components, with a positive imprint initially creating a density contraction (top), and negative creating an expansion (bottom), with the arrows indicating the direction of the flow.&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/gaussian_imprint_B&#34; alt=&#34;A cut through the condensate wavefunction density following the phase imprinting of a Gaussian with amplitudes A=\pm ( 2\pi, 6\pi, 10\pi). The positive imprints create an initial contraction of the cloud (top), while the negative imprints lead to expansion (bottom). For the larger kicking strengths interference fringes can be observed during expansion and contractions.&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;condensate-analysis&#34;&gt;Condensate analysis&lt;/h2&gt;

&lt;p&gt;To analyse the effects of the phase imprinting we will below introduce the decomposition of the kinetic energy to isolate the effect from phonons and vortices. Following this, for the vortex lattice we will introduce two closely linked methods to examine geometric structure — Delaunay triangulation and Voronoi tessellation. These methods are dual to one another, and can be used to easily identify order, structure and local parameters within systems of many particles.&lt;/p&gt;

&lt;h3 id=&#34;kinetic-energy-decomposition&#34;&gt;Kinetic energy decomposition&lt;/h3&gt;

&lt;p&gt;Given that the phase engineering modifies the condensate kinetic energy profile, it is instructive to quantify this effect. One can apply a spectral decomposition of the kinetic energy of the condensate into contributions solely from the vortices (incompressible), and those from the phonons (compressible) . For this, the wavefunction is again written in terms of amplitude $\sqrt{\rho(\mathbf{r},t)}$ and phase &lt;em&gt;S&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;), which allows the kinetic part of the Gross–Pitaevskii energy functional Eq.  to be calculated as
$$E_{\text{kqp}} = \int d\mathbf{r} \left( \frac{\hbar^2}{2m}| \nabla\sqrt{\rho(\mathbf{r},t)} |^2  + \frac{m}{2}|\sqrt{\rho(\mathbf{r},t)}\mathbf{v}(\mathbf{r},t) |^2\right).$$
 One can then decompose this into the quantum pressure (first) and kinetic energy (second) terms. The kinetic energy term can be seen as a density-weighted velocity field, $\mathbf{u}(\mathbf{r},t) = \sqrt{\rho(\mathbf{r},t)}\mathbf{v}(\mathbf{r},t)$, and it can be further decomposed into the sum of compressible and incompressible terms,
&lt;strong&gt;u&lt;/strong&gt;&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)+&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;).
 The two terms can be calculated by performing a Helmholtz decomposition of the field &lt;strong&gt;u&lt;/strong&gt;, which separates terms that are longitudinal (&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt;) and transversal (&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;) with&lt;/p&gt;

&lt;p&gt;[eqn:kinterms]
$$\begin{aligned}
    \nabla \times \mathbf{u}^c(\mathbf{r},t) &amp;amp;= 0, \&lt;br /&gt;
    \nabla \cdot \mathbf{u}^i(\mathbf{r},t) &amp;amp;= 0.\end{aligned}$$&lt;/p&gt;

&lt;p&gt;By introducing the vector potential, &lt;strong&gt;A&lt;/strong&gt;, and the scalar potential, &lt;em&gt;B&lt;/em&gt;, such that&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \mathbf{u}^c = \nabla B, \&lt;br /&gt;
    \mathbf{u}^i = \nabla \times \mathbf{A},\end{aligned}$$&lt;/p&gt;

&lt;p&gt;we can rewrite Eq.  as
$$\begin{aligned}
    \nabla \times \mathbf{u}(\mathbf{r},t) = -\nabla^2 \mathbf{A}, \&lt;br /&gt;
    \nabla \cdot \mathbf{u}(\mathbf{r},t) = \nabla^2 {B}.\end{aligned}$$&lt;/p&gt;

&lt;p&gt;To solve the above equation we begin by seeking a solution for &lt;em&gt;B&lt;/em&gt; by performing a spectral decomposition of the full density-weighted velocity field as
$$B = \displaystyle\sum\limits_{j} \frac{k_j}{|\mathbf{k}|^2}\mathscr{F}[\mathbf{u}],$$
 where &lt;em&gt;k&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; is the &lt;em&gt;j&lt;/em&gt;-th component in &lt;strong&gt;k&lt;/strong&gt; space, and ℱ is the Fourier transform. The resulting solution for &lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt; is then given by
$$\mathscr{F}[\mathbf{u}_i^c] = \displaystyle\sum\limits_{j} \frac{k_i k_j}{|\mathbf{k}|^2} \mathscr{F}[\mathbf{u}],$$
 which after taking note of Eq.  gives
$$\begin{aligned}
    \mathscr{F}[\mathbf{u}_i^i] &amp;amp;= \mathscr{F}[\mathbf{u}_i] - \mathscr{F}[\mathbf{u}_i^c]. \&lt;br /&gt;
    &amp;amp;= \displaystyle\sum\limits_{j}\left(\delta_{i,j} - \frac{k_ik_j}{|\mathbf{k}|^2}\right)\mathscr{F}[\mathbf{u}_i]. \nonumber\end{aligned}$$&lt;/p&gt;

&lt;p&gt;This decomposition separates the energy contribution from phonons and vortex cores, represented by compressible and incompressible terms respectively . By averaging over binned shells in &lt;strong&gt;k&lt;/strong&gt;-space, the kinetic energy spectra, &lt;em&gt;E&lt;/em&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;em&gt;k&lt;/em&gt;), are calculated as 
$$\label{eqn:kin_spec_ic}
    E^{c,i}(k) = \frac{mk}{2}\sum\limits_{j\in\mathbf{r}} \int\limits_{0}^{2\pi}d\phi_k \frac{ |\mathcal{U}_j^{c,i}(\mathbf{k},t) |^2}{s_k},$$
 where
𝒰&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;k&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=∫&lt;em&gt;d&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−i(&lt;strong&gt;k&lt;/strong&gt; ⋅ &lt;strong&gt;r&lt;/strong&gt;)&lt;/sup&gt;&lt;em&gt;u&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;).
 The terms &lt;em&gt;u&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) represent the position-space density-weighted velocity components in the specified shell, where &lt;em&gt;ϕ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; is the polar angle, and &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; is the number of values in the chosen shell.&lt;/p&gt;

&lt;h3 id=&#34;delaunay-triangulation-and-voronoi-tessellation&#34;&gt;Delaunay triangulation and Voronoi tessellation&lt;/h3&gt;

&lt;p&gt;A common method for examining the ordering and periodicity of large-scale crystalline structures is to generate a mesh with each vertex being the location of a particle. With this, one can easily observe ordered and disordered regions in a material; well defined straight lines indicate a perfect crystal, with any bends indicating the presence of imperfections. Some of the most widely used methods for this are the dual techniques from computational geometry of Delaunay triangulation and Voronoi tessellation.&lt;/p&gt;

&lt;p&gt;The Delaunay triangulation of an arbitrary set of points in Euclidian space, &lt;strong&gt;R&lt;/strong&gt;, which we will denote as &lt;em&gt;D&lt;/em&gt;(&lt;strong&gt;R&lt;/strong&gt;), is constructed in the following way:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;No point will fall within the interior of any circumcircle of 3 points where &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;1..3&lt;/sub&gt; ⊂ &lt;strong&gt;R&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Delaunay triangulation will maximise the minimum angle between points.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If four points are on the same circumcircle, then both possible configurations give a Delaunay triangulation.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/deltri&#34; alt=&#34;Non-Delaunay (a) and Delaunay (b) triangulation of 4 Euclidian points.&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This concept is more easily explained visually. Fig. [fig:delaun] shows two different triangulations of four points; situation (&lt;em&gt;a&lt;/em&gt;) is a non-Delaunay triangulation, as the points &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt; and &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;3&lt;/sub&gt; each fall within the circumcircle of the other points. However, by simply flipping the central edge from (&lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;, &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;4&lt;/sub&gt;) to (&lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;, &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;3&lt;/sub&gt;) we can see in (&lt;em&gt;b&lt;/em&gt;) that we now have a valid Delaunay triangulation. No point falls within the circumcircle of the other points, and the minimum angle formed is maximised relative to configuration (&lt;em&gt;a&lt;/em&gt;). Following directly from this, one can see that Delaunay triangulation can be used to connect the closest vertices in a network. A nice side-effect of Delaunay triangulation is that one can examine when the number of edges from a vertex deviates from the expected value in the lattice, which is 6 for triangular lattices. This can be a useful means to locate defects in a crystal lattice, and we will make use of this during later discussions. This is performed using the built-in &lt;span style=&#34;font-variant:small-caps;&#34;&gt;MATLAB&lt;/span&gt; function “delaunayTriangulation”, and counting the number of attachments to each individual vertex. A triangulation of the vortex lattice from Fig. [fig:showingoff] within the previously discussed radial boundary of *r* = 2 × 10&lt;sup&gt;−4&lt;/sup&gt; m is shown in Fig. [fig:delaun_vtxlatt].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/Del_tr_VTXLATT&#34; alt=&#34;Delaunay triangulation of the vortex lattice ground state. The vertices away from the condensate boundary have the expected 6-edge structure.&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;An alternative representation, using the dual of the Delaunay triangulation, is that of the Voronoi tessellation (diagram). The characteristic of these diagrams is that they are composed of cells each encompassing an individual vertex, within which all enclosed points are closer to that particular vertex than any other. This representation can be generated from the Delaunay triangulation and vice-versa. Taking the centres of the circumcircles describing the Delaunay triangulations, and connecting these forms the boundaries of the Voronoi cells. A simple generation method can be seen as creating and expanding the radius of circles (or &lt;em&gt;n&lt;/em&gt;-spheres in &lt;em&gt;n&lt;/em&gt;-dimensions) centred on each vertex. Where the circles intersect with one another defines the boundary of each individual cell. An example of a Voronoi diagram compared with a Delaunay triangulation is given by Fig. [fig:Voronoi].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/voronoi&#34; alt=&#34;Comparison of Delaunay triangulation (a) with a Voronoi diagram (b). These graphs are duals, which means that one can be used to generate the other.&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The area of each cell can be used as a metric of the strength of the interaction between particles in a many-body system, but also we may represent quantities local to each region in a system by the colour-scale of each cell. For the vortex lattice as given by Fig. [fig:showingoff], a sample Voronoi diagram is given in Fig. [fig:voron_vtxlatt] with the color representing the area spanned by each Voronoi cell of the lattice.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Images/ch4_vtx/Voronoi_area_VTXLATT&#34; alt=&#34;Voronoi tesselation of the vortex lattice. The area of each cell is represented by the color mapping. To avoid the tessellation tending to infinity, a buffer region of vortices is created close to the boundary. &#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;moiré-superlattice-structures-1&#34;&gt;Moiré superlattice structures&lt;/h1&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;As mentioned in Sec. [ss:pert_opt_latt], the use of optical lattice potentials is ubiquitous in the field of ultracold atoms. Given their near perfect periodic structure, it is interesting to examine the effect these lattices have on already periodic systems. For a rapidly rotating condensate, the density profile will feature a large periodic Abrikosov lattice having 6-fold rotational symmetry i.e. a triangular lattice structure. The use of optical lattices stationary in the co-rotating frame on vortex lattices has previously been shown to allow for pinning of the vortex cores to the lattice maxima . Assuming blue detuned laser fields, the lattice maxima will drive atoms away, and make it favourable for vortex cores to sit in these positions. A transition between lattice geometries can be observed in these cases. This is, however, experimentally challenging as in the lab frame the optical lattice must rotate with the vortex lattice and match its rotation rate. Nevertheless, the creation of a rotating quasi two-dimensional optical lattice was achieved in , where the authors used a rotating mask with the holes placed in such a way as to allow for the required optical diffraction patterns. However, the system suffered from difficulties arising from the inclusion of a mechanically rotating stage, as well as the heating effects due to the presence of the always-on optical lattice. As the vortex lattice has 6-fold rotational symmetry, and assuming the chosen rotation rate of *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, after rotating for *t* ≈ 1/6 s the system has returned to its initial orientation. It is therefore intriguing to see if the need for a rotating optical potential can be replaced by a periodically flashed optical lattice. Here, we will investigate the effect of a single application of an optical lattice to the vortex lattice.&lt;/p&gt;

&lt;p&gt;For short application times, the potential will kick the wavefunction, and can be seen as leaving a phase imprint with minimal immediate density change. As discussed in Sec. [ss:pert_opt_latt], the effect of the kick can then be observed in the ensuing dynamics. Interestingly, one can observe the appearance of moiré interference patterns in the condensate density, while the positions of the vortex cores are only minimally affected. We will begin by discussing the model, and present the explanation of the resulting interference pattern. We will show that it stems from the interference between the different &lt;strong&gt;k&lt;/strong&gt;-vectors, with signatures of the effect being visible in the condensate’s kinetic energy spectrum. Finally, we will discuss the uses of this effect as a microscope for observing the presence of vortex lattices without time-of-flight.&lt;/p&gt;

&lt;p&gt;As already discussed in detail above, given the large number of vortices in the condensate density, as well as the lowered density resulting from the large centrifugal forces, the vortex cores become large and form a highly periodic triangular lattice. The non-orthogonal lattice vectors are given in position space by &lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt; = &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;[1, 0] and $\mathbf{a}_2 = a_v[-&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;, \sqrt{3}/2]$, where &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; is the distance between vortex cores. The lattice “constant” is truly only constant in areas of near uniform density. Thus, due to the inhomogeneous wavefunction density, the vortices near the edges are separated by a slightly larger distance than those at the centre. For the analysis we have therefore chosen to ignore all vortices near the condensate edge. The momentum space (&lt;strong&gt;k&lt;/strong&gt;-space) lattice vectors are reciprocal to the given &lt;strong&gt;r&lt;/strong&gt;-space vectors, and given by $\mathbf{b}_1 = 4\pi/(\sqrt{3}a_v)\left[\sqrt{3}/2,&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;\right]$ and $\mathbf{b}_2 = 4\pi/(\sqrt{3}a_v)\left[0,1\right]$.&lt;/p&gt;

&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;

&lt;p&gt;Using an optical potential one can create a perturbation in the condensate density by switching it on for a brief period of time. Such a kick must occur only for a time much shorter than both the rotation period of the vortex lattice, as well as the inter-vortex spacing divided by the speed of sound in the condensate, so that the effect is limited to a phase imprinting and not to a direct change in the density distribution. For the work carried out herein, the duration of the kick is &lt;em&gt;τ&lt;/em&gt;&lt;sub&gt;kick&lt;/sub&gt; = 10&lt;sup&gt;−5&lt;/sup&gt; s, which is fast compared to the classical rotation period of the 6-fold symmetric lattice of &lt;em&gt;T&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt; ≈ 1.66 × 10&lt;sup&gt;−1&lt;/sup&gt; s. This ensures that the vortex lattice is essentially stationary during the kick. To examine the effect that periodicity plays on the system, the optical potential was chosen to match the geometry of the Abrikosov vortex lattice, with the angle of relative alignment &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; given as a free parameter. The optical potential was modelled as the sum of counter-propagating laser beams, as
&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;opt&lt;/sub&gt; = &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;∑&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;cos&lt;sup&gt;2&lt;/sup&gt;[&lt;strong&gt;k&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;⋅&lt;strong&gt;r&lt;/strong&gt;],
 where &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; is the optical lattice potential amplitude, and *j* = [0, 1, 2, …] is the index of each respective laser with a differing &lt;strong&gt;k&lt;/strong&gt;-space wave-vector. By careful choice of the wave-vectors &lt;strong&gt;k&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; the density modulation given by the vortices is matched to the optical potential. This is achieved using the reciprocal lattice vectors defined by the vortex lattice, &lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;1, 2&lt;/sub&gt;, and an additional third wave-vector, $\mathbf{k}_3 = 4\pi/(\sqrt{3}a_o)\left[\sqrt{3}/2,-&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;\right]$. For the resulting optical potential, we define the lattice sites as the maxima of intensity. These are in turn matched with the condensate density minima of the vortex lattice.&lt;/p&gt;

&lt;p&gt;As the vortex lattice constant in a rapidly rotating atomic BEC can be quite large depending upon the system parameters, optical lattices with wavelengths on the order of tens of microns can be necessary . By ensuring a short kick with an amplitude on the order of 10&lt;sup&gt;−2&lt;/sup&gt;&lt;em&gt;μ&lt;/em&gt;, with &lt;em&gt;μ&lt;/em&gt; as the BEC’s chemical potential, the result of the kick is an imprinted phase on the wavefunction . As an example, following a single kick the vortex lattice phase can be observed to be modified, with localised phase gradients at the optical lattice maxima, as seen in Fig. [fig:Phase_diff_after_kick]. These localised gradients lead to the development of a flow originating from each optical lattice potential maxima location, and in turn create well-defined interference patterns resulting from phonons created by the kick. In the presence of a vortex lattice with a periodic core arrangement, this creates moiré superlattice structures in the density of the condensate. Such patterns have been observed in many solid-state systems, for example in graphene on hexagonal boron nitride , though it is static in such cases. In our system, the structures are dynamical, and revive at well defined intervals, where the frequency of the oscillations can be related to the speed of sound
$$c(\textbf{r},t) = \sqrt{\frac{\rho (\textbf{r},t) g}{m}},$$
 divided by the lattice constant.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/Phase_diff_after_kick&#34; alt=&#34;The condensate phase for the vortex lattice following a kick (left) and without the background lattice phase at t=0 (right). The phase modulation through the optical lattice kick is clearly visible.&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To study these resulting structures, we have performed a spectral decomposition of the kinetic energy of the condesate . For this the wavefunction is first written in amplitude (density) &lt;em&gt;ρ&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) and phase &lt;em&gt;S&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) form via a Madelung transform as given by . as $
        \Psi(\mathbf{r},t) = \sqrt{\rho(\mathbf{r},t)}\exp{\left[\mathrm{i}S(\mathbf{r},t)\right]}.
$ Making use of the Gross–Pitaevskii energy functional , and substituting in the above form gives
$$E_{\text{kqp}} = \int d\mathbf{r} \left( \frac{\hbar^2}{2m}| \nabla\sqrt{\rho(\mathbf{r},t)} |^2  + \frac{m}{2}|\sqrt{\rho(\mathbf{r},t)}\mathbf{v}(\mathbf{r},t) |^2\right).$$
 One can decompose this into the quantum pressure (first) and kinetic energy (second) terms. The kinetic energy term can seen as a density-weighted velocity field, $\mathbf{u}(\mathbf{r},t) = \sqrt{\rho(\mathbf{r},t)}\mathbf{v}(\mathbf{r},t)$. This can be further decomposed into the sum of compressible and incompressible terms,
&lt;strong&gt;u&lt;/strong&gt;&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)+&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;),
 where &lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt;, &lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sup&gt; are the compressible and incompressible terms respectively. This can be solved for both terms by performing a Helmholtz decomposition on the resulting field separating terms that are longitudinal (&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt;) and transverse (&lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;) with&lt;/p&gt;

&lt;p&gt;[eqn:kinterms]
$$\begin{aligned}
    \nabla \times \mathbf{u}^c(\mathbf{r},t) = 0, \&lt;br /&gt;
    \nabla \cdot \mathbf{u}^i(\mathbf{r},t) = 0.\\\end{aligned}$$&lt;/p&gt;

&lt;p&gt;By introducing the vector potential, &lt;strong&gt;A&lt;/strong&gt;, and scalar potential, &lt;em&gt;B&lt;/em&gt;, such that&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    \mathbf{u}^c = \nabla B, \&lt;br /&gt;
    \mathbf{u}^i = \nabla \times \mathbf{A} \\\end{aligned}$$&lt;/p&gt;

&lt;p&gt;we can rewrite Eq.  as
$$\begin{aligned}
    \nabla \times \mathbf{u}(\mathbf{r},t) = -\nabla^2 \mathbf{A}, \&lt;br /&gt;
    \nabla \cdot \mathbf{u}(\mathbf{r},t) = \nabla^2 {B}. \\\end{aligned}$$&lt;/p&gt;

&lt;p&gt;To solve the above equation we begin by solving for &lt;em&gt;B&lt;/em&gt; by performing a spectral decomposition as
$$B = \displaystyle\sum\limits_{j} \frac{k_j}{|\mathbf{k}|^2}\mathscr{F}[\mathbf{u}],$$
 where &lt;em&gt;k&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; is the &lt;em&gt;j&lt;/em&gt;-th component in &lt;strong&gt;k&lt;/strong&gt; space, and ℱ is the Fourier transform. The resulting solution for &lt;strong&gt;u&lt;/strong&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sup&gt; is given by
$$\mathscr{F}[\mathbf{u}_i^c] = \displaystyle\sum\limits_{j} \frac{k_i k_j}{|\mathbf{k}|^2} \mathscr{F}[\mathbf{u}],$$
 which after taking note of Eq.  gives
$$\begin{aligned}
    \mathscr{F}[\mathbf{u}_i^i] &amp;amp;= \mathscr{F}[\mathbf{u}_i] - \mathscr{F}[\mathbf{u}_i^c]. \&lt;br /&gt;
    &amp;amp;= \displaystyle\sum\limits_{j}\left(\delta_{i,j} - \frac{k_ik_j}{|\mathbf{k}|^2}\right)\mathscr{F}[\mathbf{u}_i].\end{aligned}$$&lt;/p&gt;

&lt;p&gt;This decomposition separates the energy contribution from phonons and vortex cores, represented by compressible and incompressible terms respectively . By averaging over binned shells in &lt;strong&gt;k&lt;/strong&gt;-space, the kinetic energy spectra, &lt;em&gt;E&lt;/em&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;em&gt;k&lt;/em&gt;), are calculated as 
$$E^{c,i}(k) = \frac{mk}{2}\sum\limits_{j\in\mathbf{r}} \int\limits_{0}^{2\pi}d\phi_k \frac{ |\mathcal{U}_j^{c,i}(\mathbf{k},t) |^2}{s_k},$$
 where
𝒰&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;k&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=∫&lt;em&gt;d&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;em&gt;e&lt;/em&gt;&lt;sup&gt;−&lt;em&gt;i&lt;/em&gt;(&lt;strong&gt;k&lt;/strong&gt; ⋅ &lt;strong&gt;r&lt;/strong&gt;)&lt;/sup&gt;&lt;em&gt;u&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;).
 The terms &lt;em&gt;u&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;c&lt;/em&gt;, &lt;em&gt;i&lt;/em&gt;&lt;/sup&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;) represent the position-space density-weighted velocity components in the specified shell, where &lt;em&gt;ϕ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; is the polar angle, and &lt;em&gt;s&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; is the number of values in the chosen shell.&lt;/p&gt;

&lt;p&gt;For state-of-the-art theoretical analysis of condensates, one of the most widely used methods to understand the effects of the kinetic energy is to perform a spectral decomposition via the method explained in Sec. [sec:kinspec]. This separates the contributions from vortices and phonons in the kinetic energy, and is analogous to methods used in classical fluid systems. For vortices, in both liquid helium and atomic Bose–Einstein condensates, this decomposition also allows one to characterise the onset of quantum turbulence, and is used extensively in the literature . However, Reeves &lt;span&gt;&lt;em&gt;et&lt;/em&gt;&lt;/span&gt; al. have recently discussed how the kinetic energy spectral decomposition as presented in Sec. [sec:kinspec] does not truly represent the kinetic energy of the system, as the spectral terms are not additive in &lt;strong&gt;k&lt;/strong&gt;-space. The classical interpretation is described as being “*obtained by applying the general correspondence between a two-point correlation function and its associated power spectrum to the velocity field*”, as stated by the authors. They propose a quantum version of the above description, which involves including the condensate phase, alongside the density weighted velocity field, as $\mathbf{u}(\mathbf{r},t) = \sqrt{\rho(\mathbf{r},t)}\mathbf{v}(\mathbf{r},t)\exp\left(\textrm{i}S(\mathbf{r},t)\right)$. The resulting kinetic spectra then accurately describes the true spectrum of the condensate. For an examination of the vortex lattice, it is instructive to investigate the effectiveness of both approaches, and an example of the kinetic energy spectra is given in Fig. [fig:ek_clvqu] for both the classical (left) and quantum (right) methods. For the classical spectrum, highly periodic structures are observed which appear at wavenumbers corresponding to the distances between vortices, which is not present in the quantum spectrum. Though the quantum spectrum may more accurately represent the kinetic energy of the condensate system, the periodic structure observed in the classical case are lost.&lt;/p&gt;

&lt;p&gt;This is due to the included phase term breaking the correspondence between the power spectrum of a signal and its associated autocorrelation function , which are related by a Fourier transform according to the Wiener-Khinchin formula . Though not truly the compressible and incompressible energies of a fully quantum system, due to the mean-field description the condensate system can be written in the form of a continuity equation (see Eq. ) with the probability current taking the form of the density weighted velocity field as used in Sec. [sec:kinspec]. For such classical fluid descriptions, the classical method can be applied for isolating and describing both compressible and incompressible energies, and is used in the above mentioned studies. One can clearly see that this formalism allows us to identify the spatial structure of the observed pattern, which results from ensuring that the autocorrelation–power spectrum relation remains. As the periodicity is an important characteristic of the vortex lattice, the use of the classical kinetic energy spectral decomposition gives more information useful to this work, and will be used in the following sections.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/Ek_classical/VTXLATT_Ek.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/Ek_quantum/VTXLATT_Ek.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/Ek_classical/VTXLATT_Comp.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/Ek_quantum/VTXLATT_Comp.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/Ek_classical/VTXLATT_Incomp.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/Ek_quantum/VTXLATT_Incomp.png&#34; title=&#34;fig:&#34; alt=&#34;The compressible and incompressible kinetic energy spectra comparing the classical (left) and the quantum version (right).&#34; style=&#34;width:45.0%&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;delta-kick-dynamics&#34;&gt;Delta-kick dynamics&lt;/h2&gt;

&lt;h3 id=&#34;non-rotating-condensate&#34;&gt;Non-rotating condensate&lt;/h3&gt;

&lt;p&gt;To fully characterise the effect kicking has on a rapidly rotating BEC carrying a vortex lattice it is instructive to first understand the dynamics following a kick in the absence of a vortex lattice. For an accurate comparison we need to take into account that in the absence of rotation no centrifugal forces appear, and we therefore adjust the trapping frequency of the non-rotating condensate such that the background densities match that of the rotating condensate. This is achieved from Eq.  by assuming the centrifugal term competing against the harmonic oscillator term as &lt;em&gt;V&lt;/em&gt;&lt;sub&gt;opt&lt;/sub&gt; = (1/(2&lt;em&gt;m&lt;/em&gt;))(&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; − &lt;em&gt;Ω&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;)&lt;em&gt;r&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;, where *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; is the value chosen for the rapidly rotating case, as given by Eq. .&lt;/p&gt;

&lt;p&gt;For a stationary (non-kicked) condensate the kinetic energy spectrum will remain constant during time-evolution, with a kick leading to the appearance of new, time varying components. To observe this we numerically evolve the system by setting &lt;em&gt;V&lt;/em&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;)=&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;ext&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;)+&lt;em&gt;V&lt;/em&gt;&lt;sub&gt;opt&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;, &lt;em&gt;t&lt;/em&gt;), where the time dependent optical potential is only active for *τ* = 10&lt;sup&gt;−5&lt;/sup&gt; s of the simulation time. As discussed earlier, this short kicking duration is sufficient to allow a phase imprint onto the condensate wavefunction, without any change in the density on the timescales of the kick itself. Next, we examine the compressible and incompressible kinetic energy spectrum following the kick (see Fig. [fig:ekc_eki_novtx]). Unsurprisingly, the spectrum is dominated by a peak corresponding to the wavenumber associated with the optical potential at $k=4\pi/(\sqrt{3}a_o)$ (indicated by the dashed line), and several smaller ones corresponding to higher harmonics of &lt;em&gt;n&lt;/em&gt;-th next nearest neighbour components of the lattice. This makes sense as the nearest neighbour lattice spacings should be the dominant structure with higher order spacings dropping in intensity due to the finite system size. As no rotation is added by the imparted phonon modes, the incompressible energy is an order of magnitude smaller compared to the compressible energy. Although the incompressible energy should technically be zero for a condensate with no vortices, given the difference in magnitudes (10&lt;sup&gt;2&lt;/sup&gt; → 10&lt;sup&gt;4&lt;/sup&gt;) this can be taken as a &lt;em&gt;k&lt;/em&gt;-space resolution issue following the decomposition, and can be assumed as zero. Following from this we will therefore restrict the analysis to the compressible part of the spectrum.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/EKcEKi_kick_dt2&#34; alt=&#34;Compressible and incompressible energy spectra of a non-rotating condensate directly following a kick. A peak at k=4\pi/(\sqrt{3}a_o) can be seen, which corresponds to the lattice spacing, a_o (indicated by the dashed line), and the smaller, higher energy peaks can be attributed to higher harmonics between nearest and next-nearest neighbours. The incompressible spectrum is much smaller than the compressible spectrum, and thus is neglected for all further analysis. Reprinted from O’Riordan et al. .&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The evolution of the nearest neighbour peak in the compressible kinetic energy spectrum during the first 250 ms after the kick is shown in Fig. [fig:novtx_p5k](&lt;em&gt;a&lt;/em&gt;). It initially oscillates in and out of existence and eventually disperses over a wide range of wavenumbers. Snapshots of the density evolution are given in Fig. [fig:novtx_p5k](&lt;em&gt;b&lt;/em&gt;), which clearly show that the oscillations correspond to the existence of a transient lattice pattern with several revivals, having the same underlying structure as the optical potential. In fact, the lattice pattern is best formed whenever the main peak in the kinetic energy spectrum goes to zero, i.e. when the imprinted kinetic energy has been converted into density modulations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig3&#34; alt=&#34;(a) Main peak of the compressible kinetic energy spectrum for a kicking strength of V_0 \approx 1.35\times10^{-2}\mu. It can be seen to revive, and eventually disperse over a wide range of wavenumbers. (b) Condensate densities at several times during the evolution. A pattern matching the optical potential can be observed to appear and disappear several times over the course of the evolution. Reprinted from O’Riordan et al. .&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;rapidly-rotating-condensate&#34;&gt;Rapidly rotating condensate&lt;/h3&gt;

&lt;p&gt;Kicking a condensate carrying an Abrikosov vortex lattice with the above optical lattice gives an additional parameter, &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt;, which describes the orientation of the imprinted phonon lattice angle relative to the vortex lattice. We initially assume that the vortex and optical potential lattices have the same lattice constant, &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;o&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;a&lt;/em&gt;, which means that symmetry allows for a restriction of the angle to &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; ∈ [0, &lt;em&gt;π&lt;/em&gt;/3). In the following it can be seen that adjusting &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; leads to the appearance of different, transient super-structures in the condensate density. If &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = 0 (see Fig. [fig:moire_density](&lt;em&gt;a&lt;/em&gt;)) the kicking imparts kinetic energy at wavenumbers that are already well defined in the lattice. No significant change to the compressible kinetic energy spectrum is observed in this case, apart from small amplitude modulations on the well defined peaks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig4&#34; alt=&#34;Condensate density at t=1.4\times10^{-2} s for several optical lattice rotation angles. The cell size of the super-lattice structures can be seen to shrink as the angle is increased. The angles for the examples shown are (a)~\theta_\Delta=0, (b)~\theta_\Delta=2\pi/45, (c)~\theta_\Delta=4\pi/45, (d)~\theta_\Delta=2\pi/15. Reprinted from O’Riordan et al. .&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, if the angle between both lattices is finite, and not an integer multiple of &lt;em&gt;π&lt;/em&gt;/3, superlattice structures appear after a short time (see Fig. [fig:moire_density](&lt;em&gt;b&lt;/em&gt;)-(&lt;em&gt;d&lt;/em&gt;)), which have a structure cell size that decreases for increasing values of &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; ∈ [0, &lt;em&gt;π&lt;/em&gt;/6] and beyond which increases for larger values until the misalignment angle reaches the lattice symmetry point again at &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;π&lt;/em&gt;/3. These structures are transient, and several revivals can be observed before the condensate settles back into the vortex lattice structure with an increase in the background wavenumber spread, as expected based on kicking the non-rotating condensate. This settling does not imply that the condensate has dissipated the energy, but merely that the energy has spread over all possible wavenumbers, with the underlying lattice structure remaining dominant. An example of this for a fixed angle is shown in Fig. [fig:dtheta20_ev].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig5&#34; alt=&#34;Condensate density shows visible moiré structures upon receiving a kick with \theta_\Delta=\pi/9. The appearance and disappearance of a moiré structure with wavelength \lambda_M \approx 2.9 a over a timescale of about 50 ms can be seen. Reprinted from O’Riordan et al. .&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To explain the interference patterns observed for misaligning the optical and the vortex lattice, we employ moiré interference theory . Moiré patterns are known to appear when two periodic structures are overlaid while slightly misaligned to each other, and can be calculated from the reciprocal lattice vectors. In all generality, any choice of equidistantly separated reciprocal lattice vectors can be parameterised as
$$\mathbf{g}_{l} = g_0 \left[ \sin\left( \frac{2\pi l}{\upsilon}+\theta \right),\, \cos\left( \frac{2\pi l}{\upsilon} +\theta\right) \right],$$
 where &lt;em&gt;υ&lt;/em&gt; describes the rotational symmetry of the lattice, &lt;em&gt;l&lt;/em&gt; labels the vector direction on the unit circle, &lt;em&gt;θ&lt;/em&gt; is the angle with respect to a chosen coordinate system and &lt;em&gt;g&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; is the reciprocal lattice constant. For commensurate and triangular lattices we get $g_0=4\pi/(\sqrt{3}a)$, *υ* = 6 and the vector directions are *l* = [0…*υ*−1]. As only the relative mis-alignement between the vortex and the phonon lattice matters, we choose *θ* = 0 for the vortex lattice and *θ* = &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; for the optical potential alignment. All possible wavelengths that can appear in an interference pattern between two such lattices in position space are then given by
$$\lambda_{ll&amp;rsquo;} = \frac{\lambda_0}{|{\mathbf{g}_{ll^\prime}|}},
            \label{eq:InterferenceVectors}$$
 where &lt;strong&gt;g&lt;/strong&gt;&lt;sub&gt;*l&lt;strong&gt;l*′&lt;/sub&gt; = &lt;/strong&gt;g&lt;strong&gt;&lt;sub&gt;&lt;em&gt;l&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;vtx&lt;/sup&gt; − &lt;/strong&gt;g&lt;strong&gt;&lt;sub&gt;*l*′&lt;/sub&gt;&lt;sup&gt;opt&lt;/sup&gt;, and $\lambda_0 = 4\pi/\sqrt{3}$ for the commensurate triangular lattices. This yields 6 interfering wavevectors, and as a result 6 moiré wavelengths. Figure [fig:moire_higher] shows these resulting interferences in both position and reciprocal space, with the colour indicating the corresponding wavenumbers and wavelengths. The band-like structure of the interferences have contact points at the angle of maximal and minimal alignment of the two lattices, &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = (*j&lt;/strong&gt;π*/3, *j&lt;strong&gt;π*/6) respectively. For a chosen rotation angle between these limiting values, we obtain several wavenumbers, and hence wavelengths. One can see from Fig. [fig:dtheta20_ev] for &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;π&lt;/em&gt;/9 that a pattern matching the longest wavelength, &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; = max[&lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;*l&lt;/strong&gt;l*′&lt;/sub&gt;]≈2.9&lt;em&gt;a&lt;/em&gt;, appears around *t* = 24 ms and is clearly the most visible one for the given angle. Shorter wavelengths, while are expected to be present, are hard to discern in this system, and therefore we will concentrate on the lowest wavenumber for the following analysis.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;k&lt;/strong&gt;-space the shortest |&lt;strong&gt;g&lt;/strong&gt;&lt;sub&gt;*l*&lt;em&gt;l&lt;/em&gt;&lt;sup&gt;′&lt;/sup&gt;&lt;/sub&gt;| corresponds to adjacent wave-vectors with the smallest &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; between them (see inset in Fig. [fig:moire_lambda_1]). Due to the symmetry of the lattices the most visible structures are therefore given by &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;00&lt;/sub&gt; for &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; ∈ [0, &lt;em&gt;π&lt;/em&gt;/6] and &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;01&lt;/sub&gt; for &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; ∈ [&lt;em&gt;π&lt;/em&gt;/6, &lt;em&gt;π&lt;/em&gt;/3] (see inset of Fig. [fig:moire_lambda_1]). While this symmetry assumption no longer holds strictly true after the system has been kicked, it is still fulfilled to a very good approximation during the initial dynamics. One can then obtain the wavelength of the dominating moiré structure as 
$$\lambda_M = \frac{a}{2\sin(\eta/2)},
            \label{eqn:moire_size}$$
 where $\eta=\min(\theta_\Delta,\frac{\pi}{3} - \theta_\Delta ) $ (see Fig. [fig:moire_lambda_1]). These super-structures become observable when the wavelength becomes smaller than the radius of the condensate, which for the chosen parameters is &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; ≈ 11&lt;em&gt;a&lt;/em&gt; and which corresponds to an angle &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; ≈ &lt;em&gt;π&lt;/em&gt;/36. One can see from Fig. [fig:moire_lambda_1] that once the relative angle is increased beyond this value the structure sizes shrink to a minimum value at the point of complete misalignment, &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;π&lt;/em&gt;/6, giving &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; ≈ 1.93 &lt;em&gt;a&lt;/em&gt;, and increase again up to the point of symmetry. Beyond this point the behaviour starts over, due to the symmetry of the lattice. Note that in principle the above procedure can be carried out for square or other optical lattice geometries.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/HigherK_edit&#34; title=&#34;fig:&#34; alt=&#34;The moiré interference pattern in terms of wavenumbers (left) and corresponding wavelengths (right). The resulting wavenumber g_{ll^{\prime}} is normalised by the vortex lattice spacing in reciprocal space g_v, and the moiré wavelength \lambda_M is normalised by the vortex spacing in position space a_v. The lowest lying band in reciprocal space is the main contributor to the visible moiré interference patterns, corresponding to the largest wavelength (both in blue). Higher orders are shown for the reciprocal and the corresponding position space, with the higher modes only visible between the beats of the lowest wavenumber moiré interferences. Colours correspond between wavelengths and wavenumbers.&#34; style=&#34;width:48.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/HigherK_moire_edit&#34; title=&#34;fig:&#34; alt=&#34;The moiré interference pattern in terms of wavenumbers (left) and corresponding wavelengths (right). The resulting wavenumber g_{ll^{\prime}} is normalised by the vortex lattice spacing in reciprocal space g_v, and the moiré wavelength \lambda_M is normalised by the vortex spacing in position space a_v. The lowest lying band in reciprocal space is the main contributor to the visible moiré interference patterns, corresponding to the largest wavelength (both in blue). Higher orders are shown for the reciprocal and the corresponding position space, with the higher modes only visible between the beats of the lowest wavenumber moiré interferences. Colours correspond between wavelengths and wavenumbers.&#34; style=&#34;width:48.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig6&#34; alt=&#34;The dashed green line indicates the condensate radius. Inset: The different vectors in \mathbf{k}-space of the two lattices, with the optical lattice rotated by an angle \theta_\Delta. The \mathbf{g}_{ll&amp;#39;} = |\mathbf{g}_l - \mathbf{g}_l&amp;#39;| vectors defining the dominant moiré wavelength are those for which the enclosed angle is smallest. Reprinted from O’Riordan et al. .&#34; style=&#34;width:55.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The appearance of the moiré vector in &lt;strong&gt;k&lt;/strong&gt;-space can be confirmed from the numerical simulations by looking at the compressible kinetic energy spectra which is given in Fig. [fig:dtheta_kspec]. Apart from the dominant peaks corresponding to the underlying triangular geometry of the Abrikosov lattice, which are independent of &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; (straight lines in Fig. [fig:dtheta_kspec]), a number of additional peaks appear. Their position is a function of the misalignment angle and the lowest wavenumber that appears increases its value with increasing &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt;. This is consistent with the moiré model and the appearance of density structures of differing size. Furthermore, a symmetric repeat of this structure about the &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;π&lt;/em&gt;/6 point is also visible, which corresponds to the &lt;em&gt;π&lt;/em&gt;/3 − &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; lattice vector component. The minimum wavelength observed agrees with the theoretically determined minimum value of &lt;em&gt;λ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt; ≈ 1.93 &lt;em&gt;a&lt;/em&gt; and all other values over the range of observed angles. Note that for the higher harmonics at larger wavenumbers similar behaviour exists and is also covered by the moiré model.&lt;/p&gt;

&lt;p&gt;To better observe the wavenumbers in the spectra, one can remove the background lattice spectrum. Corresponding to the systems shown in Fig. [fig:dtheta_kspec] this is given in Fig [fig:dtheta_kspec_backg], with the peaks at *t* = 0 removed. In this instance, lower wavenumber interference patterns are more easily visualised, with a slight enhancement of higher orders. We can also observe the appearance of secondary interference patterns across low to high wavenumbers, though visibility quickly diminishes approaching higher wavenumbers. It should be noted that given sufficient time the higher order wavenumbers can influence the density dynamics, but the system remains dominated by the lowest wavenumber. Due to the coupling between adjacent modes in the system, all interference patterns become hard to discern after some time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig7&#34; alt=&#34;Compressible kinetic energy spectrum as a function of \theta_\Delta. All values are time-averaged over an interval t=0 s to t=1 s. The moiré peak corresponding to the lowest wavenumber can be seen shifting to larger values for increasing angles and similar behavior is visible for the higher order components. Reprinted from O’Riordan et al. .&#34; style=&#34;width:65.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/ekc_theta_remove_backg&#34; alt=&#34;Compressible kinetic energy spectrum with the structures stemming from the static background removed. The effect of the moiré interference pattern for lower and higher modes is more clearly visible compared to Fig. [fig:dtheta_kspec].&#34; style=&#34;width:65.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In the following we will briefly discuss what happens for stronger kicking, or when the two lattices are non-commensurate. In the above the strength of the kicking pulse was chosen such that its perturbation only leads to a phase imprinting , with minimal change to the initial density. If one increases the kicking intensity the situation becomes quite different and one can see from Fig. [fig:kickp20k](&lt;em&gt;a&lt;/em&gt;) that higher order wavenumbers become more strongly excited. This, in turn, leads to modulations of the condensate density at shorter wavelength and an example is shown in Figs. [fig:kickp20k](&lt;em&gt;b&lt;/em&gt;)-(&lt;em&gt;e&lt;/em&gt;), with the numerically calculated averaged spectra given in Fig. [fig:kick_compare_spec]. For fully realistic experimental situations it is necessary to also consider the heating of the condensate once the kicking becomes stronger. However, we do not extend this direction towards stronger kicking strengths in this work.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/fig8_2&#34; alt=&#34;(a) For a kicking strength of V_0 = 5.4\times10^{-2}\mu for a non-rotating condensate higher order modes become non-negligible contributors to the compressible kinetic energy spectrum. This leads to the appearance of higher-order peaks and a different behaviour of the condensate density. Close-ups of the density structures are shown for (b) 24 ms, (c) 36 ms, (d) 56 ms, and (e) 88 ms. Note that the structures with higher amplitudes in these plots are given by the optical lattice constant, a_o, which is set to the mean inter-vortex distance for the rapidly rotating condensate. In the presence of vortices this is anticipated to create many additional interferences. Reprinted from O’Riordan et al. .&#34; style=&#34;width:75.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/EKCEKI_novtx_power&#34; title=&#34;fig:&#34; alt=&#34;For kicking pulses of V_0 = (1.35,2.7,5.4)\times 10^{-2} \mu the kinetic energy spectra show a clear increase in higher order modes being excited for both compressible (left) and incompressible (right) cases with increased kicking strength.&#34; style=&#34;width:49.0%&#34; /&gt; &lt;img src=&#34;ch5_kickit/EKCEKI_novtx_power&#34; title=&#34;fig:&#34; alt=&#34;For kicking pulses of V_0 = (1.35,2.7,5.4)\times 10^{-2} \mu the kinetic energy spectra show a clear increase in higher order modes being excited for both compressible (left) and incompressible (right) cases with increased kicking strength.&#34; style=&#34;width:49.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A situation where the optical and the vortex lattice have different lattice constants can be imagined to appear naturally due to experimental uncertainties. Defining &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;o&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;(1 + &lt;em&gt;ϵ&lt;/em&gt;) the expression in Eq.  can be calculated to be
$$\lambda_M = \frac{a_v(1+\epsilon)}{\sqrt{2(1+\epsilon)(1-\cos\theta) + \epsilon^2}},
        \label{eqn:moire_size_eps}$$
 which reduces to Eq.  for *ϵ* = 0. Evaluating this expression for *ϵ* = ( − 0.1, 0, 0.1) shows that the largest moiré wavelength changes slightly for small values of &lt;em&gt;ϵ&lt;/em&gt;, but it remains distinct enough from the higher order wavelengths to stay visible in the evolution (see Fig. [fig:epsilon]). This ensures that the system examined here is experimentally realistic. For large deviations of the lattice constant, the assumption of the largest moiré wavelength playing the dominant role is no longer valid, as many of the interfering wavevectors approach comparable scales.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/Moire_higherk_epsrange&#34; alt=&#34;Small deviations for \epsilon can be seen to only lead to minor changes of the induced moiré wavelength.&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;vortex-dynamics-following-a-kick&#34;&gt;Vortex dynamics following a kick&lt;/h2&gt;

&lt;p&gt;While we have concentrated mostly on the phonon modes of the condensate density it is necessary to also examine the result of kicking on the vortex lattice. Figure [fig:kickit_traj] shows the densities and trajectories in the co-rotating frame for kicks of &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;Δ&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;π&lt;/em&gt;(&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;60&lt;/sub&gt;, 1/10). Some deviation from solid-body rotation is observed at the edge of the examined vortex region, but the central vortex regions show almost no variation from their ideal lattice positions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch5_kickit/Trajectory_after_kick_theta0_15_3offset&#34; alt=&#34;The condensate densities are shown for times t=(20,200) ms, and for \theta_\Delta = (\pi/60,\pi/10) (top and bottom). The resulting trajectories of the vortices show minimal deviation from their initial lattice positions over 2 seconds of time evolution.&#34; style=&#34;width:90.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Both cases demonstrate the same overall dynamics, with the vortex lattice showing extreme robustness against the phononic perturbances that build following a kick.&lt;/p&gt;

&lt;h2 id=&#34;conclusions-and-outlook-1&#34;&gt;Conclusions and outlook&lt;/h2&gt;

&lt;p&gt;The purpose of the previous work was to investigate the effect of a kicked optical lattice potential with a well defined periodicity on a vortex lattice having its own periodic structure. As observed, the kicking had a negligible effect on the vortex positions, with the lattice remaining well defined with near constant spacings, even in the long time limit. The optical lattice kicks solely modified the background density around the vortex cores. One could observe that the vortex lattice remains incredibly stable and strongly resilient to perturbations and modulations in density. Given the stability of the lattice, it can be expected that even for a finite number of kicks, the lattice will remain mostly unbroken. It can also be expected that heating effects would play a role in destabilising the condensate, and to determine any long-term realistic behavior from this system, including the treatment of a non-negligible thermal cloud contribution would be necessary.&lt;/p&gt;

&lt;p&gt;The kinetic energy spectra provided a useful tool to investigate the order of the imparted wavenumbers following a kick, and were very closely matched with the results from moiré interference theory. The existence of this moiré interference effect has some interesting consequences. It can, for example, be thought of as a tool to test the periodicity of a structure that is otherwise too small to be resolved without time of flight. In general, this technique may be used on other types of periodic structures, for example crossed solitons in 2D condensates . As optical lattices can offer a large number of free parameters (lattice constant, amplitude, misalignment, geometry, …), a full toolbox can be developed from this technique. This could potentially be used for probing condensate systems, applying well-defined structures onto stationary condensates, and for generating the aforementioned interferences in the presence of an underlying periodicity.&lt;/p&gt;

&lt;p&gt;While in my thesis proposal the system discussed in this chapter was suggested to investigate delta-kicked chaotic dynamics , it became clear very quickly that the robustness of the vortex lattice with respect to realistic kicking strengths did not allow for significant vortex dynamics. Nevertheless, an investigation into periodic kicking is still an interesting (and numerically even more challenging) endeavor. As vortex lattices feature a well-defined rotation rate and 6-fold symmetry, the system rotates to a symmetric position every &lt;em&gt;π&lt;/em&gt;/3. Providing a periodic kick at this rate, would therefore allow the lattice to always have the same alignment angle, at least for an initial number of kick repetitions.&lt;/p&gt;

&lt;h1 id=&#34;defect-engineering-in-vortex-lattices&#34;&gt;Defect engineering in vortex lattices&lt;/h1&gt;

&lt;h2 id=&#34;introduction-2&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In the previous chapter we have discussed the application of kicked optical potentials to vortex lattice carrying condensates. The vortex lattice proved to be very resilient, with the individual vortex positions largely unaffected by the perturbation, apart from some minor oscillations about their equilibrium positions. The global structure of the lattice was preserved, and remained well ordered. It begs the question of how to create a disordered arrangement from this well ordered structure. Given the similarity of vortex lattices to some crystal structures in condensed matter, it is interesting to examine lattice ordering, and investigate the behaviour of the vortex lattice subjected to a defect or vacancy. True crystalline solid-state materials have feature sizes on the order of &lt;span&gt;Å&lt;/span&gt;ngstroms, and can be difficult to observe experimentally, especially the appearance of lattice defects. Even more difficult can be the creation of well defined defects within the crystal structures. Cold atomic systems allow for the same fundamental effects to be investigated on mesoscopic scales, and in currently experimentally realisable systems. Here, we will demonstrate the creation of crystal defects in a BEC vortex lattice. With this, an interesting question to ask is if the lattice were to lose a vortex at a specified location, how would the overall system respond?&lt;/p&gt;

&lt;p&gt;In Section [sec:phase] we discussed the use of phase imprinting techniques to modify the condensate phase. While it was discussed that a vortex can be created with the required ±2&lt;em&gt;π&lt;/em&gt; phase winding, phase imprinting can also be used to annihilate a pre-existing vortex. Assuming a vortex with clockwise phase winding, the direct application of a phase profile with counter-clockwise winding can remove the topological charge of the vortex and annihilate it. In this chapter we will examine the use of this technique, and investigate the resulting effects on the vortex lattice order.&lt;/p&gt;

&lt;p&gt;This work has been accepted for publication in Physical Review A, with the content referenced therefrom.&lt;/p&gt;

&lt;h2 id=&#34;model-1&#34;&gt;Model&lt;/h2&gt;

&lt;p&gt;To investigate the evolution of a vortex lattice subjected to the phase imprinting technique we once again numerically solve the Gross–Pitaevskii equation in two dimensions, assuming a strong confinement along the third axis, following the model given in Sec. [sec:modelsystem]. This allows us to restrict the dynamics to the *x*–&lt;em&gt;y&lt;/em&gt; plane and focus fully on the Abrikosov lattice geometry. In the frame co-rotating with the condensate the nonlinear mean-field equation governing the BEC wave-function is once again given by
$$\begin{aligned}
    \textrm{i}\hbar\partial_t \Psi(\mathbf{r},t) = \left[-\frac{\hbar^2}{2m}\nabla^2 + V\left(\mathbf{r}\right)
    + g_{\textrm{2D}}\vert \Psi(\mathbf{r},t) \vert^2- \Omega L_z \right]\Psi(\mathbf{r},t).
        $$&lt;/p&gt;

&lt;p&gt;While the Abrikosov ground state is perfectly ordered, removing or adding vortices will lead to disorder in the lattice. Recently, quantifying the disorder of vortex lattices has become an active topic of interest . Here, we suggest to quantify the order of the vortex lattice by first determining the position of each vortex by summing the wavefunction phase over adjacent grid sites and locating ±2&lt;em&gt;π&lt;/em&gt; windings. This gives a vortex position estimated to the nearest numerical grid point. A linear least-squares fit is then performed to more accurately determine the vortex core location to sub-grid resolution, as described by Sec. [sec:vortrack]. This allows us to determine the wavefunction zeroes within the region, and obtain a continuous rather than discrete range of values for the vortex positions. Since tracking many-body dynamics is a difficult problem, we make use of the Delaunay triangulation and Voronoi tessellation techniques from computational geometry to examine the ordering of the the vortex lattice, as introduced in Sec. [sec:delaunay]. In the ideal triangular Abrikosov lattice, every vortex has 6 nearest neighbours, *l* = (0, …, 5), located at &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;l&lt;/em&gt;&lt;/sub&gt; = *l*&lt;em&gt;π&lt;/em&gt;/3 around the polar angle. Any perturbation that breaks this symmetric arrangement can be easily observed using Delaunay triangulation. This technique generates a mesh from the vortex positions, which makes it easy to check for the presence of non 6-fold neighbouring vortices. These vortices are termed as &lt;em&gt;n&lt;/em&gt;-fold topological lattice defects, where &lt;em&gt;n&lt;/em&gt; is the number of connected edges, and dislocation defects can form when, for example, a 5-fold and a 7-fold defect pairs. Since all these structures are easily countable, this method allows us to characterize the effect that a well-defined perturbation has on the lattice. Alternatively, Voronoi tessellations, which can be generated from the Delaunay triangulation and vice versa, make it easy to observe structural changes in the lattice, and are useful for visualising quantities local to the regions of interest.&lt;/p&gt;

&lt;p&gt;As unperturbed Abrikosov lattices in BECs are well ordered everywhere in the bulk region we define the previously mentioned radial boundary at approximately &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; of the maximum density, which corresponds to *r* = 2 × 10&lt;sup&gt;−4&lt;/sup&gt; m from the BEC centre and restrict our analysis to vortices inside it. This leaves an edge boundary of approximately 4&lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; wide where vortices are not counted. As discussed in Sec. [sec:modelsystem], this gives approximately &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; = 341 vortices in the region of interest, which is a sufficient number for the following analysis. Given the coordinate locations for each vortex within the boundary, it is possible to calculate statistical quantities that characterised the degree to which the lattice is ordered. While the Delaunay and Voronoi representations of the lattice are useful methods for the reasons described above, having a metric to measure the deviation from a symmetric arrangement is also useful. As our system is of finite size, the commonly used translational correlations have only limited value, and we will focus in the following on orientational correlations which quantify how the rotational symmetry of the vortices correlates across length-scales. The orientational correlation function for a two-dimensional lattice with 6-fold rotational symmetry is defined as
$$\begin{aligned}
    g_6&amp;reg; = \frac{1}{N&amp;reg;}\displaystyle\sum\limits_{j,k}^{N&amp;reg;}\zeta_6(\mathbf{r}_j)\zeta_6^{*}(\mathbf{r}_k),\end{aligned}$$
 with
$$\begin{aligned}
    \zeta_6(\mathbf{r}_{j}) =  \frac{1}{n_j}\displaystyle\sum\limits_{l}^{n_j}\exp(\mathrm{i}6\theta_{jl}),\end{aligned}$$
 where &lt;em&gt;N&lt;/em&gt;(&lt;em&gt;r&lt;/em&gt;) is the number of paired vortices at locations &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; and &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt; separated by *r* = |&lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; − &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt;|, &lt;em&gt;ζ&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt; is the orientational order parameter, &lt;em&gt;l&lt;/em&gt; runs over the nearest neighbouring vortices, &lt;em&gt;n&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; is the number of elements in the respective bin-range (&lt;em&gt;n&lt;/em&gt;&lt;sub&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; = 6 for a perfect triangular lattice), and &lt;em&gt;θ&lt;/em&gt;&lt;sub&gt;*j*&lt;em&gt;l&lt;/em&gt;&lt;/sub&gt; is the angle a paired vortex and nearest neighbour makes relative to a reference axis . We examine the orientational correlation function as a measure of the order of a “vortex unit cell”, defined by the angle made by nearest neighbours to an individual vortex. For a perfectly ordered triangular lattice this value will tend to 1 at *r* = &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;, nearest neighbour and higher order crystal spacings, and 0 elsewhere.&lt;/p&gt;

&lt;h2 id=&#34;phase-imprinting-defects&#34;&gt;Phase imprinting defects&lt;/h2&gt;

&lt;p&gt;The phase imprinting methods discussed in Sec. [sec:phase] can be used to annihilate a vortex from the lattice by applying a phase profile of opposite winding to remove the vortex phase singularity. This will leave the condensate with a density depletion at the prior location of the singularity, which will consequently fill in and excite phonon modes in the condensate. Alternatively, one can also change the direction of rotation of a vortex in the lattice by applying a 4&lt;em&gt;π&lt;/em&gt; magnitude phase in opposition to the present direction of rotation. Many proposed methods and resulting implementations of this set of techniques have been demonstrated for vortex generation , and so it is assumed that the methods and discussions provided are realisable. In the following we will introduce the effect of removing a vortex on the lattice system, and discuss the resulting dynamics.&lt;/p&gt;

&lt;h3 id=&#34;single-vortex-dynamics&#34;&gt;Single vortex dynamics&lt;/h3&gt;

&lt;p&gt;To fully understand the effects of removing a vortex from the lattice system, we will first investigate removing the angular momentum from a single vortex-carrying condensate. For this we apply a phase pattern that cancels the pre-existing 2&lt;em&gt;π&lt;/em&gt; phase winding, and time evolve the system to examine the resulting dynamics. Figure [fig:annihilation_1vtx] demonstrates the resulting dynamics, and as expected, the density depletion in the condensate fills in following the phase singularity removal. Since the system is rotationally symmetric, we also plot the expectation value of the squared radius, ⟨&lt;em&gt;r&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;⟩, where &lt;em&gt;r&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; = &lt;em&gt;x&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; + &lt;em&gt;y&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;, which clearly shows that the annihilation process excites the breathing mode at the expected frequency of 2&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; for a two-dimensional system . The energy shift due to the phase removal can also be meaningfully characterised via the ratio of compressible (phonon) and incompressible (vortex) kinetic energy as given by Sec. [sec:kinspec], with the spectra shown in Fig. [fig:kinspec]. The kinetic energies are determined from the density weighted velocity field, $\mathbf{u} = |\Psi|\frac{\hbar}{m}\nabla \theta$, where &lt;em&gt;θ&lt;/em&gt; is the phase of the condensate, by making use of Eq. . As one can see from Fig. [fig:kinspec] after the vortex is annihilated and phonons are created, the energy ratio drops to favour lower incompressible-to-compressible values, in particular for higher wavenumbers. The latter is likely due to the removal of larger kinetic energies from the atoms closer to the vortex core.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig1.pdf&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/tikz/EKt.pdf&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;While the above example suggests that erasing vortices is a straightforward and controllable process, this assumption must be checked for the situation where the imprinted phase singularity and the existing phase are not perfectly centered on each other. This is shown in Fig. [fig:annihilation_1vtx_uncentred], and one finds that cases where the imprinted profile is sufficiently close to the core (i.e. within twice the healing length, *ξ* ≈ 1.06 × 10&lt;sup&gt;−6&lt;/sup&gt; m) the existing vortex gets erased as before. However, beyond this distance a separate antivortex gets created and the vortex-antivortex pair travels to the edge of the condensate system and begins to circulate around , as is shown in Sec. [sec:fewvtx]. For a densely packed lattice of vortices, however, this is not a problem as the typical distance between vortices is of comparable size with the healing length.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig3.pdf&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;lattice-dynamics&#34;&gt;Lattice dynamics&lt;/h3&gt;

&lt;p&gt;The removal of a single vortex from the vortex lattice by phase erasing initially affects only the nearest neighbours, as the phase gradient is only significant over the length scale of a healing length close to the erased singularity. The altered velocity profile will lead to the remaining vortices leaving their initial equilibrium positions in the Abrikosov lattice and the excitation of phonon modes. However, in the lattice areas away from the impurity, these phonon modes have only minimal impact on the geometry, as was observed with the optical lattice kicking described in Sec. [sec:moire_dyn_lattice]. To characterize the vortex dynamics following the application of the phase profile, we will in the following track each individual vortex throughout the full time-evolution and use the resulting trajectories, Delaunay triangulations, and Voronoi tessellations for analysis.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig4.pdf&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch6_phasegineer/varr_161_rho&#34; alt=&#34; Wavefunction densities following a vortex removal close to the centre of the condensate. The vacancy region exists for some time after the removal, before the honeycomb-like structure decays and locally disorders the vortex lattice. &#34; style=&#34;width:96.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let us first consider the situation where a single vortex is erased within the central area of the vortex lattice. In Fig. [fig:trajplot] we show the trajectories of the remaining vortices over a time-scale of 4 seconds, and the corresponding wavefunction densities at *t* = (0.1, 1, 4) s in Fig. [fig:varr161_rho]. One can see that a long-lived vacancy is maintained close to the centre with the adjacent vortices rotating faster than the lattice due to the loss of the local velocity field. The honeycomb-like vacancy region eventually decays and the system settles into a new local geometry. The velocity field magnitude and direction of the condensate local to the removal site are shown in Fig. [fig:varr161_velfield] for *t* = (0.01, 0.1) s. Almost directly following the imprint, the removal site shows a phononic flow that fills in the now unstable dip in the density, and which eventually disperses across the lattice. The small-scale flow magnitude that exists in the remaining region is sufficient to allow for the decay of the honeycomb-like structure during the subsequent time evolution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch6_phasegineer/velfield/var161_velfield&#34; alt=&#34;The velocity field magnitude and direction following the removal of a centrally located vortex from the lattice. At t=10 ms a phononic flow can be observed, resulting from the vortex annihilation. For t=100 ms, a net flow across the previous position of the erased vortex indicates an instability in the region, eventually leading to decay of the vacancy region. &#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Similar behavior can be observed if the erased vortex is not within the central area, as long as it is within a region of constant areal vortex density. However, being closer to the edge of the lattice reduces the stability of the perturbed region, which is likely due in part to the solid-body velocity field of the vortex lattice away from the centre. The overall lattice remains well structured after a vortex removal, as can be seen from the orientational correlation function shown in Fig. [fig:g6] for different times. Although the gaps between the peaks that exist at *t* = 0 disappear during the evolution due to the presence of the phonon excitation, the overall correlations remain high for long times and near constant across all length scales. The slight peak softening arises from the vortices no longer being aligned to a perfect triangular lattice position, which is indicative of a weak disordering or distortion of the lattice structure.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig5.pdf&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As described above, the Delaunay triangulation of the lattice can give a graphical overview of how connected the different vortices are, and therefore what changes to the lattice structure have occurred . We show the case where a single vortex was removed from the lattice centre in Fig. [fig:deltri_1vtx]. One can see that a pair of (5,7)-fold connected lattice defects have formed after the removal (at 10 ms), which slightly adjusts and becomes stable for longer times. Removing vortices at different positions in the lattice shows similar behavior, with a localization of the disordered region not far from the site of the vortex removal.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig6.pdf&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If the phase imprinting is not directly aligned with the vortex singularity, other &lt;em&gt;n&lt;/em&gt;-fold dislocations can be found in the Delaunay triangulation. This is due in part to the vortex core size becoming comparable to the average spacing between the vortices in rapidly rotating condensates, and therefore the imprinted changes to the velocity field affect more nearby vortices. To investigate this effect at the lattice centre, a series of simulations were performed by imprinting at different locations as a function of &lt;em&gt;r&lt;/em&gt; and &lt;em&gt;θ&lt;/em&gt;. Due to the lattice symmetry, the resulting dynamics can be completely obtained by examining the region of *r* = [0, &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;/2) and *θ* = [0, &lt;em&gt;π&lt;/em&gt;/6). A schematic of this shown in Fig. [fig:hex].&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/hex.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Figure [fig:lattice_misalign] shows the time-averaged number of lattice defects following the imprint within this examined region. One can see that if the displacement is still within the core of the vortex, on average 1 or 2 defects are created of the 5-fold (&lt;em&gt;a&lt;/em&gt;) and the 7-fold (&lt;em&gt;b&lt;/em&gt;) kind. At *r* ≈ &lt;em&gt;a&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt;/4 from the core centre, the imprint tends to create upwards of 3 to 4 defects, which again tends back to the average of 2 beyond this region. This shows that the previously discussed issue resulting from the creation of antivortices through imperfect alignment does not exist in Abrikosov lattices, and we will concentrate on the perfect imprint of the phase in the following discussions.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig7.pdf&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To further demonstrate the localized nature of the defects, let us briefly discuss the situation where two vortices are erased in separate regions away from the lattice centre. The Delaunay triangulation for this case is shown in Fig. [fig:traj_2vtx_edge], and the independence of the two localized regions is clearly visible, with each showing behavior similar to the case discussed above. Since we are limiting ourselves here to perfect imprinting, we also show the number of edges formed between vortices as a function of time for 5, 6 and 7 nearest neighbours respectively (&lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;/sub&gt;) in Fig. [fig:vtx_rem2_edge]. One can see that the initial perturbation settles quickly to values similar to the ones above.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig8.pdf&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig9.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In addition to simply erasing vorticity, we can also use phase imprinting to create varying degrees of disorder. By, for example, applying an appropriate 4&lt;em&gt;π&lt;/em&gt; magnitude phase imprint we can replace a vortex with an antivortex at a given position. Since this does not require a change in the local density, all resulting perturbations stem from the adjusted velocity field of the vortex that has been flipped , with snapshots at *t* = (10, 100) ms shown in Fig. [fig:varr161anti_velfield]. Here we can clearly see the change in velocity field direction around the central vortex relative to the surrounding vortices. This in turn causes the surrounding vortices to rotate at a different rate than the solid-body rate of the overall lattice, creating a loss of triangular symmetry in this region on a faster scale than removing a single vortex. It is immediately obvious that such a situation is unstable, which can be confirmed by observing the creation of a large number of defects during the evolution, as shown in Fig. [fig:varr161anti_defect]. An increase in the number of defects can be seen up to approximately *t* = 3 s, during which the antivortex causes local disordering of the lattice, annihilates with a nearby vortex, and gives rise to the creation of a large number of (5,7) defect pairs. After this the number of defects no longer grows, but instead fluctuates about a stable value which is greater than that of the previously examined cases.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;ch6_phasegineer/velfield/var161anti_velfield&#34; alt=&#34;Velocity field of the vortex lattice following the flipping of a vortex to an antivortex for t=(10,100) ms. The change in the velocity field adjacent to the vortex causes the surrounding vortices to rotate at a much slower rate than the solid-body rotation of the vortex lattice. This in turn creates a large change in the resulting ordering of the lattice. The unbalanced local field will eventually lead to the antivortex moving and annihilating with a nearby vortex.&#34; style=&#34;width:95.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig10.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A final class of possible perturbations is the removal of a cluster of neighbouring vortices from the lattice, and in Fig. [fig:remove7_defect] we show the results from erasing an entire seven vortex unit cell from the condensate. As expected, one can see that the number of lattice defects rises considerably and does not settle during the time over which we can simulate the condensate. In this case, the disordered regions occupy a large area of the lattice and the number of 6-fold connected vortices becomes very low.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig11.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Comparing the orientational correlation function for the three cases discussed in this section (removing two distant vortices, creating an antivortex, and removing 7 vortices) also demonstrates the different degree of disorder they produce (see Fig. [fig:g6_2edge_anti_nuclear]). The removal of the two vortices at opposite sides of the condensate still yields reasonably high correlations (⟨&lt;em&gt;g&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt;(&lt;em&gt;r&lt;/em&gt;)⟩ ≈ 0.8) at all times and length scales, indicating a well ordered lattice. Creating an antivortex in the lattice leads to lower correlations across all length scales, especially in the long time limit (⟨&lt;em&gt;g&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt;(&lt;em&gt;r&lt;/em&gt;)⟩ ≈ 0.7), but still tends to the same long-ranged value as the previous case. This indicates an ordered lattice outside the region of the localized defects. Lastly, the removal of seven vortices shows a significant drop in correlations at all length scales and across both times (⟨&lt;em&gt;g&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt;(&lt;em&gt;r&lt;/em&gt;)⟩ ≈ 0.5), indicating a global disordering of the vortices, which is consistent with the large number of defects identified earlier.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/arxiv/fig12.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;An alternative view of the above dynamics can be given from the Voronoi tessellation of the lattice. For the above cases of (&lt;em&gt;a&lt;/em&gt;) removing a vortex from the centre, (&lt;em&gt;b&lt;/em&gt;) removing 2 away from the centre, (&lt;em&gt;c&lt;/em&gt;) flipping the rotation direction, and (&lt;em&gt;d&lt;/em&gt;) removing 7, the ensuing evolutions are shown in Fig. [fig:voronoisarea], with the colours representing the vortex cell area. Snapshots are taken at times *t* = (0.01, 0.1, 1, 6) s, with the mean area $\bar{A}$ and standard deviation &lt;em&gt;σ&lt;/em&gt; over time also shown. We can use this to observe the perturbation on the lattice, and see how it disturbs positions across the entire condensate. One can see that the perturbation initially affects only the vortices close to the defect. The Voronoi cells within this region have a much larger area than those of the surrounding regions. As the system evolves the defect disturbs the system outward from the initial imprint, with the strength of this disturbance being visible in the change of cell areas. As described earlier, the defect region maintains its honeycomb-like structure for up to *t* = 1 s. Rapid oscillations in $\bar{A}$ and a peak in &lt;em&gt;σ&lt;/em&gt; persist up to approximately *t* = 1.5 s, after which they settle into an oscillation at the breathing mode frequency 2&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt; and a constant value respectively for cases (&lt;em&gt;a&lt;/em&gt;), (&lt;em&gt;b&lt;/em&gt;) and (&lt;em&gt;c&lt;/em&gt;). The settling of these values is indicative of the lattice vacancy decaying and the lattice settling into a more disordered arrangement. For case (&lt;em&gt;d&lt;/em&gt;) the removal affects the entire lattice, with the finer details of settling into a new arrangement now completely overtaken by the large-scale disordering.&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_area.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_area.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_area.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_area.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can use the local orientational order parameter &lt;em&gt;g&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt;(0)=|&lt;em&gt;ζ&lt;/em&gt;&lt;sub&gt;6&lt;/sub&gt;(&lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;)|&lt;sup&gt;2&lt;/sup&gt; as the colour scale for the above examples. This is shown in Fig. [fig:voronoiscorr], again with the mean-value and standard deviations over time given. As with the Delaunay triangulation, and the orientational correlations one can see that the effects of the perturbations are confined to the region close to the affected vortex site. The loss of triangular symmetry is observed for the cells surrounding the affected sites for (&lt;em&gt;a&lt;/em&gt;) and (&lt;em&gt;b&lt;/em&gt;), which show an almost identical profile for mean-value and standard deviation. For well separated sites the resulting effects on the lattice can be considered as being independent of one another, due to the local nature of the perturbation. For cases (&lt;em&gt;c&lt;/em&gt;) and (&lt;em&gt;d&lt;/em&gt;), the local disordering of the regions is much higher, with significant deviation from triangular lattice symmetry for *t* = 1 s and beyond. These above methods allow us to clearly identify the effects of the perturbations to the lattice, and are a way towards an understanding of the resulting non-equilibrium dynamics.&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_corr.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_corr.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_corr.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;0.6&lt;/span&gt; &lt;embed src=&#34;ch6_phasegineer/voro/varr_corr.pdf&#34; title=&#34;fig:&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;discussion-and-conclusions&#34;&gt;Discussion and conclusions&lt;/h2&gt;

&lt;p&gt;We have discussed the situation where controllable amounts of disorder can be created in a BEC vortex lattice through vortex removal or rotational direction flipping at predetermined positions. A single vortex removed from an Abrikosov vortex lattice via phase imprinting creates a quasi-stable honeycomb-like vacancy site. The removal of the associated velocity field near the vacancy, however, disturbs the local solid-body behavior and the vacancy region rotates slower than the surrounding vortex lattice. It eventually decays, creating highly stable topological lattice defects due to the local rearrangement of the vortices, which persist for long times.&lt;/p&gt;

&lt;p&gt;In fact, the resulting defects can be seen to pair, with (5,7) lattice defects being the most prominent, and manifesting themselves as dislocation defects in the lattice. Similar behaviour was observed for removing two separated vortices on the lattice, with the resulting defects being independent of one another. This lowered the correlation value, which indicated a drop in the ordering of the vortex lattice. Next, we examined the effect of introducing an anitvortex into the lattice by flipping the phase profile of a pre-existing vortex. The effect of this was to further reduce the order of the vortex lattice, and settle into a lower correlated state than the above cases. Finally, we examined the removal of a large number of adjacent vortices in the lattice, which showed a significant drop in correlations, and hence ordering, over the course of evolution.&lt;/p&gt;

&lt;p&gt;The characterization of perturbed lattices put forward by us complements the recent work of Rakonjac &lt;em&gt;et al.&lt;/em&gt; , where the authors determine the disorder present in a vortex lattice in a BEC by comparing the ratio of the standard deviation of nearest neighbor distances to the mean distance. Here we extend the available tools by using orientational correlations, Delaunay triangulation for topological defect detection, Voronoi tessellation for identifying regions of modified orientational order, and by introducing a method to controllably engineer lattice defects through phase imprinting.&lt;/p&gt;

&lt;p&gt;One possible use for the techniques we have discussed is to create vortex turbulence in low-dimensional condensate systems. Contrary to all currently existing discussions, this would make use of the phase erasing technique in Abrikosov lattices to examine turbulence starting from highly ordered systems . While the use of vortex flipping has been considered previously , doing this in a highly controllable manner would be advantageous, as one could potentially also investigate phase transitions in the vortex system.&lt;/p&gt;

&lt;p&gt;KTHNY (Kosterlitz, Thouless, Halperin, Nelson, Young) theory predicts the melting of two-dimensional systems as a two-step process, where the paired (5,7) defects dissociate, causing a loss of translational correlations, while maintaining quasi-long range orientational order . This resulting phase is known as “hexatic”, and exists between the solid and isotropic liquid phases in two-dimensions. This phase may potentially be observed from the decay profile of correlations in this system. However, given the finite size of this system, observing the hexatic phase may be challenging, as one normally uses the combination of translational correlations as well as orientational correlations to identify this behaviour. In this instance, given the lack of applicability of translational correlations, one might instead opt to examine the structure factor
$$S(\mathbf{q}) = \frac{1}{N_v}\displaystyle\sum\limits_{j,k=1}^{N_v} e^{-\textrm{i}\mathbf{q}\cdot(\mathbf{r}_j - \mathbf{r}_k)},$$
 where &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;v&lt;/em&gt;&lt;/sub&gt; is the number of vortices, and &lt;strong&gt;r&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;, &lt;em&gt;j&lt;/em&gt;&lt;/sub&gt; are the respective vortex positions. The structure factor can be examined for an arc-like profile, which is indicative of the presence of a hexatic phase . While this was briefly examined (see Fig. [fig:struct_fact]), conclusive results of such a phase were not initially found. This is likely due to the finite-size of the examined system.&lt;/p&gt;

&lt;p&gt;A potential criteria for the onset of the hexatic phase can be given between the stretching and orientational order of nearest neighbouring vortex positions and a Lindemann parameter which quantifies the loss of both translational and orientational order . Additionally, one can examine the statistics of the endpoints of defect strings, formed between pairs of dislocation (5,7) defects, which can be determined from small particle number systems . While not examined in the preceding work, these methods can form the basis of a future investigation for the existence of the hexatic phase in the vortex lattice system.&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;ch6_phasegineer/structfact.pdf&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;conclusions-and-outlook-2&#34;&gt;Conclusions and outlook&lt;/h1&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;In this thesis we have presented our work on the dynamical behaviour of non-equilibrium Bose–Einstein condensates, where we have examined the behaviour of vortex lattices subjected to two distinct perturbations. We began by modelling the condensate using the mean-field Gross–Pitaevskii equation. Using this formalism we then discussed the superfluid properties of the condensate, and concentrated primarily on states with vorticity in two-dimensions. We primarily discussed high rotation rates of the condensate, where the condensate attains a large number of singly charged vortices arranged in a triangular Abrikosov vortex lattice. We restricted ourself to a rotation rate of *Ω* = 0.995&lt;em&gt;ω&lt;/em&gt;&lt;sub&gt;⊥&lt;/sub&gt;, and sought a numerical solution of the system with *N* ≈ 10&lt;sup&gt;6&lt;/sup&gt; atoms of **&lt;sup&gt;87&lt;/sup&gt;Rb.&lt;/p&gt;

&lt;p&gt;We next introduced the algorithmic framework to numerically solve this system, making use of the Fourier split-operator method. With this we discussed imaginary time evolution to determine the vortex lattice ground state, and real time evolution for all subsequent dynamics. The simulation of this system was computationally challenging due to the finely sampled numerical grid required to resolve all features of the condensate in position and momentum space. To overcome this challenge, we introduced GPU computing methods, which were demonstrated for the problem of coherent atomic transport. For this we investigated a system using SAP methods with magnetic waveguides on atom-chips. These advanced computational techniques allowed for a fully three-dimensional simulation of the Schrödinger equation to be solved in significantly less time than a standard CPU implmentation. The resulting GPU code was compared with a traditional MPI-enabled code, and showed equivalent performance to an 8-core 8-node cluster for the same system parameters. This led to the development of a software suite for the numerical solution of the Gross–Pitaevskii equation titled “GPUE”. An independently operated performance test of this suite was found to outperform other numerical softwares for the same class of problems.&lt;/p&gt;

&lt;p&gt;Using the developed numerical suite, we performed a series of simulations for stationary and rotating condensates with a low number of vortices. We mentioned the necessary criteria for ensuring a well-ordered vortex lattice, and examined a condition where these criteria were unfulfilled. Following this, we introduced two distinctive perturbation techniques to disturb the the condensate, and allow non-equilibrium dynamics to be observed. The first method used a kicked optical potential, which modified the condensate phase. By matching the structure and lattice constants of both the optical and vortex lattices, the kick allowed for the generation of transient, time-varying superlattice structures in the density. These superlattice structures were observed during the subsequent dynamical evolution following the kick. By varying the alignment angle of the optical lattice relative to the vortices, we showed that the wavelength of the structures could be changed. The change in the structures were explained using moiré interference theory, and arose from the interference between the reciprocal lattice vectors of both the optical and vortex lattices. This was confirmed by examining the compressible kinetic energy spectrum of the condensate. The kicking perturbation showed how robust the vortex lattice was to density variations, with the phonons generated by the kick having little to no effect on the vortex positions.&lt;/p&gt;

&lt;p&gt;As the vortex lattice proved to be very robust following the kicked potential, we next investigated methods to controllably create disorder in the vortex lattice. By directly phase imprinting topological excitations (phase singularities), we demonstrated that this was possible. From the well ordered vortex lattice ground state we annihilated or flipped the rotation direction of vortices at predefined positions in the lattice. As a vacancy was created in the vortex lattice following an annihilation, the remaining vortices attempted to redistribute and reorder to the most favourable position. Through extensive simulations, this was shown to create localised topological defects in the lattice, with the overall lattice still maintaining a large degree of order. Varying degrees of disorder were then created by removing additional vortices, or by flipping a vortex rotation profile. The use of Delaunay triangulation allowed us to easily identify the defect types, and largely showed the appearance of (5,7) topological lattice defects. By examining the orientational correlations of the lattice we observed that different imprints created varying degrees of lattice disordering. We then made use of Voronoi tessellations to allow local variations in lattice area and orientational correlations respectively to be identified following an annihilation, and demonstrated the effect the phase imprinting had on the vortex lattice on different timescales.&lt;/p&gt;

&lt;h2 id=&#34;outlook&#34;&gt;Outlook&lt;/h2&gt;

&lt;p&gt;Given the current state-of-the-art experimental control of condensate systems through use of SLMs, the perturbation methods discussed within this thesis are expected to be realisable. These perturbations represent two very useful techniques for quantum state control and engineering. For the kicked optical lattice, the creation of moiré interference patterns with wavelengths much greater than the lattice spacing opens the possibility for detecting vortices without time-of-flight expansion in a lattice. We consider this technique to be a unique method for examining the periodicity of a lattice system, where the evolving pattern can also potentially be observed through the &lt;em&gt;in-situ&lt;/em&gt; imaging techniques, as discussed in [sec:intro_super]. Further extensions of this work can involve investigating the periodicity of large-scale soliton trains in quasi-1D condensates.&lt;/p&gt;

&lt;p&gt;Some preliminary work in small-scale zig-zag and linear vortex crystals was carried out in conjunction with A. Barahmi and Th. Busch. This showed that with little periodicity in the system there were negligible peaks in the compressible energy spectrum. As a result, there were no discernible moiré superlattice patterns in the condensate density. It is expected that for these structures to be observed that highly periodic systems with a well defined reciprocal lattice are required. However, given a highly periodic system, any disordering of the system will affect the visibility of the peaks. As a result, this method could potentially allow for an examination of lattice disorder, and can form the basis of a future investigation.&lt;/p&gt;

&lt;p&gt;The vortex annihilation/flipping through phase imprinting appears to be a very good candidate to create varying degrees of disorder in a vortex lattice system. The analysis methods discussed and used for this work can easily be applied to real experimental data. A potential use for this is to create controllable routes towards quantum turbulence from a well-ordered system. While the examination presented focussed primarily on the use of phase profiles opposite to that of the lattice, the imprinting of like-signed vortices also remains an interesting choice. Forcing vortices into different locations in the lattice is potentially an additional method to create lattice dislocations, and hence, topological lattice defects. One might consider erasing and adding vortices at different locations to both create and remove topological lattice defects. This can form the basis for a memory storage technique in a quantum computing system. The applicability of this method can potentially be examined in a future work.&lt;/p&gt;

&lt;p&gt;Additionally, one can also create multi-charged vortices in the condensate. The effect of the surrounding lattice on the resulting multi-charged vortex would be an interesting problem. One might expect the &lt;em&gt;l&lt;/em&gt;-charge vortex decay to be suppressed if the energy to move the surrounding lattice vortices is greater than the energy to maintain the &lt;em&gt;l&lt;/em&gt;-charged vortex. This was briefly investigated by examining the Bogoliubov-de Gennes solutions of the imprinted vortex lattice system, with the aim of observing if the resulting excitation modes were complex. These modes were, however, not found due to the numerical complexity of the problem, and it remains an open question if this suppression exists. This will be investigated in a future work.&lt;/p&gt;

&lt;p&gt;While we briefly mentioned the search for a KTHNY hexatic phase transition in this system, this will require further examination. Future work can include an investigation for the existence of this transition, and examine whether dislocation mediated melting of the vortex lattice can occur as a result of the phase imprinting techniques. Though we consider the framework developed and examined for all the above methods to be valid, the consideration of finite temperature effects would ensure that the investigated methods are truly physically realistic. For such finite temperature condensates, one might consider use of the Zaremba–Nikuni–Griffin (ZNG) formalism , or the formalism of Billam *et al.* . An extension of the above works can examine this.&lt;/p&gt;

&lt;p&gt;The use of GPU computing for simulating quantum dynamics is currently an under-utilised paradigm. The potential for a significant performance gain exists, given an effective mapping of a numerical algorithm to the GPU hardware. While the code developed and utilised for all the above simulations offers a clear performance advantage, it should be noted that further development and maintenance of such code can be challenging. Rapid changes to the CUDA programming models have introduced many new features to the standard which could potentially be used for solving more complex problems of both linear and nonlinear Schrödinger-type problems. However, such changes often require training, software rewrites, or newer hardware to take advantage of these. An extension of the GPUE codebase to cover one and three dimensional Gross–Pitaevskii systems will allow for this suite to be as feature rich as the currently most capable suites available , whilst still holding the current edge in performance. Solutions using arbitrary gauge fields for these problems will also offer a distinctive advantage. Additionally, the inclusion of a numerical BdG solver for the resulting numerical solutions will allow for this software to become a very general suite for BEC problems.&lt;/p&gt;

&lt;p&gt;The methods and works examined in this thesis offer interesting answers, questions and possibilities for the future of controllable quantum systems and technologies.&lt;/p&gt;

&lt;p&gt;[1] AmazDooM font, CC BY-NC 3.0&lt;/p&gt;

&lt;p&gt;[2] The documentation is built using  &lt;a href=&#34;http://www.stack.nl/~dimitri/doxygen/&#34;&gt;Doxygen&lt;/a&gt; with the command “doxygen ./docs/gpue_doxy.conf”, and requires the &lt;em&gt;dot&lt;/em&gt; package for figure generation. This may change during future releases.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 1</title>
      <link>https://mlxd.github.io/post/2015-09-18-quantums/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-18-quantums/</guid>
      <description>

&lt;h1 id=&#34;bose-einstein-condensation&#34;&gt;Bose$-$Einstein condensation&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;This will be a hand-waiving introduction to Bose-Einstein condensate theory. I&amp;rsquo;ll begin by introducing what is a Bose-Einstein condensate, followed by how we model it (hint: we use the Gross-Pitaevskii equation). For more detailed derivations, see Pethick and Smith [ISBN: 978-0521846516] or Pitaevskii and Stringari [ISBN: 978-0198507192].&lt;/p&gt;

&lt;p&gt;Again, this is another work in progress, so expect me to continually dump my thoughts here and on subsequent posts.&lt;/p&gt;

&lt;h2 id=&#34;schrödinger-equation&#34;&gt;Schrödinger equation&lt;/h2&gt;

&lt;p&gt;To understand how we simulate a Bose$-$Einstein condensate, first we must examine the behaviour of the Schrödinger equation. I will assume that you are already familiar with the Schrödinger equation, but if not, I will recommend the usual material:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Principles of Quantum Mechanics, Shankar [ISBN: 978-0306447907]&lt;/li&gt;
&lt;li&gt;Introduction to Quantum Mechanics, Griffiths [ISBN: 978-9332542891]&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;single-particle&#34;&gt;Single particle&lt;/h3&gt;

&lt;p&gt;The single particle Schrödinger equation describes the behaviour of a non-relativistic (i.e. much slower than the speed of light, and/or massless) quantum particle. Firstly, we define our Hamiltonian as&lt;/p&gt;

&lt;p&gt;$$
\hat{H}_0 = -\frac{\hbar^2}{2m} \hat{\nabla}^2 ,
$$&lt;/p&gt;

&lt;p&gt;where $~\hat{H}_0$ corresponds with the momentum-space operator for a free particle. Assuming the particle is trapped by an external potential energy, we can give the following Hamiltonian instead,&lt;/p&gt;

&lt;p&gt;$$
\hat{H}_1 = \hat{H}_0 + \hat{V}_{\textrm{ext}}(\mathbf{r},t).
$$&lt;/p&gt;

&lt;p&gt;Now we have a potential and kinetic term for our system. In cold atomic systems, we nearly always have trapped atoms, by use of an external trapping potential [usually with optical or magnetic fields]. To simulate the dynamics of a single particle in a trapping potential, we use the time dependent Schrödinger equation,&lt;/p&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}{\Psi}(\mathbf{r},t) =  \hat{H}_1 {\Psi}(\mathbf{r},t).
$$&lt;/p&gt;

&lt;h3 id=&#34;many-particle&#34;&gt;Many particle&lt;/h3&gt;

&lt;p&gt;$$
 H_N = \displaystyle\sum\limits_{i=1}^{N} \left(-\frac{\hbar^2}{2m_i} \nabla_i^2 + V_\textrm{ext}(\mathbf{r}_i,t) + \displaystyle\sum_{j\neq i}^{N-1}U(\mathbf{r}_i,\mathbf{r}_j) \right)
$$
Solving this for the ground state is hard, even numerically. The memory requirements grow exponentially as we increase the particle count, as every particle must interact in some way with all the others nearby. Therefore, in order to find the lowest energy state we must &lt;a href=&#34;http://arxiv.org/pdf/1301.2073v1.pdf&#34;&gt;simplify things&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s assume that particles don&amp;rsquo;t interact over long, or even short ranges. What if they can only interact when they occupy the same position, as though $|\mathbf{r}_i - \mathbf{r}_j| = 0$. Also, we can say that the strength of this interaction is dependent upon some parameter, $g$, which depends on properties of the particle. We can also assume that the more particles in a particular region, then the larger the interactions in that specific region. Thus, we can say that these interactions can be approximated by $g\rho(\mathbf{r},t)$, where $\rho$ is the particle density in the region.&lt;/p&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}\hat{\Psi}(\mathbf{r}_1,\dots\mathbf{r}_N,t) = \left[\hat{\Psi}(\mathbf{r}_1,\dots\mathbf{r}_N,t), H_N \right]
$$&lt;/p&gt;

&lt;h2 id=&#34;gp-equation&#34;&gt;GP equation&lt;/h2&gt;

&lt;p&gt;$$
i\hbar\frac{\partial}{\partial t}\Psi(\mathbf{r},t) = \left[ -\frac{\hbar^2}{2m} \nabla^2 + V(\mathbf{r},t) + \color{violet}{g\vert\Psi(\mathbf{r},t)\vert^2} -\color{teal}{\mathbf{\Omega}\cdot \mathbf{L} }\right]\Psi(\mathbf{r},t)&lt;br /&gt;
$$&lt;/p&gt;

&lt;h3 id=&#34;madelung-transform&#34;&gt;Madelung transform&lt;/h3&gt;

&lt;p&gt;$$
 \Psi(\mathbf{r},t) = \sqrt{\rho\left(\mathbf{r},t\right)}\exp\left[i\theta\left(\mathbf{r},t\right)\right],
$$
where $$\rho(\mathbf{r},t) = |\Psi\left(\mathbf{r},t\right)|^2$$&lt;/p&gt;

&lt;h3 id=&#34;evolution&#34;&gt;Evolution&lt;/h3&gt;

&lt;p&gt;$$
\Psi(\mathbf{r},t+\delta t) = \exp\left(-\frac{i H}{\hbar}\delta t\right)\Psi(\mathbf{r},t)
$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 2</title>
      <link>https://mlxd.github.io/post/2015-09-20-quantum-vortices/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-20-quantum-vortices/</guid>
      <description>

&lt;h1 id=&#34;quantum-vortices&#34;&gt;Quantum vortices&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Consider, if you will, a bucket of water. We can also do this with a closed bottle of water, to prevent from getting wet, but let&amp;rsquo;s assume we have a bucket. We drop a spoon/stick/paddle in there, and begin to draw a circle, stirring the water. If the item is removed, the water continues to rotate, gradually slowing down before coming to a halt. Let us now assume that the water is spinning quickly, such that a hole develops in the centre. We call this a vortex. As it rotates faster and faster, the vortex increases in size, until we rotate so fast that the water flies out over the edge of the bucket. Hopefully, you have a towel on hand.&lt;/p&gt;

&lt;p&gt;Now, let us assume that we have a really small bucket, namely a &lt;em&gt;quantum bucket&lt;/em&gt;. This quantum bucket, like the normal bucket, holds atoms, but very few of them in comparison. These atoms are also very cold, and form what is known as a [Bose-Einstein condensate](). Now, imagine we have a really small spoon/stick/paddle, and we once again begin to stir. What do we assume will happen?&lt;/p&gt;

&lt;p&gt;Nothing may happen. Otherwise, something strange may happen. Both &lt;em&gt;nothing&lt;/em&gt;, and &lt;em&gt;something strange&lt;/em&gt; are equally interesting. What causes these two separate, yet related, cases is a (not unique) property of Bose-Einstein condensates known as &lt;em&gt;superfluidity&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Let us go back to stirring our condensate. If we stir slowly enough, the condensate will remain stationary. That is to say, it will be as if we were not stirring at all. To allow it rotate, the stirring rate must be above a specific value. This is because, in a superfluid, the circulation occurs in discrete units only. That is to say, it is quantised.&lt;/p&gt;

&lt;p&gt;Unlike a classical fluid, such as water, a condensate cannot accept a continuous range of values with which it rotates. Also, unlike a classical fluid, a superfluid in rotation will continue to rotate without slowing, provided the quantum bucket holds it in place. Beyond the critical value for rotation in a condensate a vortex will be visible. This vortex will not grow or shrink with changes around the critical value, as though a vortex in water might. However, since it does not grow, what happens with faster rotation?&lt;/p&gt;

&lt;p&gt;Since the rotation is quantised, we could assume that beyond another specific value, the vortex might just become wider,  with a circulation of 2 units, instead of just 1. This, however, is not the case (in most cases encountered). Instead of a &lt;em&gt;winding&lt;/em&gt; 2 vortex, we obtain 2 &lt;em&gt;winding&lt;/em&gt; 1 vortices.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to GPUE: Part 3</title>
      <link>https://mlxd.github.io/post/2015-09-22-tdsim/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-09-22-tdsim/</guid>
      <description>

&lt;h1 id=&#34;time-dependent-simulations&#34;&gt;Time dependent simulations&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;I will focus on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pseudo-spectral_method&#34;&gt;pseudo-spectral&lt;/a&gt; Fourier split operator (or split step) method.&lt;/p&gt;

&lt;p&gt;Firsly, we need to quantised position space by making a grid over a specific range of position values. Assume $-10$ $\mu$m to $+10$ $\mu$m, giving a grid divided into $xDim=2^8$ equispaced elements. Let us call this grid $\mathbf{x}$, and the maximum value $x_\textrm{max}$. The following Julia code will carry out the above:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;xDim = 2^8; # The resolution of your grid.
xMax = 4e-4;
x = linspace(-xMax, xMax, xDim);
dx = abs(x[2]-x[1]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, so now that we have our grid in position space, we need to also consider generating another grid, this time in &lt;a href=&#34;https://en.wikipedia.org/wiki/Position_and_momentum_space&#34;&gt;momentum space&lt;/a&gt; (also known as reciprocal space, $k$ space). Position and momentum space are related by the Fourier transform.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;kxMax = (2*pi/xMax)*(xDim/2);
kx = circshift(linspace(-kxMax,kxMax,xDim),xDim/2);
dkx = abs(kx[2] - kx[1]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, as you may know, knowledge of position can affect your knowledge of momentum, and vice-versa. In this case, our fundamental limit is defined by the size of our grid dimension, $d$. Just as the wavenumber is given by the relation $k = \frac{2\pi}{\lambda}$, we can obtain our smallest $k$ value using our largest position space value, $x_\textrm{max}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;#Define properties of the system
omegaX = 2*pi*1 # Harmonic trapping potential frequency
hbar = 1.0545718e-34;
m = 1.4431607e-25; #Rb87 mass
a_s = 4.76e-9; #S-wave scattering length
dt = 1e-4; #Timestep

#Make an initial guess
wfc = pdf(Normal(0,xMax/100),x) + 0*im;

#Define the trapping potential and kinetic energy operators
V = 0.5*m*x.^2.*omegaX^2;
K = (0.5*hbar^2/m).*(kx.^2);

GV = exp(-0.5*V*dt/hbar);
GK = exp(-K*dt/hbar);

wfc /= sqrt(sum(abs(wfc).^2)*dx);
for t=1:10000
        wfc = wfc.*GV;
        wfc = ifft(fft(wfc).*GK);
        wfc = wfc.*GV;
        wfc /= sqrt(sum(abs(wfc).^2)*dx);
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;function energy(wfc,dx,V,K)
        EV = V.*wfc;
        EK = ifft(K.*fft(wfc));
        E = conj(wfc).*(EV + EK)
        return real(sum(E)*dx)/hbar
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-jl&#34;&gt;e_0 = 1e100 #Arbitrarily large unrealistic value
e_1 = energy(wfc,dx,V,K);

while e_0-e_1 &amp;gt; 1e-7
        push!(E,e_1)
        wfc = wfc.*GV;
        wfc = ifft(fft(wfc).*GK);
        wfc = wfc.*GV;
        wfc /= sqrt(sum(abs(wfc).^2)*dx);
        e_0 = e_1;
        e_1 = energy(wfc,dx,V,K)
        println(e_1)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$$  k_\textrm{max} = \frac{2\pi}{x_\textrm{max}}d $$
n A&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Permutations of n-D data</title>
      <link>https://mlxd.github.io/post/2017-09-04-nd-data/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-09-04-nd-data/</guid>
      <description>&lt;p&gt;Something I have been (occasionally) thinking about for quite a long time is the means to manipulate high-dimensional data-sets (dense grids, specifically), and do so efficiently. Namely, I wish to make the data along any specific orthgonal basis direction to become adjacent in memory by strides of the length of samples along that axis.&lt;/p&gt;

&lt;p&gt;The reason for this? To allow for optimal vectorisation and caching of data when performing computations. Take for example a GPU: if we put data on GPU memory we want to access and manipulate it in chunks given by the chosen thread-size. If we access elements out of order, we essentially lose all of the parallelism offered by the device, as the data access will not be performed in the optimal $n$-element wide chunks, but individually at worst, and somewhere in between most likely.&lt;/p&gt;

&lt;p&gt;For a problem with a Cartesian gridded data set in the space given by $ijk$, we can define the lexicographical order from fastest to slowest indices to be in the $ijk$ order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;for(int k=0; k &amp;lt; k_size; ++k)
    for(int j=0; j &amp;lt; j_size; ++j)
        for(int i=0; i &amp;lt; i_size; ++i)
            data[i + i_size*(j + j_size*k)] = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example, $i$ is the fast index and the axis along which the data is linearly adjacent in memory, and $k$ is the slow axis (with $j$ being slower than fast and faster than slow).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mlxd.github.io/img/ndData.jpg&#34; alt=&#34;alt text&#34; title=&#34;A sample layout permutation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The included image above is an example of rotation about the $j$ axis, showing on the right the respective mappings to new index values (for the sake of my interest I&amp;rsquo;ve taken slices along $j$ and $i$, but worked with the latter for the rest of this discussion).&lt;/p&gt;

&lt;p&gt;The bottom of the image shows the rearrangements of memory from the original (upper) to the rotated (lower) memory configurations. The indices themselves seem to take the following mappings (orig. $\rightarrow $ rot.):&lt;/p&gt;

&lt;p&gt;$$ \begin{align}
i &amp;amp; \rightarrow \textrm{stride}(j)-k, \\&lt;br /&gt;
j &amp;amp; \rightarrow j, \\&lt;br /&gt;
k &amp;amp; \rightarrow i, \
\end{align}$$&lt;/p&gt;

&lt;p&gt;where the stride() operation returns the spacing between the elements in the given dimension (in this case, the stride of $j$ is the size of $i$).&lt;/p&gt;

&lt;p&gt;I intend to find an optimal way to perform this in time. Even suboptimal, but good enough would be fine though.&lt;/p&gt;

&lt;p&gt;L.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FFTs over time and space... and devices</title>
      <link>https://mlxd.github.io/post/2017-07-11-ffts/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-07-11-ffts/</guid>
      <description>

&lt;p&gt;&lt;code&gt;The following article is a work in progress, and will be continually updated over time. I&#39;ll issue a RELEASE tag or similar when everything has been finished.&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;q-how-do-available-fft-routines-compare-over-different-libraries-and-accelerator-hardwares&#34;&gt;Q. How do available FFT routines compare over different libraries and accelerator hardwares?&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;This is something I have wondered for sometime, though it can be difficult for an apples-to-apples comparison. I will consider the above question in relation to the following plan:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Comparing FFT implementations in a pseudospectral solver for linear and nonlinear Schrodinger equation dynamics&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To decide on how to proceed, it is instructive to list all (or most) widely known and used implementations.&lt;/p&gt;

&lt;h2 id=&#34;standard-implementations&#34;&gt;Standard implementations&lt;/h2&gt;

&lt;h3 id=&#34;cpu&#34;&gt;[CPU]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FFTW: &lt;a href=&#34;http://fftw.org/&#34;&gt;http://fftw.org/&lt;/a&gt; and &lt;a href=&#34;https://github.com/FFTW/fftw3&#34;&gt;https://github.com/FFTW/fftw3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MKL-FFT: &lt;a href=&#34;https://software.intel.com/en-us/articles/the-intel-math-kernel-library-and-its-fast-fourier-transform-routines&#34;&gt;https://software.intel.com/en-us/articles/the-intel-math-kernel-library-and-its-fast-fourier-transform-routines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;clFFT: &lt;a href=&#34;https://github.com/clMathLibraries/clFFT&#34;&gt;https://github.com/clMathLibraries/clFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Eigen FFT (using kissfft backend): &lt;a href=&#34;http://eigen.tuxfamily.org/index.php?title=EigenFFT&#34;&gt;http://eigen.tuxfamily.org/index.php?title=EigenFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sFFT: &lt;a href=&#34;http://groups.csail.mit.edu/netmit/sFFT/code.html&#34;&gt;http://groups.csail.mit.edu/netmit/sFFT/code.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KFR FFT: &lt;a href=&#34;https://github.com/kfrlib/fft&#34;&gt;https://github.com/kfrlib/fft&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gpu&#34;&gt;[GPU]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;cuFFT: &lt;a href=&#34;http://docs.nvidia.com/cuda/cufft/index.html&#34;&gt;http://docs.nvidia.com/cuda/cufft/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;clFFT: &lt;a href=&#34;https://github.com/clMathLibraries/clFFT&#34;&gt;https://github.com/clMathLibraries/clFFT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;fbfft: &lt;a href=&#34;https://github.com/facebook/fbcuda/tree/master/fbfft&#34;&gt;https://github.com/facebook/fbcuda/tree/master/fbfft&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1412.7580&#34;&gt;https://arxiv.org/abs/1412.7580&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cutting-edge&#34;&gt;[Cutting edge]&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FPGA FFT (Xilinx and Altera/Intel): &lt;a href=&#34;https://www.xilinx.com/products/intellectual-property/fft.html&#34;&gt;https://www.xilinx.com/products/intellectual-property/fft.html&lt;/a&gt; and &lt;a href=&#34;https://www.altera.com/products/intellectual-property/ip/dsp/m-ham-fft.html&#34;&gt;https://www.altera.com/products/intellectual-property/ip/dsp/m-ham-fft.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IBM TrueNorth FFT: No link/source found (yet)&lt;/li&gt;
&lt;li&gt;Rigetti pyQuil quantum FFT: &lt;a href=&#34;http://pyquil.readthedocs.io/en/latest/getting_started.html&#34;&gt;http://pyquil.readthedocs.io/en/latest/getting_started.html&lt;/a&gt; (currently emulated AFAIK, but will eventually/hopefully run directly on quantum hardware)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;test-cases&#34;&gt;Test cases&lt;/h2&gt;

&lt;p&gt;To ensure sufficient time is spent in the FFT routines I will opt for a 2D transform of an NxN grid, requiring N transforms, a transpose, and another N. The value of N can be scaled to determine sweet spots for all implementations. Granted, memory size will be the determining factor of how large we can go. $N=2^j$ where $j \in \mathbb{Z}, 7 \leq j \leq 11$ is a reasonable range of values to examine that should fit readily on most hardware.&lt;/p&gt;

&lt;p&gt;For this, the following test precisions will be instructive:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;$\mathbb{C}2\mathbb{C}$ - 32-bit float (32-bits for each real and imaginary component)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{C}2\mathbb{C}$ - 64-bit float&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{R}2\mathbb{C}$ - 32-bit float&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;$\mathbb{R}2\mathbb{C}$ - 64-bit float&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a sample system to investigate, I will consider the case of a quantum harmonic oscillator (QHO). To investigate dynamics and their resulting accuracy, a known and analytically calculable result is useful. For this, I will opt for a a superposition state of the groundstate along the $xy$ plane, and the first excited state along $x$ with the groundstate along $y$. To put things more formally:&lt;/p&gt;

&lt;p&gt;$$
\Psi(x,y) = \frac{ \Psi_{00}(x,y) + \Psi_{10}(x,y) }{\sqrt{2}}.
$$
To construct the above wavefunction we will assume that the states $\Psi_{00}(x,y)$ and $\Psi_{10}(x,y)$ are outer products of the solutions to the QHO, as given by:&lt;/p&gt;

&lt;p&gt;$$
\Psi_n(x) = \frac{1}{\sqrt{2^{n}n!}}\left(\frac{m\omega_x}{\pi\hbar}\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}}H_n(x),
$$
where $$
H_n(x)=(-1)^n\mathrm{e}^{x^2}\frac{d^n}{dx^n}\left(\mathrm{e}^{-x^2}\right),$$
are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Hermite_polynomials&#34;&gt;physicists&amp;rsquo; Hermite polynomials&lt;/a&gt;. As we are looking for the ground and first excited states ($n=0,1$) we can simplify a lot of the above calculations: $H_0(x)=1$ and $H_0(x)=2x$. Next, we determine the states $\Psi_0(x)$ and $\Psi_1(x)$ as:&lt;/p&gt;

&lt;p&gt;$$ \begin{eqnarray}
\Psi_0(x) = \left(\frac{m\omega_x}{\pi\hbar}\right)^\frac{1}{4}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}},~
\Psi_1(x) = \frac{2x}{\sqrt{2}} \left(\frac{m\omega_x}{\pi\hbar}\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m\omega_x x^2}{2\hbar}}.
\end{eqnarray}
$$&lt;/p&gt;

&lt;p&gt;Along a single dimension, our system can potentially be in any of the allowed harmonic oscillator states. Therefore, the overall state is given by a tensor product of the state along $x$ and that along $y$. If we assume the dimensionality of the Hilbert space along the $i$-th orthogonal spacial index is finite and given by $d_i$, then the overall system dimensionality (ie the total number of states we can consider) is $d = \displaystyle\prod_{i} d_i$.&lt;/p&gt;

&lt;p&gt;Assuming an $n$-dimensional system, where each individual dimension is in the groundstate of the harmonic oscillator, we can define the tensor product state as
$$
\Psi_n = \Psi_0^{\otimes n} = \Psi_0 \otimes \Psi_0  \cdots \otimes \Psi_0.
$$&lt;/p&gt;

&lt;p&gt;While the above is fine for a general case, for the purposes of FFTs we have assumed a much simpler system, dealing with combinations of only 2 states. We can then define them as $\Psi_{00}(x,y) = \Psi_{0}(x)\otimes\Psi_{0}(y)$ and $\Psi_{10}(x,y) = \Psi_{1}(x)\otimes\Psi_{0}(y)$. Thus, our final superposition state when filling everything in is given by
$$
\Psi(x,y) = \left(\frac{m}{\pi\hbar}\right)^{\frac{1}{2}}\left(\omega_x\omega_y\right)^{\frac{1}{4}}\mathrm{e}^{-\frac{m}{2\hbar}\left(\omega_x x^2 + \omega_y y^2\right)}\left(x + \frac{1}{\sqrt{2}}\right).
$$&lt;/p&gt;

&lt;p&gt;To simplify life, I will assume some of the above quantities are set to unity (i.e. $m=\omega_x = \omega_y = \hbar = 1$). This will not change the dynamics of the simulation, but simplify the equations and the numerical implementation, which can help with improving accuracy. The above equation then becomes
$$
\Psi(x,y) = \left(\frac{1}{\pi}\right)^{\frac{1}{2}}\mathrm{e}^{-\frac{1}{2}\left( x^2 + y^2 \right)}\left(x + \frac{1}{\sqrt{2}}\right).
$$&lt;/p&gt;

&lt;p&gt;For a more detailed explanation and approach to the above have a look at Christina Lee&amp;rsquo;s (&lt;a href=&#34;https://github.com/albi3ro&#34;&gt;albi3ro&lt;/a&gt;) blog post on &lt;a href=&#34;http://albi3ro.github.io/M4//prerequisites%20required/Time-Evolution.html&#34;&gt;time evolution&lt;/a&gt;, which will cover the method I use next.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;To be continued&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/***

This document will implement the quantum simulation aspects of the code, in as simple a means as possible.

***/
#include&amp;lt;stdio.h&amp;gt;
#include&amp;lt;stdlib.h&amp;gt;
#include&amp;lt;math.h&amp;gt;

#define GRIDSIZE 128
#define GRIDMAX 5
#define PI 3.14159
#define DT 1e-4


//################################################//

struct double2{
    double x;
    double y;
};

//Define the grid on which the simulation will be run.
struct Grid{
    double *x = (double*) malloc(GRIDSIZE*sizeof(double));
    double *y = (double*) malloc(GRIDSIZE*sizeof(double));
    double *xy2 = (double*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double));

    double *kx = (double*) malloc(GRIDSIZE*sizeof(double));
    double *ky = (double*) malloc(GRIDSIZE*sizeof(double));
    double *kxy2 = (double*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double));

    double2 *wfc = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
    double2 *U_V = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
    double2 *U_K = (double2*) malloc(GRIDSIZE*GRIDSIZE*sizeof(double2));
};

void setupGrids(Grid *grid){
    double invSqrt2 = 1/sqrt(2);
    //Position space grids
    for (int j=0; j &amp;lt; GRIDSIZE; ++j){
        grid-&amp;gt;x[j] = -GRIDMAX + j*(2*GRIDMAX)/((double)GRIDSIZE);
        grid-&amp;gt;y[j] = grid-&amp;gt;x[j];
    }
    for(int i=0; i &amp;lt; GRIDSIZE; ++i){
        for(int j=0; j &amp;lt; GRIDSIZE; ++j){
            grid-&amp;gt;xy2[j+GRIDSIZE*i] = 0.5*(grid-&amp;gt;x[i]*grid-&amp;gt;x[i]+grid-&amp;gt;y[j]*grid-&amp;gt;y[j]);
            //Evolution operator in position space
            grid-&amp;gt;U_V[j+GRIDSIZE*i].x = cos(-grid-&amp;gt;xy2[j+GRIDSIZE*i]*DT);
            grid-&amp;gt;U_V[j+GRIDSIZE*i].y = sin(-grid-&amp;gt;xy2[j+GRIDSIZE*i]*DT);
            
            //Wavefunction
            grid-&amp;gt;wfc[j+GRIDSIZE*i].x = sqrt( 1/PI )*exp( -0.5 * ( grid-&amp;gt;x[i]*grid-&amp;gt;x[i] + grid-&amp;gt;y[j]*grid-&amp;gt;y[j] ) ) * ( grid-&amp;gt;x[i] + invSqrt2 );
            grid-&amp;gt;wfc[j+GRIDSIZE*i].y = 0.;
        }
    }

    //Momentum space grids
    for (int j=0; j &amp;lt; GRIDSIZE; ++j){
        grid-&amp;gt;kx[j] = (j&amp;lt;(GRIDSIZE/2)) ? j*2*PI/(GRIDMAX) : -(GRIDSIZE - j)*(2*PI/(GRIDMAX));
        grid-&amp;gt;ky[j] = grid-&amp;gt;kx[j];
    }
    for(int i=0; i &amp;lt; GRIDSIZE; ++i){
        for(int j=0; j &amp;lt; GRIDSIZE; ++j){
            grid-&amp;gt;kxy2[j+GRIDSIZE*i] = 0.5*(grid-&amp;gt;kx[i]*grid-&amp;gt;kx[i]+grid-&amp;gt;ky[j]*grid-&amp;gt;ky[j]);

            //Evolution operator in momentum space
            grid-&amp;gt;U_K[j+GRIDSIZE*i].x = cos(-grid-&amp;gt;kxy2[j+GRIDSIZE*i]*DT);
            grid-&amp;gt;U_K[j+GRIDSIZE*i].y = sin(-grid-&amp;gt;kxy2[j+GRIDSIZE*i]*DT);
        }
    }
}

//################################################//
int fileIO(Grid *grid){
    //Open files to write
    FILE *f_x = fopen(&amp;quot;x&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_y = fopen(&amp;quot;y&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_xy2 = fopen(&amp;quot;xy2&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_kx = fopen(&amp;quot;kx&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_ky = fopen(&amp;quot;ky&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_kxy2 = fopen(&amp;quot;kxy2&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_U_V = fopen(&amp;quot;U_V&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_U_K = fopen(&amp;quot;U_K&amp;quot;, &amp;quot;w&amp;quot;);
    FILE *f_wfc = fopen(&amp;quot;wfc&amp;quot;, &amp;quot;w&amp;quot;);

    //No safety checks because I&#39;m a bad person

    fwrite(grid-&amp;gt;x, sizeof(double), GRIDSIZE, f_x);
    fwrite(grid-&amp;gt;y, sizeof(double), GRIDSIZE, f_y);
    fwrite(grid-&amp;gt;xy2, sizeof(double), GRIDSIZE*GRIDSIZE, f_xy2);
    fwrite(grid-&amp;gt;kx, sizeof(double), GRIDSIZE, f_kx);
    fwrite(grid-&amp;gt;ky, sizeof(double), GRIDSIZE, f_ky);
    fwrite(grid-&amp;gt;kxy2, sizeof(double), GRIDSIZE*GRIDSIZE, f_kxy2);
    fwrite(grid-&amp;gt;U_V, sizeof(double2), GRIDSIZE*GRIDSIZE, f_U_V);
    fwrite(grid-&amp;gt;U_K, sizeof(double2), GRIDSIZE*GRIDSIZE, f_U_K);
    fwrite(grid-&amp;gt;wfc, sizeof(double2), GRIDSIZE*GRIDSIZE, f_wfc);

    //No moar opin

    fclose(f_x); fclose(f_y); fclose(f_xy2); fclose(f_kx);  fclose(f_ky);
    fclose(f_kxy2); fclose(f_U_V); fclose(f_U_K); fclose(f_wfc);
    return 0;
}

//################################################//
int main(){
    Grid grid;
    setupGrids(&amp;amp;grid);
    fileIO(&amp;amp;grid);
}


//################################################//

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://mlxd.github.io/img/x_y_kx_ky.png&#34; alt=&#34;alt text&#34; title=&#34;X Y Kx Ky&#34; /&gt;
&lt;img src=&#34;https://mlxd.github.io/img/xy2_kxky2_UV_UK.png&#34; alt=&#34;alt text&#34; title=&#34;Ops&#34; /&gt;
&lt;img src=&#34;https://mlxd.github.io/img/wfc_abs2.png&#34; alt=&#34;alt text&#34; title=&#34;WFC&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Overdue todo</title>
      <link>https://mlxd.github.io/post/2016-05-11-todo/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2016-05-11-todo/</guid>
      <description>&lt;p&gt;Granted I have not published any of the articles I am writing since my initial post, they are still in the works. Unfortunately, they will also  need to wait until my thesis has been written and published (as some of them will be used therein).&lt;/p&gt;

&lt;p&gt;As a snapshot, I will intend to discuss the following topics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GPU acceleration of Schrodinger-like problems using &lt;a href=&#34;https://github.com/mlxd/gpue&#34;&gt;GPUE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Implementing the pseudospectral Fourier split-operator method for time dependent simulations&lt;/li&gt;
&lt;li&gt;An easy introduction to simulation of Bose-Einstein condensates (BECs)&lt;/li&gt;
&lt;li&gt;Numerically solving the Bogoliubov equations for BEC fun&lt;/li&gt;
&lt;li&gt;Playing with vortices in a BEC&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, do not hold your breath for these&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Questions to expand upon</title>
      <link>https://mlxd.github.io/post/2017-07-11-questions/</link>
      <pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-07-11-questions/</guid>
      <description>

&lt;h1 id=&#34;questions-to-consider&#34;&gt;Questions to consider&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;What is the optimal choice of FFTs over competing HPC software and device architectures for quantum dynamics using pseduospectral methods?&lt;/li&gt;
&lt;li&gt;Do space filling curves have a performance impact on multidimensional data when performing FFTs along the i-th dimension?&lt;/li&gt;
&lt;li&gt;Is there an optimal way to permute an n-D data set so that the elements along a specific basis direction are linear in memory? Reasons for this are optimal data access when performing operations, allowing for higher cache hits (such as with FFTs on GPUs are an example).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Initiali[sz]e</title>
      <link>https://mlxd.github.io/post/2015-10-17-init/</link>
      <pubDate>Mon, 18 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2015-10-17-init/</guid>
      <description>

&lt;p&gt;(Original post 2015-10-17; updated 2017-01-18)&lt;/p&gt;

&lt;p&gt;As this is my first post I will keep things simple. Unless otherwise specified, I will be using the following as my default tools.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;editors-ide-cool-things&#34;&gt;Editors/IDE/Cool things&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;ViM (pretty much everything code related)&lt;/li&gt;
&lt;li&gt;Atom (Markdown, text files, and the like)&lt;/li&gt;
&lt;li&gt;Jupyter (IPython, IJulia)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;languages-toolchains&#34;&gt;Languages [toolchains]&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;C/C++ [g++, icc]&lt;/li&gt;
&lt;li&gt;CUDA/OpenCL [nvcc, icc]&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;MATLAB&lt;/li&gt;
&lt;li&gt;Julia&lt;/li&gt;
&lt;li&gt;Mathematica&lt;/li&gt;
&lt;li&gt;Bash/Zsh&lt;/li&gt;
&lt;li&gt;English (occasionally)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;os&#34;&gt;OS&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Arch Linux&lt;/li&gt;
&lt;li&gt;CentOS 7&lt;/li&gt;
&lt;li&gt;OS X 10.12&lt;/li&gt;
&lt;li&gt;Windows 10&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;devices-as-of-2017-01-18&#34;&gt;Devices (as of 2017-01-18)&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;Lenovo Thinkpad T430&lt;/li&gt;
&lt;li&gt;Apple MBP (2012)&lt;/li&gt;
&lt;li&gt;Sango cluster @ OIST&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;These lists will be updated to reflect whatever I am using in time. I may make this into a spreadsheet table, so I can tag posts with hardware&amp;hellip; if it makes sense to do so.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
