<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math on Lost in Computation</title>
    <link>https://mlxd.github.io/tags/math/</link>
    <description>Recent content in Math on Lost in Computation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Lee James O&#39;Riordan (mlxd)</copyright>
    <lastBuildDate>Mon, 04 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/math/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Permutations of n-D data</title>
      <link>https://mlxd.github.io/post/2017-09-04-nd-data/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlxd.github.io/post/2017-09-04-nd-data/</guid>
      <description>&lt;p&gt;Something I have been (occasionally) thinking about for quite a long time is the means to manipulate high-dimensional data-sets (dense grids, specifically), and do so efficiently. Namely, I wish to make the data along any specific orthgonal basis direction to become adjacent in memory by strides of the length of samples along that axis.&lt;/p&gt;

&lt;p&gt;The reason for this? To allow for optimal vectorisation and caching of data when performing computations. Take for example a GPU: if we put data on GPU memory we want to access and manipulate it in chunks given by the chosen thread-size. If we access elements out of order, we essentially lose all of the parallelism offered by the device, as the data access will not be performed in the optimal $n$-element wide chunks, but individually at worst, and somewhere in between most likely.&lt;/p&gt;

&lt;p&gt;For a problem with a Cartesian gridded data set in the space given by $ijk$, we can define the lexicographical order from fastest to slowest indices to be in the $ijk$ order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;for(int k=0; k &amp;lt; k_size; ++k)
    for(int j=0; j &amp;lt; j_size; ++j)
        for(int k=0; k &amp;lt; i_size; ++i)
            data[i + i_size*j*(1 + j_size*k)] = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example, $i$ is the fast index and the axis along which the data is linearly adjacent in memory, and $k$ is the slow axis (with $j$ being slower than fast and faster than slow).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mlxd.github.io/img/ndData.jpg&#34; alt=&#34;alt text&#34; title=&#34;A sample layout permutation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The included image above is an example of rotation about the $j$ axis, showing on the right the respective mappings to new index values (for the sake of my interest I&amp;rsquo;ve taken slices along $j$ and $i$, but worked with the latter for the rest of this discussion).&lt;/p&gt;

&lt;p&gt;The bottom of the image shows the rearrangements of memory from the original (upper) to the rotated (lower) memory configurations. The indices themselves seem to take the following mappings (orig. $\rightarrow $ rot.):&lt;/p&gt;

&lt;p&gt;$$ \begin{align}
i &amp;amp; \rightarrow \textrm{stride}(j)-k, \\&lt;br /&gt;
j &amp;amp; \rightarrow j, \\&lt;br /&gt;
k &amp;amp; \rightarrow i, \
\end{align}$$&lt;/p&gt;

&lt;p&gt;where the stride() operation returns the spacing between the elements in the given dimension (in this case, the stride of $j$ is the size of $i$).&lt;/p&gt;

&lt;p&gt;I intend to find an optimal way to perform this in time. Even suboptimal, but good enough would be fine though.&lt;/p&gt;

&lt;p&gt;L.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
